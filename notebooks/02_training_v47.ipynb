{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 1. PARAMETERS"
   ],
   "metadata": {
    "id": "0V4vZ6Qm0ViG",
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "####### CONFIGURATION\n",
    "\n",
    "class CFG:\n",
    "\n",
    "    # environment\n",
    "    environment  = 'local'  # work environment ['kaggle', 'local']\n",
    "    device       = 'GPU'    # training device ['GPU', 'TPU']\n",
    "    device_index = 0        # device index (when using single device)\n",
    "    num_devices  = 1        # no. GPU/TPU devices (modeling)\n",
    "    cpu_workers  = 4        # no. CPU cores (data loading)\n",
    "\n",
    "    # general\n",
    "    version  = 47     # notebook version (for saving outputs)\n",
    "    debug    = False  # debug mode runs 10 batches for 3 epochs\n",
    "    tracking = True   # track results using neptune.ai\n",
    "    seed     = 10627  # random state\n",
    "\n",
    "    # data\n",
    "    num_folds   = 5      # no. CV folds\n",
    "    num_cuts    = 12     # no. target cuts for stratified split\n",
    "    num_reps    = 3      # no. repititions of CV\n",
    "    data_pl     = False  # False or percentage of appended pseudo-labeled data \n",
    "    max_len     = 256    # maximum sequence length \n",
    "    dynamic_pad = False  # whether to enable dynamic padding on batch level\n",
    "    \n",
    "    # augmentations\n",
    "    p_shuffle   = 0.05  # probability of batch-level sentence shuffle\n",
    "    noise_alpha = 0     # magnitude of noise in targets based on SD\n",
    "    p_translate = 0     # probability of swapping a sentence with backtranslation\n",
    "    \n",
    "    # architecture\n",
    "    backbone       = 'bert-large-uncased'  # transformer backbone   \n",
    "    hidden_size    = 1024                  # size of the hidden layer\n",
    "    pretrained     = True                  # pretrained weights [False, True, path]\n",
    "    freeze_embed   = True                  # whether to freeze the embedding layer\n",
    "    freeze_layers  = 0                     # how many deep transformer layers to freeze\n",
    "    init_range     = None                  # weight init range for new layers (None or float)\n",
    "    hidden_dropout = 0.0                   # dropout probability on hidden layers\n",
    "\n",
    "    # network head\n",
    "    pooling        = 'mean'  # pooling technique ['default', 'cls', 'mean', 'max', 'meanmax']\n",
    "    pooling_layer  = -1      # hidden layer to perform pooling\n",
    "    concat_layers  = 4       # no. concatenated pooling layers starting from pooling_layer\n",
    "    layer_norm_eps = 1e-7    # layer normalization epsilon\n",
    "    head_dropout   = 0.0     # dropout probability in head\n",
    "    \n",
    "    # training\n",
    "    num_epochs    = 5      # no. epochs per fold\n",
    "    batch_size    = 20     # no. images per batch \n",
    "    accum_iter    = 1      # no. batches for gradient accumalation\n",
    "    grad_clip     = False  # max gradient norm (False or float)\n",
    "    use_fp16      = True   # mixed precision mode \n",
    "    max_batches   = False  # max no. batches per training epoch (False or int)\n",
    "    batch_verbose = False  # print loss every n batches\n",
    "    \n",
    "    # learning rate \n",
    "    lr             = 1e-4  # starting learning rate\n",
    "    decay          = 1e-3  # weight decay of optimizer (L2 regularization)\n",
    "    lr_layer_decay = 0.85  # LR multiplier when going to deeper layers\n",
    "\n",
    "    # optimizer & scheduler\n",
    "    optim           = 'AdamW'   # LR optimizer ['Adam', 'AdamW', 'AdamP', 'madgrad']\n",
    "    adamw_bias      = True      # AdamW param: whether to enable bias correction\n",
    "    scheduler       = 'cosine'  # LR scheduler after warmup ['constant', 'linear', 'cosine']\n",
    "    warmup          = 1         # no. epochs for warmup\n",
    "    update_on_batch = True      # update LR after every batch (or epoch)\n",
    "    \n",
    "    # loss function\n",
    "    loss_fn = 'MSE'  # loss ['MSE', 'RMSE']\n",
    "\n",
    "    # stochastic weight averaging\n",
    "    swa               = False     \n",
    "    swa_start         = 5\n",
    "    swa_learning_rate = 1e-4\n",
    "    anneal_epochs     = 3 \n",
    "    anneal_strategy   = 'cos'\n",
    "    \n",
    "    # inference\n",
    "    eval_step        = 4     # no. batches before evaluation (False or int)\n",
    "    predict_oof      = True  # whether to produce OOF predictions\n",
    "    predict_test     = True  # whether to produce test predictions \n",
    "    valid_batch_size = 128   # no. cases per batch "
   ],
   "outputs": [],
   "metadata": {
    "id": "ZGLrkTFa0ViK"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "####### CONVERT CONFIGURATION\n",
    "\n",
    "CFG = dict(vars(CFG))\n",
    "for key in ['__dict__', '__doc__', '__module__', '__weakref__']:\n",
    "    del CFG[key]"
   ],
   "outputs": [],
   "metadata": {
    "id": "ONx3m0TJ2PJ1"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "####### UPDATES FOR DEBUG MODE\n",
    "\n",
    "if CFG['debug']:\n",
    "    CFG['predict_test'] = False\n",
    "    CFG['tracking']     = False\n",
    "    CFG['num_epochs']   = 2\n",
    "    CFG['num_folds']    = 2\n",
    "    CFG['num_reps']     = 1"
   ],
   "outputs": [],
   "metadata": {
    "id": "8a2ClHIAthIY"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2. PREPARATIONS"
   ],
   "metadata": {
    "id": "-9ZKt08y0ViT"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "####### PACKAGES\n",
    "\n",
    "if CFG['environment'] != 'local':\n",
    "    !pip install timm transformers accelerate adamp madgrad\n",
    "    !pip install --upgrade neptune-client\n",
    "    !pip install --upgrade --force-reinstall --no-deps -q kaggle\n",
    "    \n",
    "if CFG['device'] == 'TPU':\n",
    "    !pip install cloud-tpu-client==0.10 'https://storage.googleapis.com/tpu-pytorch/wheels/torch_xla-1.8-cp37-cp37m-linux_x86_64.whl'\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score, mean_squared_error\n",
    "from sklearn.model_selection import StratifiedKFold, GroupKFold, KFold\n",
    "\n",
    "from accelerate import notebook_launcher\n",
    "\n",
    "import warnings\n",
    "import gc; gc.enable()"
   ],
   "outputs": [],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S6rE_WKH0ViV",
    "outputId": "cbb5b126-f7d4-4f65-b2ec-9021d3596ee9",
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "####### MODULES\n",
    "\n",
    "# source\n",
    "if CFG['environment'] == 'local':\n",
    "    sys.path.append('../code')  \n",
    "elif CFG['environment'] == 'kaggle':\n",
    "    sys.path.append('../input/readability-code')  \n",
    "\n",
    "# utilities\n",
    "from utilities import *\n",
    "\n",
    "# training and inference\n",
    "from run_training import run_training\n",
    "from run_inference import run_inference\n",
    "\n",
    "# visualiztion\n",
    "from sample_batch import sample_batch"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "####### WORKING PATHS\n",
    "\n",
    "if CFG['environment'] == 'local':\n",
    "    CFG['data_path']  = '../input/'\n",
    "    CFG['out_path']   = '../output/v' + str(CFG['version']) + '/'\n",
    "    if not os.path.exists(CFG['out_path']):\n",
    "        os.mkdir(CFG['out_path'])\n",
    "        \n",
    "elif CFG['environment'] == 'kaggle':\n",
    "    CFG['data_path']  = '../input/commonlitreadabilityprize/'\n",
    "    CFG['out_path']   = ''"
   ],
   "outputs": [],
   "metadata": {
    "id": "2_X93RyNgsJI"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "####### TRACKING WITH NEPTUNE\n",
    "\n",
    "if CFG['tracking']:\n",
    "    import neptune \n",
    "    neptune.init(api_token = 'you-api-token',\n",
    "                 project_qualified_name = 'your-project')\n",
    "    neptune.create_experiment(name = 'v' + str(CFG['version']), params = CFG) "
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Info (NVML): RM has detected an NVML/RM version mismatch.. GPU usage metrics may not be reported. For more information, see https://docs-legacy.neptune.ai/logging-and-managing-experiment-results/logging-experiment-data.html#hardware-consumption \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "https://app.neptune.ai/ml_comps/readability/e/READ-399\n"
     ]
    }
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WNePNOxvCCkS",
    "outputId": "a423aa41-e716-42d6-d8b2-80b7f670bf05",
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "####### SETTINGS\n",
    "\n",
    "warnings.filterwarnings('ignore')       # ignoring warnings\n",
    "pd.options.display.max_columns = 100    # maximum displayed columns\n",
    "torch.backends.cudnn.benchmark = False  # set to True if NN inputs are the same size\n",
    "seed_everything(CFG['seed'])            # random seed"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "- setting random seed to 10627...\n"
     ]
    }
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UPuaITycSayz",
    "outputId": "335ab793-890a-465a-c744-713475733c85"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 3. DATA PREP"
   ],
   "metadata": {
    "id": "T2OuAGJw0Viv"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "####### TRAIN DATA PROCESSING\n",
    "\n",
    "# import\n",
    "df = pd.read_csv(CFG['data_path'] + 'train.csv')\n",
    "\n",
    "# check max length\n",
    "from tokenizer import get_tokenizer\n",
    "tokenizer = get_tokenizer(CFG)\n",
    "df['seq_length'] = df['excerpt'].apply(lambda x: len(tokenizer(x)['input_ids']))\n",
    "print('maximum length: {}'.format(max(df['seq_length'])))\n",
    "\n",
    "# partitioning\n",
    "df['target_cat'] = pd.cut(df['target'], CFG['num_cuts'], labels = False)\n",
    "for i in range(CFG['num_reps']):\n",
    "    folds = StratifiedKFold(n_splits = CFG['num_folds'], shuffle = True, random_state = CFG['seed'] - i)\n",
    "    for fold_idx, (trn_idx, val_idx) in enumerate(folds.split(df, df['target_cat'])):\n",
    "        df.loc[val_idx, 'fold' + str(i)] = int(fold_idx)\n",
    "    df['fold' + str(i)] = df['fold' + str(i)].astype(int)\n",
    "             \n",
    "# display\n",
    "print('train shape: {}'.format(df.shape))\n",
    "display(df.head())"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "maximum length: 314\n",
      "train shape: (2834, 11)\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "          id url_legal license  \\\n",
       "0  c12129c31       NaN     NaN   \n",
       "1  85aa80a4c       NaN     NaN   \n",
       "2  b69ac6792       NaN     NaN   \n",
       "3  dd1000b26       NaN     NaN   \n",
       "4  37c1b32fb       NaN     NaN   \n",
       "\n",
       "                                             excerpt    target  \\\n",
       "0  When the young people returned to the ballroom... -0.340259   \n",
       "1  All through dinner time, Mrs. Fayre was somewh... -0.315372   \n",
       "2  As Roger had predicted, the snow departed as q... -0.580118   \n",
       "3  And outside before the palace a great garden w... -1.054013   \n",
       "4  Once upon a time there were Three Bears who li...  0.247197   \n",
       "\n",
       "   standard_error  seq_length  target_cat  fold0  fold1  fold2  \n",
       "0        0.464009         220           7      1      3      1  \n",
       "1        0.480805         243           7      0      3      1  \n",
       "2        0.476676         229           6      4      0      3  \n",
       "3        0.450007         220           5      3      2      0  \n",
       "4        0.510845         186           8      1      2      2  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>url_legal</th>\n",
       "      <th>license</th>\n",
       "      <th>excerpt</th>\n",
       "      <th>target</th>\n",
       "      <th>standard_error</th>\n",
       "      <th>seq_length</th>\n",
       "      <th>target_cat</th>\n",
       "      <th>fold0</th>\n",
       "      <th>fold1</th>\n",
       "      <th>fold2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c12129c31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>When the young people returned to the ballroom...</td>\n",
       "      <td>-0.340259</td>\n",
       "      <td>0.464009</td>\n",
       "      <td>220</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>85aa80a4c</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All through dinner time, Mrs. Fayre was somewh...</td>\n",
       "      <td>-0.315372</td>\n",
       "      <td>0.480805</td>\n",
       "      <td>243</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b69ac6792</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>As Roger had predicted, the snow departed as q...</td>\n",
       "      <td>-0.580118</td>\n",
       "      <td>0.476676</td>\n",
       "      <td>229</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dd1000b26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>And outside before the palace a great garden w...</td>\n",
       "      <td>-1.054013</td>\n",
       "      <td>0.450007</td>\n",
       "      <td>220</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>37c1b32fb</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Once upon a time there were Three Bears who li...</td>\n",
       "      <td>0.247197</td>\n",
       "      <td>0.510845</td>\n",
       "      <td>186</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "####### TEST DATA PROCESSING\n",
    "\n",
    "# import\n",
    "sub = pd.read_csv(CFG['data_path'] + 'test.csv')\n",
    "\n",
    "# subset if debug\n",
    "if CFG['debug']:\n",
    "    sub = sub.head(CFG['valid_batch_size'])\n",
    "\n",
    "# display\n",
    "print('test shape: {}'.format(sub.shape))\n",
    "display(sub.head())"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "test shape: (7, 4)\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "          id                                    url_legal       license  \\\n",
       "0  c0f722661                                          NaN           NaN   \n",
       "1  f0953f0a5                                          NaN           NaN   \n",
       "2  0df072751                                          NaN           NaN   \n",
       "3  04caf4e0c  https://en.wikipedia.org/wiki/Cell_division  CC BY-SA 3.0   \n",
       "4  0e63f8bea      https://en.wikipedia.org/wiki/Debugging  CC BY-SA 3.0   \n",
       "\n",
       "                                             excerpt  \n",
       "0  My hope lay in Jack's promise that he would ke...  \n",
       "1  Dotty continued to go to Mrs. Gray's every nig...  \n",
       "2  It was a bright and cheerful scene that greete...  \n",
       "3  Cell division is the process by which a parent...  \n",
       "4  Debugging is the process of finding and resolv...  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>url_legal</th>\n",
       "      <th>license</th>\n",
       "      <th>excerpt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c0f722661</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>My hope lay in Jack's promise that he would ke...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>f0953f0a5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Dotty continued to go to Mrs. Gray's every nig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0df072751</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>It was a bright and cheerful scene that greete...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>04caf4e0c</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Cell_division</td>\n",
       "      <td>CC BY-SA 3.0</td>\n",
       "      <td>Cell division is the process by which a parent...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0e63f8bea</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Debugging</td>\n",
       "      <td>CC BY-SA 3.0</td>\n",
       "      <td>Debugging is the process of finding and resolv...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {}
    }
   ],
   "metadata": {
    "id": "YiVTVu2WSazW"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "###### SHOW SAMPLE BATCH\n",
    "\n",
    "sample_batch(CFG, df, sample_size = 5, seq_size = 15, batch_idx = 2)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "- setting random seed to 10627...\n",
      "- loading time: 0.1964 vs 0.1131 seconds\n",
      "- inputs shape: torch.Size([5, 256]) vs torch.Size([5, 256])\n",
      "----------------------------------------------------------------------------------------------------\n",
      "101, 5916, 15983, 2001, 2908, 1010, 10508, 2001, 2908, 1012, 1996, 2282, 2001, 3243, 4064 |           -3.081337118\n",
      "101, 2009, 2001, 3373, 2011, 1996, 4054, 2273, 1997, 3448, 2008, 14838, 1005, 1055, 25353 |           -2.145248365\n",
      "101, 1996, 5119, 1999, 1037, 3518, 2277, 4930, 1996, 3178, 1997, 2048, 1012, 1996, 2181 |           -1.400318025\n",
      "101, 1996, 3750, 2939, 12531, 2039, 1998, 2091, 1996, 2146, 1010, 2659, 1011, 8292, 18450 |           -0.495298635\n",
      "101, 2023, 21877, 7265, 4360, 2015, 2001, 10920, 1011, 2048, 2086, 2214, 1012, 2002, 2001 |            0.245805709\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[CLS] it was believed by the principal men of virginia that talbot's sy     |           -3.081337118\n",
      "[CLS] this pedrarias was seventy - two years old. he was                    |           -2.145248365\n",
      "[CLS] the emperor walked nervously up and down the long, low - ceiled       |           -1.400318025\n",
      "[CLS] the clock in a nearby church struck the hour of two. the area         |           -0.495298635\n",
      "[CLS] aunt abigail was gone, eleanor was gone. the room was quite empty     |            0.245805709\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 561
    },
    "id": "RKboY5BsSazD",
    "outputId": "214a33a8-dc62-4897-d808-b6d7bc5a2f90",
    "tags": []
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 4. CROSS-VALIDATION"
   ],
   "metadata": {
    "id": "NtAEmeT80VjI"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "####### CROSS-VALIDATION LOOP\n",
    "\n",
    "# timer\n",
    "cv_start = time.time()\n",
    "\n",
    "# run cross-validation\n",
    "print('-' * 55)\n",
    "notebook_launcher(function      = run_training,\n",
    "                  args          = (df, CFG),\n",
    "                  num_processes = CFG['num_devices'],\n",
    "                  use_fp16      = CFG['use_fp16'])\n",
    "\n",
    "# clear memory\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# feedback\n",
    "print('')\n",
    "print('Finished in {:.2f} minutes'.format((time.time() - cv_start) / 60))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "-------------------------------------------------------\n",
      "Launching training on CPU.\n",
      "-------------------------------------------------------\n",
      "REP 1/3 | FOLD 1/5\n",
      "-------------------------------------------------------\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Some weights of the model checkpoint at bert-large-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "- no. observations: train - 2267, valid - 567\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "RuntimeError",
     "evalue": "Unexpected error from cudaGetDeviceCount(). Did you run some cuda functions before calling NumCudaDevices() that might have already set an error? Error 803: system has unsupported display driver / cuda driver combination",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-51d301791c98>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# run cross-validation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'-'\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m55\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m notebook_launcher(function      = run_training,\n\u001b[0m\u001b[1;32m      9\u001b[0m                   \u001b[0margs\u001b[0m          \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCFG\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m                   \u001b[0mnum_processes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCFG\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'num_devices'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/py3/lib/python3.8/site-packages/accelerate/notebook_launcher.py\u001b[0m in \u001b[0;36mnotebook_launcher\u001b[0;34m(function, args, num_processes, use_fp16, use_port)\u001b[0m\n\u001b[1;32m    129\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Launching training on CPU.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m             \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/net/kozodoin4.hub/Competitions/readability/code/run_training.py\u001b[0m in \u001b[0;36mrun_training\u001b[0;34m(df, CFG)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m             \u001b[0;31m# run single fold\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m             trn_losses, val_losses, val_scores = train_fold(rep         = rep,\n\u001b[0m\u001b[1;32m     58\u001b[0m                                                             \u001b[0mfold\u001b[0m        \u001b[0;34m=\u001b[0m \u001b[0mfold\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m                                                             \u001b[0mdf_trn\u001b[0m      \u001b[0;34m=\u001b[0m \u001b[0mdf_trn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/net/kozodoin4.hub/Competitions/readability/code/train_fold.py\u001b[0m in \u001b[0;36mtrain_fold\u001b[0;34m(rep, fold, df_trn, df_val, CFG, model, accelerator)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;31m# handle device placement\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrn_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccelerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrn_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0;31m# get scheduler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/py3/lib/python3.8/site-packages/accelerate/accelerator.py\u001b[0m in \u001b[0;36mprepare\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    266\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prepare_deepspeed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 268\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prepare_one\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtpu_should_fix_optimizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/py3/lib/python3.8/site-packages/accelerate/accelerator.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    266\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prepare_deepspeed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 268\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prepare_one\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtpu_should_fix_optimizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/py3/lib/python3.8/site-packages/accelerate/accelerator.py\u001b[0m in \u001b[0;36m_prepare_one\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    224\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_models\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 226\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    227\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m             \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_optimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/py3/lib/python3.8/site-packages/accelerate/accelerator.py\u001b[0m in \u001b[0;36mprepare_model\u001b[0;34m(self, model)\u001b[0m\n\u001b[1;32m    282\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mprepare_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_placement\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 284\u001b[0;31m             \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    285\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistributed_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mDistributedType\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMULTI_GPU\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m             \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mddp_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mddp_handler\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/py3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    671\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    672\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 673\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    674\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m     def register_backward_hook(\n",
      "\u001b[0;32m~/.conda/envs/py3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    385\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 387\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    388\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/py3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    385\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 387\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    388\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/py3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    385\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 387\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    388\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/py3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    407\u001b[0m                 \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 409\u001b[0;31m                     \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    410\u001b[0m                 \u001b[0mshould_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/py3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    669\u001b[0m                 return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None,\n\u001b[1;32m    670\u001b[0m                             non_blocking, memory_format=convert_to_format)\n\u001b[0;32m--> 671\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    672\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    673\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/py3/lib/python3.8/site-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0;31m# This function throws if there's a driver initialization error, no GPUs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m         \u001b[0;31m# are found or any other error occurs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m         \u001b[0;31m# Some of the queued calls may reentrantly call _lazy_init();\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m         \u001b[0;31m# we need to just return without initializing in that case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Unexpected error from cudaGetDeviceCount(). Did you run some cuda functions before calling NumCudaDevices() that might have already set an error? Error 803: system has unsupported display driver / cuda driver combination"
     ]
    }
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VIOZZY6cfxBx",
    "outputId": "cc6971e8-acc8-4be0-e3e1-f2a858a6fe7f",
    "tags": []
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 5. INFERENCE"
   ],
   "metadata": {
    "id": "e5bUh1-_0VjL",
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "####### INFERENCE LOOP\n",
    "\n",
    "# timer\n",
    "cv_start = time.time()\n",
    "\n",
    "# run cross-validation\n",
    "print('-' * 55)\n",
    "notebook_launcher(function      = run_inference,\n",
    "                  args          = (df, sub, CFG),\n",
    "                  num_processes = 1,\n",
    "                  use_fp16      = CFG['use_fp16'])\n",
    "\n",
    "# clear memory\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# feedback\n",
    "print('')\n",
    "print('Finished in {:.2f} minutes'.format((time.time() - cv_start) / 60))"
   ],
   "outputs": [],
   "metadata": {
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "####### CHECK OOF PERFORMANCE\n",
    "\n",
    "# import OOF\n",
    "oof = pd.read_csv(CFG['out_path'] + 'oof.csv')\n",
    "\n",
    "# compute score\n",
    "oof_score = []\n",
    "for rep in range(CFG['num_reps']):\n",
    "    oof_score.append(get_score(oof['target'], oof['pred_rep' + str(rep)]))\n",
    "CFG['oof_score'] = np.mean(oof_score)\n",
    "\n",
    "# compute bag score\n",
    "blend = 'amean'\n",
    "oof['blend']     = compute_blend(oof, ['pred_rep' + str(rep) for rep in range(CFG['num_reps'])], blend, CFG)\n",
    "CFG['bag_score'] = get_score(oof['target'], oof['blend'])\n",
    "\n",
    "# print performance\n",
    "print('-' * 22)\n",
    "print('OOF score     = {:.4f}'.format(CFG['oof_score']))\n",
    "print('OOF bag score = {:.4f}'.format(CFG['bag_score']))\n",
    "print('-' * 22)"
   ],
   "outputs": [],
   "metadata": {
    "id": "cJQFNQsc0VjL"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "####### EXPORT CONFIGURATION\n",
    "\n",
    "# save dictionary\n",
    "pickle.dump(CFG, open(CFG['out_path'] + 'configuration.pkl', 'wb'))\n",
    "\n",
    "# send data to Neptune\n",
    "if CFG['tracking']:\n",
    "    neptune.send_metric('oof_score', CFG['oof_score'])\n",
    "    neptune.send_metric('bag_score', CFG['bag_score'])\n",
    "    neptune.send_artifact(CFG['out_path'] + 'configuration.pkl')\n",
    "    neptune.stop()"
   ],
   "outputs": [],
   "metadata": {
    "id": "2g1eeDFgleGB"
   }
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "training_v21.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "neptune": {
   "notebookId": "83aec7da-b563-4f21-b7c2-a086a97d489b",
   "projectVersion": 2
  },
  "papermill": {
   "default_parameters": {},
   "duration": 27660.340489,
   "end_time": "2021-03-13T07:27:19.479867",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-03-12T23:46:19.139378",
   "version": "2.2.2"
  },
  "toc-autonumbering": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}