{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "717c6696",
   "metadata": {
    "papermill": {
     "duration": 0.038833,
     "end_time": "2021-08-02T20:43:46.535234",
     "exception": false,
     "start_time": "2021-08-02T20:43:46.496401",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# PARAMETERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "394560b6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-02T20:43:46.628078Z",
     "iopub.status.busy": "2021-08-02T20:43:46.623762Z",
     "iopub.status.idle": "2021-08-02T20:43:46.630850Z",
     "shell.execute_reply": "2021-08-02T20:43:46.630252Z",
     "shell.execute_reply.started": "2021-08-02T20:16:54.247773Z"
    },
    "papermill": {
     "duration": 0.058336,
     "end_time": "2021-08-02T20:43:46.630999",
     "exception": false,
     "start_time": "2021-08-02T20:43:46.572663",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "####### INFERENCE CONFIGURATION\n",
    "\n",
    "class CFG:\n",
    "    \n",
    "    # environment\n",
    "    cpu_workers = 2  # no. CPU cores (data loading)\n",
    "\n",
    "    # general\n",
    "    seed = 13353  # random state\n",
    "    \n",
    "    # data\n",
    "    num_folds = 5   # no. CV folds\n",
    "    num_cuts  = 12  # no. target cuts for stratified split\n",
    "    num_reps  = 3   # no. repititions of CV\n",
    "    \n",
    "    # inference\n",
    "    batch_size = 32       # no. cases per batch    \n",
    "    clip       = [-4, 2]  # trim predictions (min, max)\n",
    "    \n",
    "    # blending\n",
    "    use_folds   = 5        # no. folds to use in blends\n",
    "    use_reps    = 2        # no. bags to use in blends\n",
    "    fold_blend  = 'amean'  # how to blend folds ['amean', 'median']\n",
    "    rep_blend   = 'amean'  # how to blend bags ['amean', 'median']\n",
    "    model_blend = 'amean'  # how to blend models ['amean', 'median']\n",
    "    \n",
    "    # stacking \n",
    "    w_stack         = 0.00  #0.45  # weight of stacking in final ensemble\n",
    "    lgb_reps        = 3     # no. bags for stacking\n",
    "    lgb_folds       = 5     # no. folds for stacking\n",
    "    lgb_stop_rounds = 200   # no. early stopping rounds\n",
    "    lgb_params      = {'objective':         'regression',\n",
    "                       'metrics':           'rmse',\n",
    "                       'n_estimators':      10000,\n",
    "                       'learning_rate':     0.01,\n",
    "                       'num_leaves':        6,\n",
    "                       'max_depth':         4,\n",
    "                       'min_child_samples': 20,\n",
    "                       'subsample':         0.6,\n",
    "                       'colsample_bytree':  0.6,\n",
    "                       'reg_alpha':         0.01,\n",
    "                       'reg_lambda':        0.01,\n",
    "                       'silent':            True,\n",
    "                       'verbosity':         -1,\n",
    "                       'n_jobs' :           -1,\n",
    "                       'random_state':      13353}\n",
    "    \n",
    "    # public kenels\n",
    "    w_public = 0.20\n",
    "    \n",
    "    # paths\n",
    "    data_path = '../input/commonlitreadabilityprize/'\n",
    "    out_path  = ''\n",
    "    \n",
    "    # models\n",
    "    models = [\n",
    "             ##################################################################\n",
    "             #'../input/readability-training-v33/', # roberta-base\n",
    "             #'../input/readability-training-v34/', # roberta-base\n",
    "             #'../input/readability-training-v37/', # roberta-base\n",
    "             #'../input/readability-v40/',          # albert-large-v2\n",
    "             #'../input/readability-training-v41/', # roberta-base\n",
    "             #'../input/readability-v46/',          # bert-base-uncased\n",
    "             #'../input/readability-training-v48/', # roberta-base [pretrained]\n",
    "             #'../input/readability-v49/',          # distilbert-base-uncased\n",
    "             #'../input/readability-v50/',          # facebook/bart-base\n",
    "             #'../input/readability-v58/',          # distilbert-base-uncased\n",
    "             #'../input/readability-v72/',          # bert-large-uncased\n",
    "             #'../input/readability-v38/',          # roberta-large\n",
    "             #'../input/readability-training-v74/', # electra-base\n",
    "             #'../input/readability-v78/',           # electra-base\n",
    "             ##################################################################\n",
    "             '../input/readability-v36/',           # roberta-large\n",
    "             '../input/readability-v47/',           # distilroberta-base\n",
    "             '../input/readability-training-v52/',  # roberta-base\n",
    "             '../input/readability-training-v55/',  # roberta-base \n",
    "             '../input/readability-training-v56/',  # roberta-base [pretrained]\n",
    "             '../input/readability-training-v59/',  # distilbert-base-uncased\n",
    "             '../input/readability-v62/',           # roberta-large\n",
    "             '../input/readability-v69/',           # bert-base-uncased\n",
    "             ##################################################################\n",
    "             ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50172e54",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-02T20:43:46.711021Z",
     "iopub.status.busy": "2021-08-02T20:43:46.710252Z",
     "iopub.status.idle": "2021-08-02T20:43:46.713681Z",
     "shell.execute_reply": "2021-08-02T20:43:46.714100Z",
     "shell.execute_reply.started": "2021-08-02T20:16:54.978626Z"
    },
    "papermill": {
     "duration": 0.045383,
     "end_time": "2021-08-02T20:43:46.714250",
     "exception": false,
     "start_time": "2021-08-02T20:43:46.668867",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "####### CONVERT CONFIGURATION\n",
    "\n",
    "CFG = dict(vars(CFG))\n",
    "for key in ['__dict__', '__doc__', '__module__', '__weakref__']:\n",
    "    del CFG[key]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e94fb237",
   "metadata": {
    "papermill": {
     "duration": 0.036791,
     "end_time": "2021-08-02T20:43:46.787910",
     "exception": false,
     "start_time": "2021-08-02T20:43:46.751119",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# PREPARATIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca208934",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-02T20:43:46.873832Z",
     "iopub.status.busy": "2021-08-02T20:43:46.871895Z",
     "iopub.status.idle": "2021-08-02T20:43:55.593084Z",
     "shell.execute_reply": "2021-08-02T20:43:55.592584Z",
     "shell.execute_reply.started": "2021-08-02T19:37:43.366993Z"
    },
    "papermill": {
     "duration": 8.766425,
     "end_time": "2021-08-02T20:43:55.593233",
     "exception": false,
     "start_time": "2021-08-02T20:43:46.826808",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type='text/css'>\n",
       ".datatable table.frame { margin-bottom: 0; }\n",
       ".datatable table.frame thead { border-bottom: none; }\n",
       ".datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n",
       ".datatable .bool    { background: #DDDD99; }\n",
       ".datatable .object  { background: #565656; }\n",
       ".datatable .int     { background: #5D9E5D; }\n",
       ".datatable .float   { background: #4040CC; }\n",
       ".datatable .str     { background: #CC4040; }\n",
       ".datatable .time    { background: #40CC40; }\n",
       ".datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n",
       ".datatable .frame tbody td { text-align: left; }\n",
       ".datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n",
       ".datatable th:nth-child(2) { padding-left: 12px; }\n",
       ".datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n",
       ".datatable .sp {  opacity: 0.25;}\n",
       ".datatable .footer { font-size: 9px; }\n",
       ".datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "####### PACKAGES\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import pickle\n",
    "import random\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score, mean_squared_error\n",
    "from sklearn.model_selection import StratifiedKFold, GroupKFold, KFold\n",
    "\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "\n",
    "import lightgbm as lgb\n",
    "\n",
    "import warnings\n",
    "import gc; gc.enable()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "sys.path.append('../input/accelerate/accelerate-main')\n",
    "from src.accelerate import Accelerator, DistributedType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "336bb9ae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-02T20:43:55.665975Z",
     "iopub.status.busy": "2021-08-02T20:43:55.665340Z",
     "iopub.status.idle": "2021-08-02T20:43:55.715041Z",
     "shell.execute_reply": "2021-08-02T20:43:55.714524Z",
     "shell.execute_reply.started": "2021-08-02T19:37:53.621395Z"
    },
    "papermill": {
     "duration": 0.088608,
     "end_time": "2021-08-02T20:43:55.715173",
     "exception": false,
     "start_time": "2021-08-02T20:43:55.626565",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "####### MODULES\n",
    "\n",
    "# source\n",
    "sys.path.append('../input/readability-code')  \n",
    "\n",
    "# utilities\n",
    "from utilities import *\n",
    "\n",
    "# data\n",
    "from data import TextData, collate_fn\n",
    "\n",
    "# model\n",
    "from model import get_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42c72a8e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-02T20:43:55.785527Z",
     "iopub.status.busy": "2021-08-02T20:43:55.784876Z",
     "iopub.status.idle": "2021-08-02T20:43:55.791890Z",
     "shell.execute_reply": "2021-08-02T20:43:55.792256Z",
     "shell.execute_reply.started": "2021-08-02T19:37:53.678896Z"
    },
    "papermill": {
     "duration": 0.044263,
     "end_time": "2021-08-02T20:43:55.792396",
     "exception": false,
     "start_time": "2021-08-02T20:43:55.748133",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- setting random seed to 13353...\n"
     ]
    }
   ],
   "source": [
    "####### ENVIRONMENT SETTINGS\n",
    "\n",
    "pd.options.display.max_columns = 100  # maximum displayed columns\n",
    "warnings.filterwarnings('ignore')     # ignoring warnings\n",
    "seed_everything(CFG['seed'])          # random seed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3dcdd70",
   "metadata": {
    "papermill": {
     "duration": 0.034215,
     "end_time": "2021-08-02T20:43:55.859370",
     "exception": false,
     "start_time": "2021-08-02T20:43:55.825155",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# DATA PREP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5dde0d38",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-02T20:43:55.930266Z",
     "iopub.status.busy": "2021-08-02T20:43:55.929733Z",
     "iopub.status.idle": "2021-08-02T20:43:55.960827Z",
     "shell.execute_reply": "2021-08-02T20:43:55.960358Z",
     "shell.execute_reply.started": "2021-08-02T19:37:53.692634Z"
    },
    "id": "YiVTVu2WSazW",
    "papermill": {
     "duration": 0.068461,
     "end_time": "2021-08-02T20:43:55.960941",
     "exception": false,
     "start_time": "2021-08-02T20:43:55.892480",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test shape: (7, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>url_legal</th>\n",
       "      <th>license</th>\n",
       "      <th>excerpt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c0f722661</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>My hope lay in Jack's promise that he would ke...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>f0953f0a5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Dotty continued to go to Mrs. Gray's every nig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0df072751</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>It was a bright and cheerful scene that greete...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>04caf4e0c</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Cell_division</td>\n",
       "      <td>CC BY-SA 3.0</td>\n",
       "      <td>Cell division is the process by which a parent...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0e63f8bea</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Debugging</td>\n",
       "      <td>CC BY-SA 3.0</td>\n",
       "      <td>Debugging is the process of finding and resolv...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                    url_legal       license  \\\n",
       "0  c0f722661                                          NaN           NaN   \n",
       "1  f0953f0a5                                          NaN           NaN   \n",
       "2  0df072751                                          NaN           NaN   \n",
       "3  04caf4e0c  https://en.wikipedia.org/wiki/Cell_division  CC BY-SA 3.0   \n",
       "4  0e63f8bea      https://en.wikipedia.org/wiki/Debugging  CC BY-SA 3.0   \n",
       "\n",
       "                                             excerpt  \n",
       "0  My hope lay in Jack's promise that he would ke...  \n",
       "1  Dotty continued to go to Mrs. Gray's every nig...  \n",
       "2  It was a bright and cheerful scene that greete...  \n",
       "3  Cell division is the process by which a parent...  \n",
       "4  Debugging is the process of finding and resolv...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "####### TEST DATA PROCESSING\n",
    "\n",
    "# import\n",
    "sub = pd.read_csv(CFG['data_path'] + 'test.csv')\n",
    "\n",
    "# display\n",
    "print('test shape: {}'.format(sub.shape))\n",
    "display(sub.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f550049a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-02T20:43:56.037304Z",
     "iopub.status.busy": "2021-08-02T20:43:56.036769Z",
     "iopub.status.idle": "2021-08-02T20:43:57.954088Z",
     "shell.execute_reply": "2021-08-02T20:43:57.953392Z",
     "shell.execute_reply.started": "2021-08-02T19:37:53.731337Z"
    },
    "papermill": {
     "duration": 1.959367,
     "end_time": "2021-08-02T20:43:57.954221",
     "exception": false,
     "start_time": "2021-08-02T20:43:55.994854",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2834, 27)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "####### IMPORT OOF PREDS\n",
    "\n",
    "for m in CFG['models']:\n",
    "\n",
    "    tmp_train_preds         = pd.read_csv(m + 'oof.csv')\n",
    "    tmp_train_preds         = tmp_train_preds[['id', 'url_legal', 'license', 'excerpt', 'target', \n",
    "                               'seq_length', 'standard_error', 'target_cat'] + \\\n",
    "                              ['fold' + str(r) for r in range(CFG['num_reps'])] + \\\n",
    "                              ['pred_rep' + str(r) for r in range(CFG['num_reps'])]]\n",
    "    tmp_train_preds.columns = ['id', 'url_legal', 'license', 'excerpt', 'target', \n",
    "                               'seq_length', 'standard_error', 'target_cat'] + \\\n",
    "                              ['fold' + str(r) for r in range(CFG['num_reps'])] + \\\n",
    "                              [str(m) + 'pred_rep' + str(r) for r in range(CFG['num_reps'])]\n",
    "\n",
    "    if m == CFG['models'][0]:\n",
    "        train_preds = tmp_train_preds        \n",
    "    else:\n",
    "        train_preds = train_preds.merge(tmp_train_preds[['id'] + [str(m) + 'pred_rep' + str(r) for r in range(CFG['num_reps'])]], how = 'left', on = 'id')\n",
    "    \n",
    "train_preds = train_preds[['id', 'target', 'target_cat'] + list(train_preds.filter(like = 'pred').columns)]\n",
    "train_preds.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3d98cd1",
   "metadata": {
    "papermill": {
     "duration": 0.035389,
     "end_time": "2021-08-02T20:43:58.024469",
     "exception": false,
     "start_time": "2021-08-02T20:43:57.989080",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# BLENDING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ea7ebaf7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-02T20:43:58.102210Z",
     "iopub.status.busy": "2021-08-02T20:43:58.101345Z",
     "iopub.status.idle": "2021-08-02T20:43:58.112920Z",
     "shell.execute_reply": "2021-08-02T20:43:58.113333Z",
     "shell.execute_reply.started": "2021-08-02T19:37:55.685383Z"
    },
    "papermill": {
     "duration": 0.054405,
     "end_time": "2021-08-02T20:43:58.113478",
     "exception": false,
     "start_time": "2021-08-02T20:43:58.059073",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------\n",
      "ID   Model                               Score\n",
      "-----------------------------------------------\n",
      "1    ../input/readability-training-v52/  0.4756\n",
      "2    ../input/readability-training-v55/  0.4756\n",
      "3    ../input/readability-training-v56/  0.4758\n",
      "4    ../input/readability-v62/           0.4799\n",
      "5    ../input/readability-v36/           0.4833\n",
      "6    ../input/readability-v47/           0.4863\n",
      "7    ../input/readability-v69/           0.4940\n",
      "8    ../input/readability-training-v59/  0.4992\n",
      "-----------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "####### CHECK OOF PERFORMANCE\n",
    "\n",
    "# sort models by performance\n",
    "weights = []\n",
    "for model_idx, m in enumerate(CFG['models']):\n",
    "    score = 0\n",
    "    for rep in range(CFG['use_reps']):\n",
    "        score += get_score(train_preds['target'], train_preds[str(m) + 'pred_rep' + str(rep)]) / CFG['use_reps']\n",
    "    weights.append(score)\n",
    "sorted_ids     = list(np.argsort(np.array(weights)))\n",
    "sorted_weights = [weights[i] for i in sorted_ids]\n",
    "CFG['models']  = [CFG['models'][i] for i in sorted_ids]\n",
    "\n",
    "# display performance \n",
    "print('-' * 47)\n",
    "print('{:<5}{:<36}{:>5}'.format('ID', 'Model', 'Score'))\n",
    "print('-' * 47)\n",
    "for model_idx, m in enumerate(CFG['models']):\n",
    "    print('{:<5}{:<36}{:.4f}'.format(model_idx + 1, m, sorted_weights[model_idx]))\n",
    "print('-' * 47)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a6abf35e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-02T20:43:58.192228Z",
     "iopub.status.busy": "2021-08-02T20:43:58.191095Z",
     "iopub.status.idle": "2021-08-02T20:43:58.204320Z",
     "shell.execute_reply": "2021-08-02T20:43:58.203681Z",
     "shell.execute_reply.started": "2021-08-02T19:37:55.711434Z"
    },
    "papermill": {
     "duration": 0.056339,
     "end_time": "2021-08-02T20:43:58.204472",
     "exception": false,
     "start_time": "2021-08-02T20:43:58.148133",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "ID   Model                               Bag score\n",
      "--------------------------------------------------\n",
      "1    ../input/readability-training-v56/  0.4689\n",
      "2    ../input/readability-training-v55/  0.4693\n",
      "3    ../input/readability-training-v52/  0.4696\n",
      "4    ../input/readability-v62/           0.4739\n",
      "5    ../input/readability-v36/           0.4769\n",
      "6    ../input/readability-v47/           0.4804\n",
      "7    ../input/readability-v69/           0.4876\n",
      "8    ../input/readability-training-v59/  0.4938\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "####### CHECK BAGGING PERFORMANCE\n",
    "\n",
    "# sort models by performance\n",
    "weights = []\n",
    "for model_idx, m in enumerate(CFG['models']):\n",
    "    rep_preds = [str(m) + 'pred_rep' + str(rep) for rep in range(CFG['use_reps'])]\n",
    "    pred      = compute_blend(train_preds, rep_preds, CFG['fold_blend'], CFG)\n",
    "    score     = get_score(train_preds['target'], pred)\n",
    "    weights.append(score)\n",
    "sorted_ids     = list(np.argsort(np.array(weights)))\n",
    "sorted_weights = [weights[i] for i in sorted_ids]\n",
    "CFG['models']  = [CFG['models'][i] for i in sorted_ids]\n",
    "\n",
    "# display performance \n",
    "print('-' * 50)\n",
    "print('{:<5}{:<36}{:>5}'.format('ID', 'Model', 'Bag score'))\n",
    "print('-' * 50) \n",
    "for model_idx, m in enumerate(CFG['models']):\n",
    "    print('{:<5}{:<36}{:.4f}'.format(model_idx + 1, m, sorted_weights[model_idx]))\n",
    "print('-' * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1837d15e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-02T20:43:58.284822Z",
     "iopub.status.busy": "2021-08-02T20:43:58.284141Z",
     "iopub.status.idle": "2021-08-02T20:43:58.304357Z",
     "shell.execute_reply": "2021-08-02T20:43:58.303742Z",
     "shell.execute_reply.started": "2021-08-02T19:37:55.738298Z"
    },
    "papermill": {
     "duration": 0.063485,
     "end_time": "2021-08-02T20:43:58.304522",
     "exception": false,
     "start_time": "2021-08-02T20:43:58.241037",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------\n",
      "Blend     Score\n",
      "----------------\n",
      "amean     0.4586\n",
      "median    0.4595\n",
      "----------------\n"
     ]
    }
   ],
   "source": [
    "####### CHECK MODEL BLEND PERFORMANCE\n",
    "\n",
    "# list of blends\n",
    "blend_list = ['amean', 'median']\n",
    "\n",
    "# blend bagged predictions\n",
    "for model_idx, m in enumerate(CFG['models']):\n",
    "    rep_preds       = [str(m) + 'pred_rep' + str(rep) for rep in range(CFG['use_reps'])]\n",
    "    train_preds[m] = compute_blend(train_preds, rep_preds, CFG['fold_blend'], CFG)\n",
    "\n",
    "# compute predcitions\n",
    "preds = CFG['models']\n",
    "for blend in blend_list:\n",
    "    train_preds[blend] = compute_blend(train_preds, preds, blend, CFG)\n",
    "\n",
    "# compute performance\n",
    "print('-' * 16)\n",
    "print('{:<10}{:>5}'.format('Blend', 'Score'))\n",
    "print('-' * 16)\n",
    "for blend in blend_list:\n",
    "    score = get_score(train_preds['target'], train_preds[blend])\n",
    "    print('{:<10}{:>5.4f}'.format(blend, score))    \n",
    "print('-' * 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9d539705",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-02T20:43:58.381767Z",
     "iopub.status.busy": "2021-08-02T20:43:58.380925Z",
     "iopub.status.idle": "2021-08-02T20:43:58.406838Z",
     "shell.execute_reply": "2021-08-02T20:43:58.407403Z",
     "shell.execute_reply.started": "2021-08-02T19:37:55.769732Z"
    },
    "papermill": {
     "duration": 0.066918,
     "end_time": "2021-08-02T20:43:58.407712",
     "exception": false,
     "start_time": "2021-08-02T20:43:58.340794",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>85aa80a4c</td>\n",
       "      <td>-0.315372</td>\n",
       "      <td>-0.142832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>057f69731</td>\n",
       "      <td>-1.126248</td>\n",
       "      <td>-0.852753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5e7c0b55b</td>\n",
       "      <td>-1.009999</td>\n",
       "      <td>-1.160706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>66f0a9ff1</td>\n",
       "      <td>-2.386485</td>\n",
       "      <td>-1.456543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bdd8488dd</td>\n",
       "      <td>-0.473702</td>\n",
       "      <td>-0.444412</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id    target      pred\n",
       "0  85aa80a4c -0.315372 -0.142832\n",
       "1  057f69731 -1.126248 -0.852753\n",
       "2  5e7c0b55b -1.009999 -1.160706\n",
       "3  66f0a9ff1 -2.386485 -1.456543\n",
       "4  bdd8488dd -0.473702 -0.444412"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "####### EXPORT BEST OOF BLEND\n",
    "\n",
    "oof_blend         = train_preds[['id', 'target']].copy()\n",
    "oof_blend['pred'] = train_preds[CFG['model_blend']]\n",
    "oof_blend.to_csv(CFG['out_path'] + 'oof_{}.csv'.format(CFG['model_blend']), index = False)\n",
    "oof_blend.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "44dbc29c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-02T20:43:58.486064Z",
     "iopub.status.busy": "2021-08-02T20:43:58.485217Z",
     "iopub.status.idle": "2021-08-02T20:43:58.880753Z",
     "shell.execute_reply": "2021-08-02T20:43:58.881163Z",
     "shell.execute_reply.started": "2021-08-02T19:37:55.803918Z"
    },
    "papermill": {
     "duration": 0.438161,
     "end_time": "2021-08-02T20:43:58.881307",
     "exception": false,
     "start_time": "2021-08-02T20:43:58.443146",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "####### CHECK MODEL OOF CORRELATION\n",
    "\n",
    "corr    = train_preds[CFG['models']].corr()\n",
    "corr    = corr.where(np.tril(np.ones(corr.shape)).astype(np.bool))\n",
    "fig, ax = plt.subplots(figsize = (15, 10))\n",
    "ticks   = [m.replace('../input/readability-', '') for m in CFG['models']]\n",
    "hmap    = sns.heatmap(corr, cmap = 'coolwarm', annot = corr, fmt = '.4f', xticklabels = ticks, yticklabels = ticks)\n",
    "plt.yticks(rotation = 0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64a5b898",
   "metadata": {
    "papermill": {
     "duration": 0.037449,
     "end_time": "2021-08-02T20:43:58.955665",
     "exception": false,
     "start_time": "2021-08-02T20:43:58.918216",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# INFERENCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "699c0c89",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-02T20:43:59.047398Z",
     "iopub.status.busy": "2021-08-02T20:43:59.046797Z",
     "iopub.status.idle": "2021-08-02T20:43:59.081427Z",
     "shell.execute_reply": "2021-08-02T20:43:59.081016Z",
     "shell.execute_reply.started": "2021-08-02T19:37:56.201139Z"
    },
    "papermill": {
     "duration": 0.082786,
     "end_time": "2021-08-02T20:43:59.081638",
     "exception": false,
     "start_time": "2021-08-02T20:43:58.998852",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numer of models: 8\n"
     ]
    }
   ],
   "source": [
    "####### LOAD MODEL CONFIGURATIONS\n",
    "\n",
    "import pickle\n",
    "\n",
    "CFGs = []\n",
    "\n",
    "for model in CFG['models']:\n",
    "    \n",
    "    model_CFG = pickle.load(open(model + 'configuration.pkl', 'rb'))  \n",
    "    \n",
    "    if model_CFG['backbone'] == 'albert-large-v2':\n",
    "        model_CFG['backbone'] = '/kaggle/input/transformers/albert-large-v2'  \n",
    "        \n",
    "    elif model_CFG['backbone'] == 'bert-base-uncased':\n",
    "        model_CFG['backbone'] = '/kaggle/input/transformers/bert-base-uncased' \n",
    "        \n",
    "    elif model_CFG['backbone'] == 'bert-large-uncased':\n",
    "        model_CFG['backbone'] = '/kaggle/input/transformers/bert-large-uncased' \n",
    "        \n",
    "    elif model_CFG['backbone'] == 'distilbert-base-uncased':\n",
    "        model_CFG['backbone'] = '/kaggle/input/transformers/distilbert-base-uncased'\n",
    "        \n",
    "    elif model_CFG['backbone'] == 'distilroberta-base':\n",
    "        model_CFG['backbone'] = '/kaggle/input/transformers/distilroberta-base'\n",
    "        \n",
    "    elif model_CFG['backbone'] == 'facebook/bart-base':\n",
    "        model_CFG['backbone'] = '/kaggle/input/transformers/facebook-bart-base'    \n",
    "        \n",
    "    elif model_CFG['backbone'] == 'facebook/bart-large':\n",
    "        model_CFG['backbone'] = '/kaggle/input/transformers/facebook-bart-large'  \n",
    "        \n",
    "    elif model_CFG['backbone'] == 'funnel-transformer/base':\n",
    "        model_CFG['backbone'] = '/kaggle/input/transformers/funnel-transformer-base'    \n",
    "        \n",
    "    elif model_CFG['backbone'] == 'funnel-transformer/large':\n",
    "        model_CFG['backbone'] = '/kaggle/input/transformers/funnel-transformer-large' \n",
    "        \n",
    "    elif model_CFG['backbone'] == 'roberta-base' or model_CFG['backbone'] == '../input/clrp-roberta-base/clrp_roberta_base':\n",
    "        model_CFG['backbone'] = '/kaggle/input/transformers/roberta-base'\n",
    "        \n",
    "    elif model_CFG['backbone'] == 'roberta-large':\n",
    "        model_CFG['backbone'] = '/kaggle/input/transformers/roberta-large'   \n",
    "                \n",
    "    elif model_CFG['backbone'] == 't5-base':\n",
    "        model_CFG['backbone'] = '/kaggle/input/transformers/t5-base'    \n",
    "        \n",
    "    elif model_CFG['backbone'] == 't5-large':\n",
    "        model_CFG['backbone'] = '/kaggle/input/transformers/t5-large' \n",
    "        \n",
    "    elif model_CFG['backbone'] == 'xlnet-base-cased':\n",
    "        model_CFG['backbone'] = '/kaggle/input/transformers/xlnet-base-cased'    \n",
    "        \n",
    "    elif model_CFG['backbone'] == 'xlnet-large-cased':\n",
    "        model_CFG['backbone'] = '/kaggle/input/transformers/xlnet-large-cased'  \n",
    "        \n",
    "        \n",
    "    CFGs.append(model_CFG)\n",
    "    \n",
    "print('Numer of models:', len(CFGs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "508ebf12",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2021-08-02T20:43:59.377447Z",
     "iopub.status.busy": "2021-08-02T20:43:59.174073Z",
     "iopub.status.idle": "2021-08-02T20:56:37.581614Z",
     "shell.execute_reply": "2021-08-02T20:56:37.582027Z",
     "shell.execute_reply.started": "2021-08-02T19:37:56.294725Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "papermill": {
     "duration": 758.460745,
     "end_time": "2021-08-02T20:56:37.582184",
     "exception": false,
     "start_time": "2021-08-02T20:43:59.121439",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a9f25266b6d4db28a16b6b730709cae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at /kaggle/input/transformers/roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at /kaggle/input/transformers/roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at /kaggle/input/transformers/roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at /kaggle/input/transformers/roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at /kaggle/input/transformers/roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at /kaggle/input/transformers/roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at /kaggle/input/transformers/roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at /kaggle/input/transformers/roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at /kaggle/input/transformers/roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at /kaggle/input/transformers/roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at /kaggle/input/transformers/roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at /kaggle/input/transformers/roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at /kaggle/input/transformers/roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at /kaggle/input/transformers/roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at /kaggle/input/transformers/roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at /kaggle/input/transformers/roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at /kaggle/input/transformers/roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at /kaggle/input/transformers/roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at /kaggle/input/transformers/roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at /kaggle/input/transformers/roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at /kaggle/input/transformers/roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at /kaggle/input/transformers/roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at /kaggle/input/transformers/roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at /kaggle/input/transformers/roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at /kaggle/input/transformers/roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at /kaggle/input/transformers/roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at /kaggle/input/transformers/roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at /kaggle/input/transformers/roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at /kaggle/input/transformers/roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at /kaggle/input/transformers/roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at /kaggle/input/transformers/roberta-large were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at /kaggle/input/transformers/roberta-large were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at /kaggle/input/transformers/roberta-large were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at /kaggle/input/transformers/roberta-large were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at /kaggle/input/transformers/roberta-large were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at /kaggle/input/transformers/roberta-large were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at /kaggle/input/transformers/roberta-large were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at /kaggle/input/transformers/roberta-large were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at /kaggle/input/transformers/roberta-large were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at /kaggle/input/transformers/roberta-large were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at /kaggle/input/transformers/roberta-large were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at /kaggle/input/transformers/roberta-large were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at /kaggle/input/transformers/roberta-large were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at /kaggle/input/transformers/roberta-large were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at /kaggle/input/transformers/roberta-large were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at /kaggle/input/transformers/roberta-large were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at /kaggle/input/transformers/roberta-large were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at /kaggle/input/transformers/roberta-large were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at /kaggle/input/transformers/roberta-large were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at /kaggle/input/transformers/roberta-large were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at /kaggle/input/transformers/distilroberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at /kaggle/input/transformers/distilroberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at /kaggle/input/transformers/distilroberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at /kaggle/input/transformers/distilroberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at /kaggle/input/transformers/distilroberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at /kaggle/input/transformers/distilroberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at /kaggle/input/transformers/distilroberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at /kaggle/input/transformers/distilroberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at /kaggle/input/transformers/distilroberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at /kaggle/input/transformers/distilroberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at /kaggle/input/transformers/bert-base-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at /kaggle/input/transformers/bert-base-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at /kaggle/input/transformers/bert-base-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at /kaggle/input/transformers/bert-base-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at /kaggle/input/transformers/bert-base-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at /kaggle/input/transformers/bert-base-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at /kaggle/input/transformers/bert-base-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at /kaggle/input/transformers/bert-base-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at /kaggle/input/transformers/bert-base-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at /kaggle/input/transformers/bert-base-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at /kaggle/input/transformers/distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_transform.bias', 'vocab_transform.weight', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at /kaggle/input/transformers/distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_transform.bias', 'vocab_transform.weight', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at /kaggle/input/transformers/distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_transform.bias', 'vocab_transform.weight', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at /kaggle/input/transformers/distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_transform.bias', 'vocab_transform.weight', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at /kaggle/input/transformers/distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_transform.bias', 'vocab_transform.weight', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at /kaggle/input/transformers/distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_transform.bias', 'vocab_transform.weight', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at /kaggle/input/transformers/distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_transform.bias', 'vocab_transform.weight', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at /kaggle/input/transformers/distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_transform.bias', 'vocab_transform.weight', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at /kaggle/input/transformers/distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_transform.bias', 'vocab_transform.weight', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at /kaggle/input/transformers/distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_transform.bias', 'vocab_transform.weight', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished 80 preds in 12.64 mins\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>../input/readability-training-v56/rep0_fold0</th>\n",
       "      <th>../input/readability-training-v56/rep0_fold1</th>\n",
       "      <th>../input/readability-training-v56/rep0_fold2</th>\n",
       "      <th>../input/readability-training-v56/rep0_fold3</th>\n",
       "      <th>../input/readability-training-v56/rep0_fold4</th>\n",
       "      <th>../input/readability-training-v56/rep1_fold0</th>\n",
       "      <th>../input/readability-training-v56/rep1_fold1</th>\n",
       "      <th>../input/readability-training-v56/rep1_fold2</th>\n",
       "      <th>../input/readability-training-v56/rep1_fold3</th>\n",
       "      <th>../input/readability-training-v56/rep1_fold4</th>\n",
       "      <th>../input/readability-training-v55/rep0_fold0</th>\n",
       "      <th>../input/readability-training-v55/rep0_fold1</th>\n",
       "      <th>../input/readability-training-v55/rep0_fold2</th>\n",
       "      <th>../input/readability-training-v55/rep0_fold3</th>\n",
       "      <th>../input/readability-training-v55/rep0_fold4</th>\n",
       "      <th>../input/readability-training-v55/rep1_fold0</th>\n",
       "      <th>../input/readability-training-v55/rep1_fold1</th>\n",
       "      <th>../input/readability-training-v55/rep1_fold2</th>\n",
       "      <th>../input/readability-training-v55/rep1_fold3</th>\n",
       "      <th>../input/readability-training-v55/rep1_fold4</th>\n",
       "      <th>../input/readability-training-v52/rep0_fold0</th>\n",
       "      <th>../input/readability-training-v52/rep0_fold1</th>\n",
       "      <th>../input/readability-training-v52/rep0_fold2</th>\n",
       "      <th>../input/readability-training-v52/rep0_fold3</th>\n",
       "      <th>../input/readability-training-v52/rep0_fold4</th>\n",
       "      <th>../input/readability-training-v52/rep1_fold0</th>\n",
       "      <th>../input/readability-training-v52/rep1_fold1</th>\n",
       "      <th>../input/readability-training-v52/rep1_fold2</th>\n",
       "      <th>../input/readability-training-v52/rep1_fold3</th>\n",
       "      <th>../input/readability-training-v52/rep1_fold4</th>\n",
       "      <th>../input/readability-v62/rep0_fold0</th>\n",
       "      <th>../input/readability-v62/rep0_fold1</th>\n",
       "      <th>../input/readability-v62/rep0_fold2</th>\n",
       "      <th>../input/readability-v62/rep0_fold3</th>\n",
       "      <th>../input/readability-v62/rep0_fold4</th>\n",
       "      <th>../input/readability-v62/rep1_fold0</th>\n",
       "      <th>../input/readability-v62/rep1_fold1</th>\n",
       "      <th>../input/readability-v62/rep1_fold2</th>\n",
       "      <th>../input/readability-v62/rep1_fold3</th>\n",
       "      <th>../input/readability-v62/rep1_fold4</th>\n",
       "      <th>../input/readability-v36/rep0_fold0</th>\n",
       "      <th>../input/readability-v36/rep0_fold1</th>\n",
       "      <th>../input/readability-v36/rep0_fold2</th>\n",
       "      <th>../input/readability-v36/rep0_fold3</th>\n",
       "      <th>../input/readability-v36/rep0_fold4</th>\n",
       "      <th>../input/readability-v36/rep1_fold0</th>\n",
       "      <th>../input/readability-v36/rep1_fold1</th>\n",
       "      <th>../input/readability-v36/rep1_fold2</th>\n",
       "      <th>../input/readability-v36/rep1_fold3</th>\n",
       "      <th>../input/readability-v36/rep1_fold4</th>\n",
       "      <th>../input/readability-v47/rep0_fold0</th>\n",
       "      <th>../input/readability-v47/rep0_fold1</th>\n",
       "      <th>../input/readability-v47/rep0_fold2</th>\n",
       "      <th>../input/readability-v47/rep0_fold3</th>\n",
       "      <th>../input/readability-v47/rep0_fold4</th>\n",
       "      <th>../input/readability-v47/rep1_fold0</th>\n",
       "      <th>../input/readability-v47/rep1_fold1</th>\n",
       "      <th>../input/readability-v47/rep1_fold2</th>\n",
       "      <th>../input/readability-v47/rep1_fold3</th>\n",
       "      <th>../input/readability-v47/rep1_fold4</th>\n",
       "      <th>../input/readability-v69/rep0_fold0</th>\n",
       "      <th>../input/readability-v69/rep0_fold1</th>\n",
       "      <th>../input/readability-v69/rep0_fold2</th>\n",
       "      <th>../input/readability-v69/rep0_fold3</th>\n",
       "      <th>../input/readability-v69/rep0_fold4</th>\n",
       "      <th>../input/readability-v69/rep1_fold0</th>\n",
       "      <th>../input/readability-v69/rep1_fold1</th>\n",
       "      <th>../input/readability-v69/rep1_fold2</th>\n",
       "      <th>../input/readability-v69/rep1_fold3</th>\n",
       "      <th>../input/readability-v69/rep1_fold4</th>\n",
       "      <th>../input/readability-training-v59/rep0_fold0</th>\n",
       "      <th>../input/readability-training-v59/rep0_fold1</th>\n",
       "      <th>../input/readability-training-v59/rep0_fold2</th>\n",
       "      <th>../input/readability-training-v59/rep0_fold3</th>\n",
       "      <th>../input/readability-training-v59/rep0_fold4</th>\n",
       "      <th>../input/readability-training-v59/rep1_fold0</th>\n",
       "      <th>../input/readability-training-v59/rep1_fold1</th>\n",
       "      <th>../input/readability-training-v59/rep1_fold2</th>\n",
       "      <th>../input/readability-training-v59/rep1_fold3</th>\n",
       "      <th>../input/readability-training-v59/rep1_fold4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.326416</td>\n",
       "      <td>-0.580566</td>\n",
       "      <td>-0.300537</td>\n",
       "      <td>-0.472412</td>\n",
       "      <td>-0.316895</td>\n",
       "      <td>-0.630371</td>\n",
       "      <td>-0.528320</td>\n",
       "      <td>-0.325684</td>\n",
       "      <td>-0.364258</td>\n",
       "      <td>-0.224731</td>\n",
       "      <td>-0.330322</td>\n",
       "      <td>-0.605469</td>\n",
       "      <td>-0.522461</td>\n",
       "      <td>-0.418701</td>\n",
       "      <td>-0.295166</td>\n",
       "      <td>-0.383301</td>\n",
       "      <td>-0.569336</td>\n",
       "      <td>-0.391846</td>\n",
       "      <td>-0.332031</td>\n",
       "      <td>-0.332520</td>\n",
       "      <td>-0.520508</td>\n",
       "      <td>-0.510254</td>\n",
       "      <td>-0.383301</td>\n",
       "      <td>-0.338135</td>\n",
       "      <td>-0.260986</td>\n",
       "      <td>-0.383057</td>\n",
       "      <td>-0.681152</td>\n",
       "      <td>-0.522949</td>\n",
       "      <td>-0.420166</td>\n",
       "      <td>-0.267578</td>\n",
       "      <td>-0.541016</td>\n",
       "      <td>-0.475586</td>\n",
       "      <td>-0.411377</td>\n",
       "      <td>-0.412598</td>\n",
       "      <td>-0.290527</td>\n",
       "      <td>-0.684570</td>\n",
       "      <td>-0.377441</td>\n",
       "      <td>-0.521484</td>\n",
       "      <td>-0.196045</td>\n",
       "      <td>-0.263428</td>\n",
       "      <td>-0.188965</td>\n",
       "      <td>-0.347656</td>\n",
       "      <td>-0.534668</td>\n",
       "      <td>-0.338623</td>\n",
       "      <td>-0.337891</td>\n",
       "      <td>-0.418457</td>\n",
       "      <td>-0.485107</td>\n",
       "      <td>-0.386963</td>\n",
       "      <td>-0.279785</td>\n",
       "      <td>-0.316162</td>\n",
       "      <td>-0.751465</td>\n",
       "      <td>-0.613281</td>\n",
       "      <td>-0.615234</td>\n",
       "      <td>-0.567383</td>\n",
       "      <td>-0.595215</td>\n",
       "      <td>-0.230591</td>\n",
       "      <td>-0.675293</td>\n",
       "      <td>-0.700684</td>\n",
       "      <td>-0.457275</td>\n",
       "      <td>-0.491455</td>\n",
       "      <td>-0.290039</td>\n",
       "      <td>-0.467285</td>\n",
       "      <td>-0.242065</td>\n",
       "      <td>-0.266113</td>\n",
       "      <td>-0.374268</td>\n",
       "      <td>-0.218140</td>\n",
       "      <td>-0.379395</td>\n",
       "      <td>-0.385498</td>\n",
       "      <td>-0.366211</td>\n",
       "      <td>-0.371094</td>\n",
       "      <td>-0.124634</td>\n",
       "      <td>-0.459961</td>\n",
       "      <td>-0.415283</td>\n",
       "      <td>-0.208984</td>\n",
       "      <td>-0.205811</td>\n",
       "      <td>-0.335938</td>\n",
       "      <td>-0.325684</td>\n",
       "      <td>-0.260742</td>\n",
       "      <td>-0.366699</td>\n",
       "      <td>-0.431396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.854004</td>\n",
       "      <td>-0.599121</td>\n",
       "      <td>-0.837891</td>\n",
       "      <td>-0.812012</td>\n",
       "      <td>-0.798340</td>\n",
       "      <td>-0.900879</td>\n",
       "      <td>-0.619141</td>\n",
       "      <td>-0.753906</td>\n",
       "      <td>-0.704590</td>\n",
       "      <td>-0.870605</td>\n",
       "      <td>-0.672852</td>\n",
       "      <td>-0.750000</td>\n",
       "      <td>-0.702637</td>\n",
       "      <td>-0.572754</td>\n",
       "      <td>-0.631836</td>\n",
       "      <td>-0.645508</td>\n",
       "      <td>-0.457520</td>\n",
       "      <td>-0.658203</td>\n",
       "      <td>-0.754883</td>\n",
       "      <td>-0.657227</td>\n",
       "      <td>-0.654297</td>\n",
       "      <td>-0.446045</td>\n",
       "      <td>-0.652832</td>\n",
       "      <td>-0.666504</td>\n",
       "      <td>-0.776855</td>\n",
       "      <td>-0.639160</td>\n",
       "      <td>-0.677734</td>\n",
       "      <td>-0.906250</td>\n",
       "      <td>-0.552246</td>\n",
       "      <td>-0.596191</td>\n",
       "      <td>-0.439453</td>\n",
       "      <td>-0.501465</td>\n",
       "      <td>-0.336426</td>\n",
       "      <td>-0.459961</td>\n",
       "      <td>-0.219360</td>\n",
       "      <td>-0.524414</td>\n",
       "      <td>-0.217285</td>\n",
       "      <td>-0.386230</td>\n",
       "      <td>-0.429443</td>\n",
       "      <td>-0.548340</td>\n",
       "      <td>-0.375488</td>\n",
       "      <td>-0.396240</td>\n",
       "      <td>-0.723633</td>\n",
       "      <td>-0.406250</td>\n",
       "      <td>-0.315918</td>\n",
       "      <td>-0.381104</td>\n",
       "      <td>-0.586914</td>\n",
       "      <td>-0.437256</td>\n",
       "      <td>-0.545410</td>\n",
       "      <td>-0.361328</td>\n",
       "      <td>-0.556152</td>\n",
       "      <td>-0.641602</td>\n",
       "      <td>-0.759277</td>\n",
       "      <td>-0.840820</td>\n",
       "      <td>-0.823730</td>\n",
       "      <td>-0.697266</td>\n",
       "      <td>-0.735352</td>\n",
       "      <td>-0.685059</td>\n",
       "      <td>-0.793457</td>\n",
       "      <td>-0.624023</td>\n",
       "      <td>-0.527832</td>\n",
       "      <td>-0.325928</td>\n",
       "      <td>-0.274414</td>\n",
       "      <td>-0.211304</td>\n",
       "      <td>-0.255371</td>\n",
       "      <td>-0.396729</td>\n",
       "      <td>-0.156982</td>\n",
       "      <td>-0.280518</td>\n",
       "      <td>-0.412842</td>\n",
       "      <td>-0.177246</td>\n",
       "      <td>-0.512207</td>\n",
       "      <td>-0.403076</td>\n",
       "      <td>-0.495361</td>\n",
       "      <td>-0.542480</td>\n",
       "      <td>-0.434082</td>\n",
       "      <td>-0.565430</td>\n",
       "      <td>-0.450195</td>\n",
       "      <td>-0.495117</td>\n",
       "      <td>-0.514160</td>\n",
       "      <td>-0.512695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.468994</td>\n",
       "      <td>-0.345459</td>\n",
       "      <td>-0.533691</td>\n",
       "      <td>-0.325928</td>\n",
       "      <td>-0.242554</td>\n",
       "      <td>-0.462158</td>\n",
       "      <td>-0.435059</td>\n",
       "      <td>-0.441162</td>\n",
       "      <td>-0.457764</td>\n",
       "      <td>-0.279785</td>\n",
       "      <td>-0.578613</td>\n",
       "      <td>-0.238403</td>\n",
       "      <td>-0.438721</td>\n",
       "      <td>-0.283447</td>\n",
       "      <td>-0.538574</td>\n",
       "      <td>-0.556641</td>\n",
       "      <td>-0.354736</td>\n",
       "      <td>-0.572266</td>\n",
       "      <td>-0.308594</td>\n",
       "      <td>-0.368896</td>\n",
       "      <td>-0.363770</td>\n",
       "      <td>-0.431152</td>\n",
       "      <td>-0.588867</td>\n",
       "      <td>-0.521484</td>\n",
       "      <td>-0.408203</td>\n",
       "      <td>-0.608887</td>\n",
       "      <td>-0.414062</td>\n",
       "      <td>-0.456787</td>\n",
       "      <td>-0.276123</td>\n",
       "      <td>-0.464111</td>\n",
       "      <td>-0.521484</td>\n",
       "      <td>-0.363281</td>\n",
       "      <td>-0.450439</td>\n",
       "      <td>-0.615234</td>\n",
       "      <td>-0.219360</td>\n",
       "      <td>-0.324951</td>\n",
       "      <td>-0.436279</td>\n",
       "      <td>-0.321045</td>\n",
       "      <td>-0.404053</td>\n",
       "      <td>-0.501953</td>\n",
       "      <td>-0.381836</td>\n",
       "      <td>-0.382812</td>\n",
       "      <td>-0.527344</td>\n",
       "      <td>-0.346680</td>\n",
       "      <td>-0.361084</td>\n",
       "      <td>-0.511230</td>\n",
       "      <td>-0.552734</td>\n",
       "      <td>-0.430176</td>\n",
       "      <td>-0.277832</td>\n",
       "      <td>-0.360352</td>\n",
       "      <td>-0.357178</td>\n",
       "      <td>-0.625000</td>\n",
       "      <td>-0.240967</td>\n",
       "      <td>-0.416748</td>\n",
       "      <td>-0.465088</td>\n",
       "      <td>-0.320801</td>\n",
       "      <td>-0.441406</td>\n",
       "      <td>-0.316406</td>\n",
       "      <td>-0.303711</td>\n",
       "      <td>-0.275879</td>\n",
       "      <td>-0.506836</td>\n",
       "      <td>-0.390381</td>\n",
       "      <td>-0.401367</td>\n",
       "      <td>-0.306152</td>\n",
       "      <td>-0.287598</td>\n",
       "      <td>-0.252930</td>\n",
       "      <td>-0.454102</td>\n",
       "      <td>-0.473145</td>\n",
       "      <td>-0.371582</td>\n",
       "      <td>-0.299805</td>\n",
       "      <td>-0.348145</td>\n",
       "      <td>-0.341553</td>\n",
       "      <td>-0.244141</td>\n",
       "      <td>-0.207886</td>\n",
       "      <td>-0.432373</td>\n",
       "      <td>-0.490234</td>\n",
       "      <td>-0.299805</td>\n",
       "      <td>-0.550293</td>\n",
       "      <td>-0.417236</td>\n",
       "      <td>-0.318848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-2.324219</td>\n",
       "      <td>-2.503906</td>\n",
       "      <td>-2.601562</td>\n",
       "      <td>-2.449219</td>\n",
       "      <td>-2.615234</td>\n",
       "      <td>-2.552734</td>\n",
       "      <td>-2.496094</td>\n",
       "      <td>-2.394531</td>\n",
       "      <td>-2.572266</td>\n",
       "      <td>-2.453125</td>\n",
       "      <td>-2.308594</td>\n",
       "      <td>-2.250000</td>\n",
       "      <td>-2.527344</td>\n",
       "      <td>-2.597656</td>\n",
       "      <td>-2.494141</td>\n",
       "      <td>-2.328125</td>\n",
       "      <td>-2.562500</td>\n",
       "      <td>-2.613281</td>\n",
       "      <td>-2.597656</td>\n",
       "      <td>-2.609375</td>\n",
       "      <td>-2.466797</td>\n",
       "      <td>-2.634766</td>\n",
       "      <td>-2.400391</td>\n",
       "      <td>-2.343750</td>\n",
       "      <td>-2.482422</td>\n",
       "      <td>-2.375000</td>\n",
       "      <td>-2.326172</td>\n",
       "      <td>-2.447266</td>\n",
       "      <td>-2.593750</td>\n",
       "      <td>-2.523438</td>\n",
       "      <td>-2.251953</td>\n",
       "      <td>-2.248047</td>\n",
       "      <td>-2.404297</td>\n",
       "      <td>-2.173828</td>\n",
       "      <td>-2.248047</td>\n",
       "      <td>-2.173828</td>\n",
       "      <td>-2.236328</td>\n",
       "      <td>-2.298828</td>\n",
       "      <td>-2.179688</td>\n",
       "      <td>-2.197266</td>\n",
       "      <td>-2.216797</td>\n",
       "      <td>-2.328125</td>\n",
       "      <td>-2.066406</td>\n",
       "      <td>-2.101562</td>\n",
       "      <td>-2.355469</td>\n",
       "      <td>-2.347656</td>\n",
       "      <td>-2.433594</td>\n",
       "      <td>-2.394531</td>\n",
       "      <td>-2.181641</td>\n",
       "      <td>-2.369141</td>\n",
       "      <td>-2.486328</td>\n",
       "      <td>-2.730469</td>\n",
       "      <td>-2.662109</td>\n",
       "      <td>-2.482422</td>\n",
       "      <td>-2.339844</td>\n",
       "      <td>-2.273438</td>\n",
       "      <td>-2.460938</td>\n",
       "      <td>-2.601562</td>\n",
       "      <td>-2.468750</td>\n",
       "      <td>-2.566406</td>\n",
       "      <td>-2.234375</td>\n",
       "      <td>-2.099609</td>\n",
       "      <td>-2.251953</td>\n",
       "      <td>-2.322266</td>\n",
       "      <td>-1.887695</td>\n",
       "      <td>-2.294922</td>\n",
       "      <td>-2.296875</td>\n",
       "      <td>-1.958984</td>\n",
       "      <td>-2.220703</td>\n",
       "      <td>-2.025391</td>\n",
       "      <td>-2.261719</td>\n",
       "      <td>-2.529297</td>\n",
       "      <td>-2.466797</td>\n",
       "      <td>-2.521484</td>\n",
       "      <td>-2.712891</td>\n",
       "      <td>-2.392578</td>\n",
       "      <td>-2.349609</td>\n",
       "      <td>-2.703125</td>\n",
       "      <td>-2.769531</td>\n",
       "      <td>-2.630859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.740234</td>\n",
       "      <td>-1.839844</td>\n",
       "      <td>-1.711914</td>\n",
       "      <td>-1.398438</td>\n",
       "      <td>-1.758789</td>\n",
       "      <td>-1.740234</td>\n",
       "      <td>-1.703125</td>\n",
       "      <td>-1.693359</td>\n",
       "      <td>-1.897461</td>\n",
       "      <td>-1.784180</td>\n",
       "      <td>-1.621094</td>\n",
       "      <td>-1.761719</td>\n",
       "      <td>-1.763672</td>\n",
       "      <td>-1.886719</td>\n",
       "      <td>-1.869141</td>\n",
       "      <td>-1.803711</td>\n",
       "      <td>-1.864258</td>\n",
       "      <td>-1.810547</td>\n",
       "      <td>-1.554688</td>\n",
       "      <td>-1.860352</td>\n",
       "      <td>-1.758789</td>\n",
       "      <td>-1.694336</td>\n",
       "      <td>-1.729492</td>\n",
       "      <td>-1.776367</td>\n",
       "      <td>-1.859375</td>\n",
       "      <td>-1.643555</td>\n",
       "      <td>-1.685547</td>\n",
       "      <td>-1.851562</td>\n",
       "      <td>-1.861328</td>\n",
       "      <td>-1.840820</td>\n",
       "      <td>-1.988281</td>\n",
       "      <td>-1.861328</td>\n",
       "      <td>-1.854492</td>\n",
       "      <td>-1.677734</td>\n",
       "      <td>-1.937500</td>\n",
       "      <td>-1.947266</td>\n",
       "      <td>-1.646484</td>\n",
       "      <td>-1.878906</td>\n",
       "      <td>-1.823242</td>\n",
       "      <td>-1.967773</td>\n",
       "      <td>-1.808594</td>\n",
       "      <td>-1.867188</td>\n",
       "      <td>-1.858398</td>\n",
       "      <td>-1.735352</td>\n",
       "      <td>-2.041016</td>\n",
       "      <td>-2.044922</td>\n",
       "      <td>-1.871094</td>\n",
       "      <td>-2.078125</td>\n",
       "      <td>-1.648438</td>\n",
       "      <td>-1.864258</td>\n",
       "      <td>-1.949219</td>\n",
       "      <td>-1.829102</td>\n",
       "      <td>-1.635742</td>\n",
       "      <td>-1.857422</td>\n",
       "      <td>-1.775391</td>\n",
       "      <td>-1.786133</td>\n",
       "      <td>-1.786133</td>\n",
       "      <td>-1.872070</td>\n",
       "      <td>-1.747070</td>\n",
       "      <td>-1.643555</td>\n",
       "      <td>-1.963867</td>\n",
       "      <td>-1.979492</td>\n",
       "      <td>-1.806641</td>\n",
       "      <td>-1.700195</td>\n",
       "      <td>-1.768555</td>\n",
       "      <td>-1.895508</td>\n",
       "      <td>-1.973633</td>\n",
       "      <td>-1.772461</td>\n",
       "      <td>-1.848633</td>\n",
       "      <td>-1.695312</td>\n",
       "      <td>-1.757812</td>\n",
       "      <td>-1.772461</td>\n",
       "      <td>-1.862305</td>\n",
       "      <td>-1.855469</td>\n",
       "      <td>-1.975586</td>\n",
       "      <td>-2.017578</td>\n",
       "      <td>-1.897461</td>\n",
       "      <td>-1.906250</td>\n",
       "      <td>-1.729492</td>\n",
       "      <td>-1.938477</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ../input/readability-training-v56/rep0_fold0  \\\n",
       "0                                     -0.326416   \n",
       "1                                     -0.854004   \n",
       "2                                     -0.468994   \n",
       "3                                     -2.324219   \n",
       "4                                     -1.740234   \n",
       "\n",
       "   ../input/readability-training-v56/rep0_fold1  \\\n",
       "0                                     -0.580566   \n",
       "1                                     -0.599121   \n",
       "2                                     -0.345459   \n",
       "3                                     -2.503906   \n",
       "4                                     -1.839844   \n",
       "\n",
       "   ../input/readability-training-v56/rep0_fold2  \\\n",
       "0                                     -0.300537   \n",
       "1                                     -0.837891   \n",
       "2                                     -0.533691   \n",
       "3                                     -2.601562   \n",
       "4                                     -1.711914   \n",
       "\n",
       "   ../input/readability-training-v56/rep0_fold3  \\\n",
       "0                                     -0.472412   \n",
       "1                                     -0.812012   \n",
       "2                                     -0.325928   \n",
       "3                                     -2.449219   \n",
       "4                                     -1.398438   \n",
       "\n",
       "   ../input/readability-training-v56/rep0_fold4  \\\n",
       "0                                     -0.316895   \n",
       "1                                     -0.798340   \n",
       "2                                     -0.242554   \n",
       "3                                     -2.615234   \n",
       "4                                     -1.758789   \n",
       "\n",
       "   ../input/readability-training-v56/rep1_fold0  \\\n",
       "0                                     -0.630371   \n",
       "1                                     -0.900879   \n",
       "2                                     -0.462158   \n",
       "3                                     -2.552734   \n",
       "4                                     -1.740234   \n",
       "\n",
       "   ../input/readability-training-v56/rep1_fold1  \\\n",
       "0                                     -0.528320   \n",
       "1                                     -0.619141   \n",
       "2                                     -0.435059   \n",
       "3                                     -2.496094   \n",
       "4                                     -1.703125   \n",
       "\n",
       "   ../input/readability-training-v56/rep1_fold2  \\\n",
       "0                                     -0.325684   \n",
       "1                                     -0.753906   \n",
       "2                                     -0.441162   \n",
       "3                                     -2.394531   \n",
       "4                                     -1.693359   \n",
       "\n",
       "   ../input/readability-training-v56/rep1_fold3  \\\n",
       "0                                     -0.364258   \n",
       "1                                     -0.704590   \n",
       "2                                     -0.457764   \n",
       "3                                     -2.572266   \n",
       "4                                     -1.897461   \n",
       "\n",
       "   ../input/readability-training-v56/rep1_fold4  \\\n",
       "0                                     -0.224731   \n",
       "1                                     -0.870605   \n",
       "2                                     -0.279785   \n",
       "3                                     -2.453125   \n",
       "4                                     -1.784180   \n",
       "\n",
       "   ../input/readability-training-v55/rep0_fold0  \\\n",
       "0                                     -0.330322   \n",
       "1                                     -0.672852   \n",
       "2                                     -0.578613   \n",
       "3                                     -2.308594   \n",
       "4                                     -1.621094   \n",
       "\n",
       "   ../input/readability-training-v55/rep0_fold1  \\\n",
       "0                                     -0.605469   \n",
       "1                                     -0.750000   \n",
       "2                                     -0.238403   \n",
       "3                                     -2.250000   \n",
       "4                                     -1.761719   \n",
       "\n",
       "   ../input/readability-training-v55/rep0_fold2  \\\n",
       "0                                     -0.522461   \n",
       "1                                     -0.702637   \n",
       "2                                     -0.438721   \n",
       "3                                     -2.527344   \n",
       "4                                     -1.763672   \n",
       "\n",
       "   ../input/readability-training-v55/rep0_fold3  \\\n",
       "0                                     -0.418701   \n",
       "1                                     -0.572754   \n",
       "2                                     -0.283447   \n",
       "3                                     -2.597656   \n",
       "4                                     -1.886719   \n",
       "\n",
       "   ../input/readability-training-v55/rep0_fold4  \\\n",
       "0                                     -0.295166   \n",
       "1                                     -0.631836   \n",
       "2                                     -0.538574   \n",
       "3                                     -2.494141   \n",
       "4                                     -1.869141   \n",
       "\n",
       "   ../input/readability-training-v55/rep1_fold0  \\\n",
       "0                                     -0.383301   \n",
       "1                                     -0.645508   \n",
       "2                                     -0.556641   \n",
       "3                                     -2.328125   \n",
       "4                                     -1.803711   \n",
       "\n",
       "   ../input/readability-training-v55/rep1_fold1  \\\n",
       "0                                     -0.569336   \n",
       "1                                     -0.457520   \n",
       "2                                     -0.354736   \n",
       "3                                     -2.562500   \n",
       "4                                     -1.864258   \n",
       "\n",
       "   ../input/readability-training-v55/rep1_fold2  \\\n",
       "0                                     -0.391846   \n",
       "1                                     -0.658203   \n",
       "2                                     -0.572266   \n",
       "3                                     -2.613281   \n",
       "4                                     -1.810547   \n",
       "\n",
       "   ../input/readability-training-v55/rep1_fold3  \\\n",
       "0                                     -0.332031   \n",
       "1                                     -0.754883   \n",
       "2                                     -0.308594   \n",
       "3                                     -2.597656   \n",
       "4                                     -1.554688   \n",
       "\n",
       "   ../input/readability-training-v55/rep1_fold4  \\\n",
       "0                                     -0.332520   \n",
       "1                                     -0.657227   \n",
       "2                                     -0.368896   \n",
       "3                                     -2.609375   \n",
       "4                                     -1.860352   \n",
       "\n",
       "   ../input/readability-training-v52/rep0_fold0  \\\n",
       "0                                     -0.520508   \n",
       "1                                     -0.654297   \n",
       "2                                     -0.363770   \n",
       "3                                     -2.466797   \n",
       "4                                     -1.758789   \n",
       "\n",
       "   ../input/readability-training-v52/rep0_fold1  \\\n",
       "0                                     -0.510254   \n",
       "1                                     -0.446045   \n",
       "2                                     -0.431152   \n",
       "3                                     -2.634766   \n",
       "4                                     -1.694336   \n",
       "\n",
       "   ../input/readability-training-v52/rep0_fold2  \\\n",
       "0                                     -0.383301   \n",
       "1                                     -0.652832   \n",
       "2                                     -0.588867   \n",
       "3                                     -2.400391   \n",
       "4                                     -1.729492   \n",
       "\n",
       "   ../input/readability-training-v52/rep0_fold3  \\\n",
       "0                                     -0.338135   \n",
       "1                                     -0.666504   \n",
       "2                                     -0.521484   \n",
       "3                                     -2.343750   \n",
       "4                                     -1.776367   \n",
       "\n",
       "   ../input/readability-training-v52/rep0_fold4  \\\n",
       "0                                     -0.260986   \n",
       "1                                     -0.776855   \n",
       "2                                     -0.408203   \n",
       "3                                     -2.482422   \n",
       "4                                     -1.859375   \n",
       "\n",
       "   ../input/readability-training-v52/rep1_fold0  \\\n",
       "0                                     -0.383057   \n",
       "1                                     -0.639160   \n",
       "2                                     -0.608887   \n",
       "3                                     -2.375000   \n",
       "4                                     -1.643555   \n",
       "\n",
       "   ../input/readability-training-v52/rep1_fold1  \\\n",
       "0                                     -0.681152   \n",
       "1                                     -0.677734   \n",
       "2                                     -0.414062   \n",
       "3                                     -2.326172   \n",
       "4                                     -1.685547   \n",
       "\n",
       "   ../input/readability-training-v52/rep1_fold2  \\\n",
       "0                                     -0.522949   \n",
       "1                                     -0.906250   \n",
       "2                                     -0.456787   \n",
       "3                                     -2.447266   \n",
       "4                                     -1.851562   \n",
       "\n",
       "   ../input/readability-training-v52/rep1_fold3  \\\n",
       "0                                     -0.420166   \n",
       "1                                     -0.552246   \n",
       "2                                     -0.276123   \n",
       "3                                     -2.593750   \n",
       "4                                     -1.861328   \n",
       "\n",
       "   ../input/readability-training-v52/rep1_fold4  \\\n",
       "0                                     -0.267578   \n",
       "1                                     -0.596191   \n",
       "2                                     -0.464111   \n",
       "3                                     -2.523438   \n",
       "4                                     -1.840820   \n",
       "\n",
       "   ../input/readability-v62/rep0_fold0  ../input/readability-v62/rep0_fold1  \\\n",
       "0                            -0.541016                            -0.475586   \n",
       "1                            -0.439453                            -0.501465   \n",
       "2                            -0.521484                            -0.363281   \n",
       "3                            -2.251953                            -2.248047   \n",
       "4                            -1.988281                            -1.861328   \n",
       "\n",
       "   ../input/readability-v62/rep0_fold2  ../input/readability-v62/rep0_fold3  \\\n",
       "0                            -0.411377                            -0.412598   \n",
       "1                            -0.336426                            -0.459961   \n",
       "2                            -0.450439                            -0.615234   \n",
       "3                            -2.404297                            -2.173828   \n",
       "4                            -1.854492                            -1.677734   \n",
       "\n",
       "   ../input/readability-v62/rep0_fold4  ../input/readability-v62/rep1_fold0  \\\n",
       "0                            -0.290527                            -0.684570   \n",
       "1                            -0.219360                            -0.524414   \n",
       "2                            -0.219360                            -0.324951   \n",
       "3                            -2.248047                            -2.173828   \n",
       "4                            -1.937500                            -1.947266   \n",
       "\n",
       "   ../input/readability-v62/rep1_fold1  ../input/readability-v62/rep1_fold2  \\\n",
       "0                            -0.377441                            -0.521484   \n",
       "1                            -0.217285                            -0.386230   \n",
       "2                            -0.436279                            -0.321045   \n",
       "3                            -2.236328                            -2.298828   \n",
       "4                            -1.646484                            -1.878906   \n",
       "\n",
       "   ../input/readability-v62/rep1_fold3  ../input/readability-v62/rep1_fold4  \\\n",
       "0                            -0.196045                            -0.263428   \n",
       "1                            -0.429443                            -0.548340   \n",
       "2                            -0.404053                            -0.501953   \n",
       "3                            -2.179688                            -2.197266   \n",
       "4                            -1.823242                            -1.967773   \n",
       "\n",
       "   ../input/readability-v36/rep0_fold0  ../input/readability-v36/rep0_fold1  \\\n",
       "0                            -0.188965                            -0.347656   \n",
       "1                            -0.375488                            -0.396240   \n",
       "2                            -0.381836                            -0.382812   \n",
       "3                            -2.216797                            -2.328125   \n",
       "4                            -1.808594                            -1.867188   \n",
       "\n",
       "   ../input/readability-v36/rep0_fold2  ../input/readability-v36/rep0_fold3  \\\n",
       "0                            -0.534668                            -0.338623   \n",
       "1                            -0.723633                            -0.406250   \n",
       "2                            -0.527344                            -0.346680   \n",
       "3                            -2.066406                            -2.101562   \n",
       "4                            -1.858398                            -1.735352   \n",
       "\n",
       "   ../input/readability-v36/rep0_fold4  ../input/readability-v36/rep1_fold0  \\\n",
       "0                            -0.337891                            -0.418457   \n",
       "1                            -0.315918                            -0.381104   \n",
       "2                            -0.361084                            -0.511230   \n",
       "3                            -2.355469                            -2.347656   \n",
       "4                            -2.041016                            -2.044922   \n",
       "\n",
       "   ../input/readability-v36/rep1_fold1  ../input/readability-v36/rep1_fold2  \\\n",
       "0                            -0.485107                            -0.386963   \n",
       "1                            -0.586914                            -0.437256   \n",
       "2                            -0.552734                            -0.430176   \n",
       "3                            -2.433594                            -2.394531   \n",
       "4                            -1.871094                            -2.078125   \n",
       "\n",
       "   ../input/readability-v36/rep1_fold3  ../input/readability-v36/rep1_fold4  \\\n",
       "0                            -0.279785                            -0.316162   \n",
       "1                            -0.545410                            -0.361328   \n",
       "2                            -0.277832                            -0.360352   \n",
       "3                            -2.181641                            -2.369141   \n",
       "4                            -1.648438                            -1.864258   \n",
       "\n",
       "   ../input/readability-v47/rep0_fold0  ../input/readability-v47/rep0_fold1  \\\n",
       "0                            -0.751465                            -0.613281   \n",
       "1                            -0.556152                            -0.641602   \n",
       "2                            -0.357178                            -0.625000   \n",
       "3                            -2.486328                            -2.730469   \n",
       "4                            -1.949219                            -1.829102   \n",
       "\n",
       "   ../input/readability-v47/rep0_fold2  ../input/readability-v47/rep0_fold3  \\\n",
       "0                            -0.615234                            -0.567383   \n",
       "1                            -0.759277                            -0.840820   \n",
       "2                            -0.240967                            -0.416748   \n",
       "3                            -2.662109                            -2.482422   \n",
       "4                            -1.635742                            -1.857422   \n",
       "\n",
       "   ../input/readability-v47/rep0_fold4  ../input/readability-v47/rep1_fold0  \\\n",
       "0                            -0.595215                            -0.230591   \n",
       "1                            -0.823730                            -0.697266   \n",
       "2                            -0.465088                            -0.320801   \n",
       "3                            -2.339844                            -2.273438   \n",
       "4                            -1.775391                            -1.786133   \n",
       "\n",
       "   ../input/readability-v47/rep1_fold1  ../input/readability-v47/rep1_fold2  \\\n",
       "0                            -0.675293                            -0.700684   \n",
       "1                            -0.735352                            -0.685059   \n",
       "2                            -0.441406                            -0.316406   \n",
       "3                            -2.460938                            -2.601562   \n",
       "4                            -1.786133                            -1.872070   \n",
       "\n",
       "   ../input/readability-v47/rep1_fold3  ../input/readability-v47/rep1_fold4  \\\n",
       "0                            -0.457275                            -0.491455   \n",
       "1                            -0.793457                            -0.624023   \n",
       "2                            -0.303711                            -0.275879   \n",
       "3                            -2.468750                            -2.566406   \n",
       "4                            -1.747070                            -1.643555   \n",
       "\n",
       "   ../input/readability-v69/rep0_fold0  ../input/readability-v69/rep0_fold1  \\\n",
       "0                            -0.290039                            -0.467285   \n",
       "1                            -0.527832                            -0.325928   \n",
       "2                            -0.506836                            -0.390381   \n",
       "3                            -2.234375                            -2.099609   \n",
       "4                            -1.963867                            -1.979492   \n",
       "\n",
       "   ../input/readability-v69/rep0_fold2  ../input/readability-v69/rep0_fold3  \\\n",
       "0                            -0.242065                            -0.266113   \n",
       "1                            -0.274414                            -0.211304   \n",
       "2                            -0.401367                            -0.306152   \n",
       "3                            -2.251953                            -2.322266   \n",
       "4                            -1.806641                            -1.700195   \n",
       "\n",
       "   ../input/readability-v69/rep0_fold4  ../input/readability-v69/rep1_fold0  \\\n",
       "0                            -0.374268                            -0.218140   \n",
       "1                            -0.255371                            -0.396729   \n",
       "2                            -0.287598                            -0.252930   \n",
       "3                            -1.887695                            -2.294922   \n",
       "4                            -1.768555                            -1.895508   \n",
       "\n",
       "   ../input/readability-v69/rep1_fold1  ../input/readability-v69/rep1_fold2  \\\n",
       "0                            -0.379395                            -0.385498   \n",
       "1                            -0.156982                            -0.280518   \n",
       "2                            -0.454102                            -0.473145   \n",
       "3                            -2.296875                            -1.958984   \n",
       "4                            -1.973633                            -1.772461   \n",
       "\n",
       "   ../input/readability-v69/rep1_fold3  ../input/readability-v69/rep1_fold4  \\\n",
       "0                            -0.366211                            -0.371094   \n",
       "1                            -0.412842                            -0.177246   \n",
       "2                            -0.371582                            -0.299805   \n",
       "3                            -2.220703                            -2.025391   \n",
       "4                            -1.848633                            -1.695312   \n",
       "\n",
       "   ../input/readability-training-v59/rep0_fold0  \\\n",
       "0                                     -0.124634   \n",
       "1                                     -0.512207   \n",
       "2                                     -0.348145   \n",
       "3                                     -2.261719   \n",
       "4                                     -1.757812   \n",
       "\n",
       "   ../input/readability-training-v59/rep0_fold1  \\\n",
       "0                                     -0.459961   \n",
       "1                                     -0.403076   \n",
       "2                                     -0.341553   \n",
       "3                                     -2.529297   \n",
       "4                                     -1.772461   \n",
       "\n",
       "   ../input/readability-training-v59/rep0_fold2  \\\n",
       "0                                     -0.415283   \n",
       "1                                     -0.495361   \n",
       "2                                     -0.244141   \n",
       "3                                     -2.466797   \n",
       "4                                     -1.862305   \n",
       "\n",
       "   ../input/readability-training-v59/rep0_fold3  \\\n",
       "0                                     -0.208984   \n",
       "1                                     -0.542480   \n",
       "2                                     -0.207886   \n",
       "3                                     -2.521484   \n",
       "4                                     -1.855469   \n",
       "\n",
       "   ../input/readability-training-v59/rep0_fold4  \\\n",
       "0                                     -0.205811   \n",
       "1                                     -0.434082   \n",
       "2                                     -0.432373   \n",
       "3                                     -2.712891   \n",
       "4                                     -1.975586   \n",
       "\n",
       "   ../input/readability-training-v59/rep1_fold0  \\\n",
       "0                                     -0.335938   \n",
       "1                                     -0.565430   \n",
       "2                                     -0.490234   \n",
       "3                                     -2.392578   \n",
       "4                                     -2.017578   \n",
       "\n",
       "   ../input/readability-training-v59/rep1_fold1  \\\n",
       "0                                     -0.325684   \n",
       "1                                     -0.450195   \n",
       "2                                     -0.299805   \n",
       "3                                     -2.349609   \n",
       "4                                     -1.897461   \n",
       "\n",
       "   ../input/readability-training-v59/rep1_fold2  \\\n",
       "0                                     -0.260742   \n",
       "1                                     -0.495117   \n",
       "2                                     -0.550293   \n",
       "3                                     -2.703125   \n",
       "4                                     -1.906250   \n",
       "\n",
       "   ../input/readability-training-v59/rep1_fold3  \\\n",
       "0                                     -0.366699   \n",
       "1                                     -0.514160   \n",
       "2                                     -0.417236   \n",
       "3                                     -2.769531   \n",
       "4                                     -1.729492   \n",
       "\n",
       "   ../input/readability-training-v59/rep1_fold4  \n",
       "0                                     -0.431396  \n",
       "1                                     -0.512695  \n",
       "2                                     -0.318848  \n",
       "3                                     -2.630859  \n",
       "4                                     -1.938477  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "####### PRODUCE TEST PREDS \n",
    "\n",
    "# timer\n",
    "cv_start = time.time()\n",
    "gc.collect()\n",
    "\n",
    "# counter\n",
    "all_counter  = 0\n",
    "rep_counter  = 0\n",
    "fold_counter = 0\n",
    "\n",
    "# placeholder\n",
    "all_nn_preds = None\n",
    "\n",
    "# progress bar\n",
    "pbar = tqdm(range(CFG['use_folds'] * CFG['use_reps'] * len(CFG['models'])))\n",
    "\n",
    "# loop through models\n",
    "for model_idx in range(len(CFG['models'])):\n",
    "       \n",
    "    # get tokenizer\n",
    "    tokenizer = AutoTokenizer.from_pretrained(CFGs[model_idx]['backbone'])\n",
    "    \n",
    "    # get data\n",
    "    test_dataset = TextData(df          = sub, \n",
    "                            tokenizer   = tokenizer,\n",
    "                            max_len     = CFGs[model_idx]['max_len'],\n",
    "                            padding     = False,\n",
    "                            p_translate = 0,\n",
    "                            labeled     = False,\n",
    "                            return_sd   = False)\n",
    "            \n",
    "    # loop through folds\n",
    "    for rep_idx in range(CFG['use_reps']):\n",
    "               \n",
    "        # loop through folds\n",
    "        for fold_idx in range(CFG['use_folds']):\n",
    "            \n",
    "            # initialize accelerator\n",
    "            accelerator = Accelerator(device_placement = True,\n",
    "                                      fp16             = CFGs[model_idx]['use_fp16'],\n",
    "                                      split_batches    = False)\n",
    "            \n",
    "            # get loader\n",
    "            test_loader = DataLoader(dataset     = test_dataset, \n",
    "                                     batch_size  = CFG['batch_size'], \n",
    "                                     shuffle     = False,\n",
    "                                     collate_fn  = lambda b: collate_fn(b, tokenizer, CFGs[model_idx], False),\n",
    "                                     num_workers = CFG['cpu_workers'],\n",
    "                                     drop_last   = False,\n",
    "                                     pin_memory  = False)\n",
    "            \n",
    "            # get model \n",
    "            model = get_model(CFG        = CFGs[model_idx], \n",
    "                              pretrained = CFG['models'][model_idx] + 'weights_rep{}_fold{}.pth'.format(rep_counter, fold_counter),\n",
    "                              silent     = True)\n",
    "            \n",
    "            # device placement\n",
    "            model, test_loader = accelerator.prepare(model, test_loader)\n",
    "    \n",
    "            # switch regime\n",
    "            model.eval()\n",
    "\n",
    "            # placeholders\n",
    "            PREDS = []\n",
    "            \n",
    "            # loop through batches\n",
    "            with torch.no_grad():\n",
    "                for batch_idx, (inputs, masks, token_type_ids) in enumerate(test_loader):\n",
    "                    \n",
    "                    # forward pass\n",
    "                    preds = model(inputs, masks, token_type_ids)\n",
    "                    preds = preds['logits'].squeeze(-1)\n",
    "\n",
    "                    # store predictions\n",
    "                    PREDS.append(accelerator.gather(preds).detach().cpu())\n",
    "\n",
    "            # store predictions\n",
    "            nn_preds     = pd.DataFrame(np.concatenate(PREDS), columns = [CFG['models'][model_idx] + 'rep' + str(rep_idx) + '_fold' + str(fold_idx)])\n",
    "            all_nn_preds = pd.concat([all_nn_preds, nn_preds], axis = 1)\n",
    "\n",
    "            # update counters\n",
    "            pbar.update()\n",
    "            all_counter  += 1\n",
    "            fold_counter += 1\n",
    "            if fold_counter == CFG['num_folds']:\n",
    "                fold_counter = 0\n",
    "\n",
    "            # clear memory\n",
    "            del model\n",
    "            del inputs, masks, token_type_ids, preds, PREDS, nn_preds\n",
    "            gc.collect()            \n",
    "            \n",
    "        # update counters\n",
    "        rep_counter += 1\n",
    "        if rep_counter == CFG['num_reps']:\n",
    "            rep_counter = 0\n",
    "\n",
    "    # clear memory\n",
    "    del accelerator, test_loader, test_dataset, tokenizer\n",
    "    gc.collect()\n",
    "        \n",
    "# print performance\n",
    "print('Finished {} preds in {:.2f} mins'.format(all_counter, (time.time() - cv_start) / 60))\n",
    "all_nn_preds.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "058c8faa",
   "metadata": {
    "papermill": {
     "duration": 0.061497,
     "end_time": "2021-08-02T20:56:37.704323",
     "exception": false,
     "start_time": "2021-08-02T20:56:37.642826",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# BLENDING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "117c51ba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-02T20:56:37.848120Z",
     "iopub.status.busy": "2021-08-02T20:56:37.844854Z",
     "iopub.status.idle": "2021-08-02T20:56:37.896246Z",
     "shell.execute_reply": "2021-08-02T20:56:37.896689Z",
     "shell.execute_reply.started": "2021-08-02T20:00:52.974246Z"
    },
    "papermill": {
     "duration": 0.131285,
     "end_time": "2021-08-02T20:56:37.896845",
     "exception": false,
     "start_time": "2021-08-02T20:56:37.765560",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blending fold predictions with: amean\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>../input/readability-training-v56/rep0</th>\n",
       "      <th>../input/readability-training-v56/rep1</th>\n",
       "      <th>../input/readability-training-v55/rep0</th>\n",
       "      <th>../input/readability-training-v55/rep1</th>\n",
       "      <th>../input/readability-training-v52/rep0</th>\n",
       "      <th>../input/readability-training-v52/rep1</th>\n",
       "      <th>../input/readability-v62/rep0</th>\n",
       "      <th>../input/readability-v62/rep1</th>\n",
       "      <th>../input/readability-v36/rep0</th>\n",
       "      <th>../input/readability-v36/rep1</th>\n",
       "      <th>../input/readability-v47/rep0</th>\n",
       "      <th>../input/readability-v47/rep1</th>\n",
       "      <th>../input/readability-v69/rep0</th>\n",
       "      <th>../input/readability-v69/rep1</th>\n",
       "      <th>../input/readability-training-v59/rep0</th>\n",
       "      <th>../input/readability-training-v59/rep1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c0f722661</td>\n",
       "      <td>-0.399365</td>\n",
       "      <td>-0.414673</td>\n",
       "      <td>-0.434424</td>\n",
       "      <td>-0.401807</td>\n",
       "      <td>-0.402637</td>\n",
       "      <td>-0.454980</td>\n",
       "      <td>-0.426221</td>\n",
       "      <td>-0.408594</td>\n",
       "      <td>-0.349561</td>\n",
       "      <td>-0.377295</td>\n",
       "      <td>-0.628516</td>\n",
       "      <td>-0.511060</td>\n",
       "      <td>-0.327954</td>\n",
       "      <td>-0.344067</td>\n",
       "      <td>-0.282935</td>\n",
       "      <td>-0.344092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>f0953f0a5</td>\n",
       "      <td>-0.780273</td>\n",
       "      <td>-0.769824</td>\n",
       "      <td>-0.666016</td>\n",
       "      <td>-0.634668</td>\n",
       "      <td>-0.639307</td>\n",
       "      <td>-0.674316</td>\n",
       "      <td>-0.391333</td>\n",
       "      <td>-0.421143</td>\n",
       "      <td>-0.443506</td>\n",
       "      <td>-0.462402</td>\n",
       "      <td>-0.724316</td>\n",
       "      <td>-0.707031</td>\n",
       "      <td>-0.318970</td>\n",
       "      <td>-0.284863</td>\n",
       "      <td>-0.477441</td>\n",
       "      <td>-0.507520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0df072751</td>\n",
       "      <td>-0.383325</td>\n",
       "      <td>-0.415186</td>\n",
       "      <td>-0.415552</td>\n",
       "      <td>-0.432227</td>\n",
       "      <td>-0.462695</td>\n",
       "      <td>-0.443994</td>\n",
       "      <td>-0.433960</td>\n",
       "      <td>-0.397656</td>\n",
       "      <td>-0.399951</td>\n",
       "      <td>-0.426465</td>\n",
       "      <td>-0.420996</td>\n",
       "      <td>-0.331641</td>\n",
       "      <td>-0.378467</td>\n",
       "      <td>-0.370313</td>\n",
       "      <td>-0.314819</td>\n",
       "      <td>-0.415283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>04caf4e0c</td>\n",
       "      <td>-2.498828</td>\n",
       "      <td>-2.493750</td>\n",
       "      <td>-2.435547</td>\n",
       "      <td>-2.542188</td>\n",
       "      <td>-2.465625</td>\n",
       "      <td>-2.453125</td>\n",
       "      <td>-2.265234</td>\n",
       "      <td>-2.217188</td>\n",
       "      <td>-2.213672</td>\n",
       "      <td>-2.345313</td>\n",
       "      <td>-2.540234</td>\n",
       "      <td>-2.474219</td>\n",
       "      <td>-2.159180</td>\n",
       "      <td>-2.159375</td>\n",
       "      <td>-2.498438</td>\n",
       "      <td>-2.569141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0e63f8bea</td>\n",
       "      <td>-1.689844</td>\n",
       "      <td>-1.763672</td>\n",
       "      <td>-1.780469</td>\n",
       "      <td>-1.778711</td>\n",
       "      <td>-1.763672</td>\n",
       "      <td>-1.776563</td>\n",
       "      <td>-1.863867</td>\n",
       "      <td>-1.852734</td>\n",
       "      <td>-1.862109</td>\n",
       "      <td>-1.901367</td>\n",
       "      <td>-1.809375</td>\n",
       "      <td>-1.766992</td>\n",
       "      <td>-1.843750</td>\n",
       "      <td>-1.837109</td>\n",
       "      <td>-1.844727</td>\n",
       "      <td>-1.897852</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  ../input/readability-training-v56/rep0  \\\n",
       "0  c0f722661                               -0.399365   \n",
       "1  f0953f0a5                               -0.780273   \n",
       "2  0df072751                               -0.383325   \n",
       "3  04caf4e0c                               -2.498828   \n",
       "4  0e63f8bea                               -1.689844   \n",
       "\n",
       "   ../input/readability-training-v56/rep1  \\\n",
       "0                               -0.414673   \n",
       "1                               -0.769824   \n",
       "2                               -0.415186   \n",
       "3                               -2.493750   \n",
       "4                               -1.763672   \n",
       "\n",
       "   ../input/readability-training-v55/rep0  \\\n",
       "0                               -0.434424   \n",
       "1                               -0.666016   \n",
       "2                               -0.415552   \n",
       "3                               -2.435547   \n",
       "4                               -1.780469   \n",
       "\n",
       "   ../input/readability-training-v55/rep1  \\\n",
       "0                               -0.401807   \n",
       "1                               -0.634668   \n",
       "2                               -0.432227   \n",
       "3                               -2.542188   \n",
       "4                               -1.778711   \n",
       "\n",
       "   ../input/readability-training-v52/rep0  \\\n",
       "0                               -0.402637   \n",
       "1                               -0.639307   \n",
       "2                               -0.462695   \n",
       "3                               -2.465625   \n",
       "4                               -1.763672   \n",
       "\n",
       "   ../input/readability-training-v52/rep1  ../input/readability-v62/rep0  \\\n",
       "0                               -0.454980                      -0.426221   \n",
       "1                               -0.674316                      -0.391333   \n",
       "2                               -0.443994                      -0.433960   \n",
       "3                               -2.453125                      -2.265234   \n",
       "4                               -1.776563                      -1.863867   \n",
       "\n",
       "   ../input/readability-v62/rep1  ../input/readability-v36/rep0  \\\n",
       "0                      -0.408594                      -0.349561   \n",
       "1                      -0.421143                      -0.443506   \n",
       "2                      -0.397656                      -0.399951   \n",
       "3                      -2.217188                      -2.213672   \n",
       "4                      -1.852734                      -1.862109   \n",
       "\n",
       "   ../input/readability-v36/rep1  ../input/readability-v47/rep0  \\\n",
       "0                      -0.377295                      -0.628516   \n",
       "1                      -0.462402                      -0.724316   \n",
       "2                      -0.426465                      -0.420996   \n",
       "3                      -2.345313                      -2.540234   \n",
       "4                      -1.901367                      -1.809375   \n",
       "\n",
       "   ../input/readability-v47/rep1  ../input/readability-v69/rep0  \\\n",
       "0                      -0.511060                      -0.327954   \n",
       "1                      -0.707031                      -0.318970   \n",
       "2                      -0.331641                      -0.378467   \n",
       "3                      -2.474219                      -2.159180   \n",
       "4                      -1.766992                      -1.843750   \n",
       "\n",
       "   ../input/readability-v69/rep1  ../input/readability-training-v59/rep0  \\\n",
       "0                      -0.344067                               -0.282935   \n",
       "1                      -0.284863                               -0.477441   \n",
       "2                      -0.370313                               -0.314819   \n",
       "3                      -2.159375                               -2.498438   \n",
       "4                      -1.837109                               -1.844727   \n",
       "\n",
       "   ../input/readability-training-v59/rep1  \n",
       "0                               -0.344092  \n",
       "1                               -0.507520  \n",
       "2                               -0.415283  \n",
       "3                               -2.569141  \n",
       "4                               -1.897852  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "######## BLEND FOLD PREDICTIONS\n",
    "\n",
    "# copy predictions\n",
    "test_preds_nn       = all_nn_preds.copy()\n",
    "test_preds_nn['id'] = sub['id']\n",
    "\n",
    "# blend folds\n",
    "print('Blending fold predictions with: ' + CFG['fold_blend'])\n",
    "for m in CFG['models']:\n",
    "    for rep in range(CFG['use_reps']):\n",
    "        preds = [m + 'rep' + str(rep) + '_fold' + str(fold) for fold in range(CFG['use_folds'])]\n",
    "        test_preds_nn[m + 'rep' + str(rep)] = compute_blend(test_preds_nn, preds, CFG['fold_blend'], CFG)\n",
    "        test_preds_nn.drop(preds, axis = 1, inplace = True)\n",
    "test_preds_nn.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "64594580",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-02T20:56:38.042231Z",
     "iopub.status.busy": "2021-08-02T20:56:38.041193Z",
     "iopub.status.idle": "2021-08-02T20:56:38.072045Z",
     "shell.execute_reply": "2021-08-02T20:56:38.072521Z",
     "shell.execute_reply.started": "2021-08-02T20:00:53.065135Z"
    },
    "papermill": {
     "duration": 0.112894,
     "end_time": "2021-08-02T20:56:38.072678",
     "exception": false,
     "start_time": "2021-08-02T20:56:37.959784",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blending bag predictions with: amean\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>../input/readability-training-v56/</th>\n",
       "      <th>../input/readability-training-v55/</th>\n",
       "      <th>../input/readability-training-v52/</th>\n",
       "      <th>../input/readability-v62/</th>\n",
       "      <th>../input/readability-v36/</th>\n",
       "      <th>../input/readability-v47/</th>\n",
       "      <th>../input/readability-v69/</th>\n",
       "      <th>../input/readability-training-v59/</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c0f722661</td>\n",
       "      <td>-0.407019</td>\n",
       "      <td>-0.418115</td>\n",
       "      <td>-0.428809</td>\n",
       "      <td>-0.417407</td>\n",
       "      <td>-0.363428</td>\n",
       "      <td>-0.569788</td>\n",
       "      <td>-0.336011</td>\n",
       "      <td>-0.313513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>f0953f0a5</td>\n",
       "      <td>-0.775049</td>\n",
       "      <td>-0.650342</td>\n",
       "      <td>-0.656812</td>\n",
       "      <td>-0.406238</td>\n",
       "      <td>-0.452954</td>\n",
       "      <td>-0.715674</td>\n",
       "      <td>-0.301917</td>\n",
       "      <td>-0.492480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0df072751</td>\n",
       "      <td>-0.399255</td>\n",
       "      <td>-0.423889</td>\n",
       "      <td>-0.453345</td>\n",
       "      <td>-0.415808</td>\n",
       "      <td>-0.413208</td>\n",
       "      <td>-0.376318</td>\n",
       "      <td>-0.374390</td>\n",
       "      <td>-0.365051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>04caf4e0c</td>\n",
       "      <td>-2.496289</td>\n",
       "      <td>-2.488867</td>\n",
       "      <td>-2.459375</td>\n",
       "      <td>-2.241211</td>\n",
       "      <td>-2.279492</td>\n",
       "      <td>-2.507227</td>\n",
       "      <td>-2.159277</td>\n",
       "      <td>-2.533789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0e63f8bea</td>\n",
       "      <td>-1.726758</td>\n",
       "      <td>-1.779590</td>\n",
       "      <td>-1.770117</td>\n",
       "      <td>-1.858301</td>\n",
       "      <td>-1.881738</td>\n",
       "      <td>-1.788184</td>\n",
       "      <td>-1.840430</td>\n",
       "      <td>-1.871289</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  ../input/readability-training-v56/  \\\n",
       "0  c0f722661                           -0.407019   \n",
       "1  f0953f0a5                           -0.775049   \n",
       "2  0df072751                           -0.399255   \n",
       "3  04caf4e0c                           -2.496289   \n",
       "4  0e63f8bea                           -1.726758   \n",
       "\n",
       "   ../input/readability-training-v55/  ../input/readability-training-v52/  \\\n",
       "0                           -0.418115                           -0.428809   \n",
       "1                           -0.650342                           -0.656812   \n",
       "2                           -0.423889                           -0.453345   \n",
       "3                           -2.488867                           -2.459375   \n",
       "4                           -1.779590                           -1.770117   \n",
       "\n",
       "   ../input/readability-v62/  ../input/readability-v36/  \\\n",
       "0                  -0.417407                  -0.363428   \n",
       "1                  -0.406238                  -0.452954   \n",
       "2                  -0.415808                  -0.413208   \n",
       "3                  -2.241211                  -2.279492   \n",
       "4                  -1.858301                  -1.881738   \n",
       "\n",
       "   ../input/readability-v47/  ../input/readability-v69/  \\\n",
       "0                  -0.569788                  -0.336011   \n",
       "1                  -0.715674                  -0.301917   \n",
       "2                  -0.376318                  -0.374390   \n",
       "3                  -2.507227                  -2.159277   \n",
       "4                  -1.788184                  -1.840430   \n",
       "\n",
       "   ../input/readability-training-v59/  \n",
       "0                           -0.313513  \n",
       "1                           -0.492480  \n",
       "2                           -0.365051  \n",
       "3                           -2.533789  \n",
       "4                           -1.871289  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "######## BLEND BAG PREDICTIONS\n",
    "\n",
    "print('Blending bag predictions with: ' + CFG['rep_blend'])\n",
    "for m in CFG['models']:\n",
    "    preds            = test_preds_nn.filter(like = m).columns\n",
    "    test_preds_nn[m] = compute_blend(test_preds_nn, preds, CFG['rep_blend'], CFG)\n",
    "    test_preds_nn.drop(preds, axis = 1, inplace = True)\n",
    "test_preds_nn.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3f538423",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-02T20:56:38.240007Z",
     "iopub.status.busy": "2021-08-02T20:56:38.231680Z",
     "iopub.status.idle": "2021-08-02T20:56:38.641697Z",
     "shell.execute_reply": "2021-08-02T20:56:38.642105Z",
     "shell.execute_reply.started": "2021-08-02T20:00:53.107493Z"
    },
    "papermill": {
     "duration": 0.496034,
     "end_time": "2021-08-02T20:56:38.642261",
     "exception": false,
     "start_time": "2021-08-02T20:56:38.146227",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "####### CHECK MODEL TEST CORRELATION\n",
    "\n",
    "corr    = test_preds_nn[CFG['models']].corr()\n",
    "corr    = corr.where(np.tril(np.ones(corr.shape)).astype(np.bool))\n",
    "fig, ax = plt.subplots(figsize = (15, 10))\n",
    "ticks   = [m.replace('../input/readability-', '') for m in CFG['models']]\n",
    "hmap    = sns.heatmap(corr, cmap = 'coolwarm', annot = corr, fmt = '.4f', xticklabels = ticks, yticklabels = ticks)\n",
    "plt.yticks(rotation = 0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bd75e4a1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-02T20:56:38.789299Z",
     "iopub.status.busy": "2021-08-02T20:56:38.788669Z",
     "iopub.status.idle": "2021-08-02T20:56:38.793018Z",
     "shell.execute_reply": "2021-08-02T20:56:38.793476Z",
     "shell.execute_reply.started": "2021-08-02T20:00:53.562083Z"
    },
    "papermill": {
     "duration": 0.087975,
     "end_time": "2021-08-02T20:56:38.793642",
     "exception": false,
     "start_time": "2021-08-02T20:56:38.705667",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blending model predictions with: amean\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>../input/readability-training-v56/</th>\n",
       "      <th>../input/readability-training-v55/</th>\n",
       "      <th>../input/readability-training-v52/</th>\n",
       "      <th>../input/readability-v62/</th>\n",
       "      <th>../input/readability-v36/</th>\n",
       "      <th>../input/readability-v47/</th>\n",
       "      <th>../input/readability-v69/</th>\n",
       "      <th>../input/readability-training-v59/</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c0f722661</td>\n",
       "      <td>-0.407019</td>\n",
       "      <td>-0.418115</td>\n",
       "      <td>-0.428809</td>\n",
       "      <td>-0.417407</td>\n",
       "      <td>-0.363428</td>\n",
       "      <td>-0.569788</td>\n",
       "      <td>-0.336011</td>\n",
       "      <td>-0.313513</td>\n",
       "      <td>-0.406761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>f0953f0a5</td>\n",
       "      <td>-0.775049</td>\n",
       "      <td>-0.650342</td>\n",
       "      <td>-0.656812</td>\n",
       "      <td>-0.406238</td>\n",
       "      <td>-0.452954</td>\n",
       "      <td>-0.715674</td>\n",
       "      <td>-0.301917</td>\n",
       "      <td>-0.492480</td>\n",
       "      <td>-0.556433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0df072751</td>\n",
       "      <td>-0.399255</td>\n",
       "      <td>-0.423889</td>\n",
       "      <td>-0.453345</td>\n",
       "      <td>-0.415808</td>\n",
       "      <td>-0.413208</td>\n",
       "      <td>-0.376318</td>\n",
       "      <td>-0.374390</td>\n",
       "      <td>-0.365051</td>\n",
       "      <td>-0.402658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>04caf4e0c</td>\n",
       "      <td>-2.496289</td>\n",
       "      <td>-2.488867</td>\n",
       "      <td>-2.459375</td>\n",
       "      <td>-2.241211</td>\n",
       "      <td>-2.279492</td>\n",
       "      <td>-2.507227</td>\n",
       "      <td>-2.159277</td>\n",
       "      <td>-2.533789</td>\n",
       "      <td>-2.395691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0e63f8bea</td>\n",
       "      <td>-1.726758</td>\n",
       "      <td>-1.779590</td>\n",
       "      <td>-1.770117</td>\n",
       "      <td>-1.858301</td>\n",
       "      <td>-1.881738</td>\n",
       "      <td>-1.788184</td>\n",
       "      <td>-1.840430</td>\n",
       "      <td>-1.871289</td>\n",
       "      <td>-1.814551</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  ../input/readability-training-v56/  \\\n",
       "0  c0f722661                           -0.407019   \n",
       "1  f0953f0a5                           -0.775049   \n",
       "2  0df072751                           -0.399255   \n",
       "3  04caf4e0c                           -2.496289   \n",
       "4  0e63f8bea                           -1.726758   \n",
       "\n",
       "   ../input/readability-training-v55/  ../input/readability-training-v52/  \\\n",
       "0                           -0.418115                           -0.428809   \n",
       "1                           -0.650342                           -0.656812   \n",
       "2                           -0.423889                           -0.453345   \n",
       "3                           -2.488867                           -2.459375   \n",
       "4                           -1.779590                           -1.770117   \n",
       "\n",
       "   ../input/readability-v62/  ../input/readability-v36/  \\\n",
       "0                  -0.417407                  -0.363428   \n",
       "1                  -0.406238                  -0.452954   \n",
       "2                  -0.415808                  -0.413208   \n",
       "3                  -2.241211                  -2.279492   \n",
       "4                  -1.858301                  -1.881738   \n",
       "\n",
       "   ../input/readability-v47/  ../input/readability-v69/  \\\n",
       "0                  -0.569788                  -0.336011   \n",
       "1                  -0.715674                  -0.301917   \n",
       "2                  -0.376318                  -0.374390   \n",
       "3                  -2.507227                  -2.159277   \n",
       "4                  -1.788184                  -1.840430   \n",
       "\n",
       "   ../input/readability-training-v59/      pred  \n",
       "0                           -0.313513 -0.406761  \n",
       "1                           -0.492480 -0.556433  \n",
       "2                           -0.365051 -0.402658  \n",
       "3                           -2.533789 -2.395691  \n",
       "4                           -1.871289 -1.814551  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "####### BLEND MODEL PREDICTIONS\n",
    "\n",
    "print('Blending model predictions with: ' + CFG['model_blend'])\n",
    "preds = test_preds_nn.filter(like = 'input').columns\n",
    "test_preds_nn['pred'] = compute_blend(test_preds_nn, preds, CFG['model_blend'], CFG) \n",
    "test_preds_nn.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bf10cf28",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-02T20:56:38.933757Z",
     "iopub.status.busy": "2021-08-02T20:56:38.933113Z",
     "iopub.status.idle": "2021-08-02T20:56:38.945295Z",
     "shell.execute_reply": "2021-08-02T20:56:38.944824Z",
     "shell.execute_reply.started": "2021-08-02T20:00:53.588573Z"
    },
    "papermill": {
     "duration": 0.082931,
     "end_time": "2021-08-02T20:56:38.945414",
     "exception": false,
     "start_time": "2021-08-02T20:56:38.862483",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c0f722661</td>\n",
       "      <td>-0.406761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>f0953f0a5</td>\n",
       "      <td>-0.556433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0df072751</td>\n",
       "      <td>-0.402658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>04caf4e0c</td>\n",
       "      <td>-2.395691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0e63f8bea</td>\n",
       "      <td>-1.814551</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id      pred\n",
       "0  c0f722661 -0.406761\n",
       "1  f0953f0a5 -0.556433\n",
       "2  0df072751 -0.402658\n",
       "3  04caf4e0c -2.395691\n",
       "4  0e63f8bea -1.814551"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "####### EXPORT BEST TEST BLEND\n",
    "\n",
    "test_blend = test_preds_nn[['id', 'pred']].copy()   \n",
    "test_blend.to_csv('sub_{}.csv'.format(CFG['model_blend']), index = False)\n",
    "test_blend.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3623ffdd",
   "metadata": {
    "papermill": {
     "duration": 0.108554,
     "end_time": "2021-08-02T20:56:39.149403",
     "exception": false,
     "start_time": "2021-08-02T20:56:39.040849",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# STACKING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "eafee80b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-02T20:56:39.368087Z",
     "iopub.status.busy": "2021-08-02T20:56:39.367244Z",
     "iopub.status.idle": "2021-08-02T20:56:39.373123Z",
     "shell.execute_reply": "2021-08-02T20:56:39.373579Z",
     "shell.execute_reply.started": "2021-08-02T20:00:53.612408Z"
    },
    "papermill": {
     "duration": 0.118145,
     "end_time": "2021-08-02T20:56:39.373775",
     "exception": false,
     "start_time": "2021-08-02T20:56:39.255630",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "####### COPY PREDICTIONS\n",
    "\n",
    "df_train = train_preds.copy()\n",
    "df_test  = test_preds_nn.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ae876b06",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-02T20:56:39.577383Z",
     "iopub.status.busy": "2021-08-02T20:56:39.576839Z",
     "iopub.status.idle": "2021-08-02T20:56:40.042055Z",
     "shell.execute_reply": "2021-08-02T20:56:40.041615Z",
     "shell.execute_reply.started": "2021-08-02T20:00:53.620840Z"
    },
    "papermill": {
     "duration": 0.563254,
     "end_time": "2021-08-02T20:56:40.042171",
     "exception": false,
     "start_time": "2021-08-02T20:56:39.478917",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "      <th>target_cat</th>\n",
       "      <th>../input/readability-v36/pred_rep0</th>\n",
       "      <th>../input/readability-v36/pred_rep1</th>\n",
       "      <th>../input/readability-v36/pred_rep2</th>\n",
       "      <th>../input/readability-v47/pred_rep0</th>\n",
       "      <th>../input/readability-v47/pred_rep1</th>\n",
       "      <th>../input/readability-v47/pred_rep2</th>\n",
       "      <th>../input/readability-training-v52/pred_rep0</th>\n",
       "      <th>../input/readability-training-v52/pred_rep1</th>\n",
       "      <th>../input/readability-training-v52/pred_rep2</th>\n",
       "      <th>../input/readability-training-v55/pred_rep0</th>\n",
       "      <th>../input/readability-training-v55/pred_rep1</th>\n",
       "      <th>../input/readability-training-v55/pred_rep2</th>\n",
       "      <th>../input/readability-training-v56/pred_rep0</th>\n",
       "      <th>../input/readability-training-v56/pred_rep1</th>\n",
       "      <th>../input/readability-training-v56/pred_rep2</th>\n",
       "      <th>../input/readability-training-v59/pred_rep0</th>\n",
       "      <th>../input/readability-training-v59/pred_rep1</th>\n",
       "      <th>../input/readability-training-v59/pred_rep2</th>\n",
       "      <th>../input/readability-v62/pred_rep0</th>\n",
       "      <th>../input/readability-v62/pred_rep1</th>\n",
       "      <th>../input/readability-v62/pred_rep2</th>\n",
       "      <th>../input/readability-v69/pred_rep0</th>\n",
       "      <th>../input/readability-v69/pred_rep1</th>\n",
       "      <th>../input/readability-v69/pred_rep2</th>\n",
       "      <th>../input/readability-training-v56/</th>\n",
       "      <th>../input/readability-training-v55/</th>\n",
       "      <th>../input/readability-training-v52/</th>\n",
       "      <th>../input/readability-v62/</th>\n",
       "      <th>../input/readability-v36/</th>\n",
       "      <th>../input/readability-v47/</th>\n",
       "      <th>../input/readability-v69/</th>\n",
       "      <th>../input/readability-training-v59/</th>\n",
       "      <th>amean</th>\n",
       "      <th>median</th>\n",
       "      <th>standard_error</th>\n",
       "      <th>flesch_reading_ease</th>\n",
       "      <th>smog_index</th>\n",
       "      <th>flesch_kincaid_grade</th>\n",
       "      <th>coleman_liau_index</th>\n",
       "      <th>automated_readability_index</th>\n",
       "      <th>dale_chall_readability_score</th>\n",
       "      <th>difficult_words</th>\n",
       "      <th>linsear_write_formula</th>\n",
       "      <th>gunning_fog2</th>\n",
       "      <th>text_standard</th>\n",
       "      <th>mean_parse_tree_depth</th>\n",
       "      <th>total_sentences</th>\n",
       "      <th>...</th>\n",
       "      <th>semicolons</th>\n",
       "      <th>quotes</th>\n",
       "      <th>nonstop_char_count</th>\n",
       "      <th>nonstop_word_count</th>\n",
       "      <th>words_per_sentence</th>\n",
       "      <th>ents_per_sentence</th>\n",
       "      <th>chars_per_sentence</th>\n",
       "      <th>chars_per_word</th>\n",
       "      <th>punctutation_per_word</th>\n",
       "      <th>mean_adj</th>\n",
       "      <th>mean_adp</th>\n",
       "      <th>mean_adv</th>\n",
       "      <th>mean_aux</th>\n",
       "      <th>mean_cconj</th>\n",
       "      <th>mean_det</th>\n",
       "      <th>mean_intj</th>\n",
       "      <th>mean_noun</th>\n",
       "      <th>mean_num</th>\n",
       "      <th>mean_part</th>\n",
       "      <th>mean_pron</th>\n",
       "      <th>mean_propn</th>\n",
       "      <th>mean_punct</th>\n",
       "      <th>mean_sconj</th>\n",
       "      <th>mean_verb</th>\n",
       "      <th>mean_x</th>\n",
       "      <th>mean_space</th>\n",
       "      <th>mean_sym</th>\n",
       "      <th>complex_words</th>\n",
       "      <th>long_words</th>\n",
       "      <th>kincaid</th>\n",
       "      <th>ari</th>\n",
       "      <th>coleman_liau</th>\n",
       "      <th>flesch</th>\n",
       "      <th>gunning_fog</th>\n",
       "      <th>lix</th>\n",
       "      <th>smog</th>\n",
       "      <th>rix</th>\n",
       "      <th>dale_chall</th>\n",
       "      <th>tobeverb</th>\n",
       "      <th>auxverb</th>\n",
       "      <th>conjunction</th>\n",
       "      <th>pronoun</th>\n",
       "      <th>preposition</th>\n",
       "      <th>nominalization</th>\n",
       "      <th>pronoun_b</th>\n",
       "      <th>interrogative</th>\n",
       "      <th>article</th>\n",
       "      <th>subordination</th>\n",
       "      <th>conjunction_b</th>\n",
       "      <th>preposition_b</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>85aa80a4c</td>\n",
       "      <td>-0.315372</td>\n",
       "      <td>7</td>\n",
       "      <td>-0.211182</td>\n",
       "      <td>-0.156738</td>\n",
       "      <td>-0.255371</td>\n",
       "      <td>-0.092651</td>\n",
       "      <td>-0.126099</td>\n",
       "      <td>-0.195068</td>\n",
       "      <td>-0.075256</td>\n",
       "      <td>-0.080505</td>\n",
       "      <td>-0.219849</td>\n",
       "      <td>-0.005001</td>\n",
       "      <td>-0.157104</td>\n",
       "      <td>-0.129272</td>\n",
       "      <td>-0.017303</td>\n",
       "      <td>-0.143555</td>\n",
       "      <td>-0.205200</td>\n",
       "      <td>-0.152588</td>\n",
       "      <td>-0.250244</td>\n",
       "      <td>-0.130127</td>\n",
       "      <td>-0.245239</td>\n",
       "      <td>-0.096924</td>\n",
       "      <td>-0.161621</td>\n",
       "      <td>-0.359863</td>\n",
       "      <td>-0.115051</td>\n",
       "      <td>-0.346680</td>\n",
       "      <td>-0.080429</td>\n",
       "      <td>-0.081053</td>\n",
       "      <td>-0.077881</td>\n",
       "      <td>-0.171082</td>\n",
       "      <td>-0.183960</td>\n",
       "      <td>-0.109375</td>\n",
       "      <td>-0.237457</td>\n",
       "      <td>-0.201416</td>\n",
       "      <td>-0.142832</td>\n",
       "      <td>-0.140228</td>\n",
       "      <td>0.480805</td>\n",
       "      <td>71.24</td>\n",
       "      <td>8.8</td>\n",
       "      <td>7.5</td>\n",
       "      <td>6.90</td>\n",
       "      <td>7.8</td>\n",
       "      <td>6.06</td>\n",
       "      <td>17</td>\n",
       "      <td>8.500000</td>\n",
       "      <td>8.65</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.805310</td>\n",
       "      <td>17</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>8.820896</td>\n",
       "      <td>1.746269</td>\n",
       "      <td>9.941176</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>55.117647</td>\n",
       "      <td>5.544379</td>\n",
       "      <td>3.117647</td>\n",
       "      <td>1.08</td>\n",
       "      <td>1.08</td>\n",
       "      <td>1.67</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.58</td>\n",
       "      <td>1.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.83</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.58</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.42</td>\n",
       "      <td>3.58</td>\n",
       "      <td>0.08</td>\n",
       "      <td>2.58</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.92</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12</td>\n",
       "      <td>26</td>\n",
       "      <td>9.722558</td>\n",
       "      <td>12.427926</td>\n",
       "      <td>7.541115</td>\n",
       "      <td>76.415078</td>\n",
       "      <td>14.257364</td>\n",
       "      <td>43.782946</td>\n",
       "      <td>10.745967</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>7.628832</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>30</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>057f69731</td>\n",
       "      <td>-1.126248</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.932617</td>\n",
       "      <td>-0.907227</td>\n",
       "      <td>-0.729004</td>\n",
       "      <td>-0.751465</td>\n",
       "      <td>-0.862305</td>\n",
       "      <td>-0.764160</td>\n",
       "      <td>-0.903320</td>\n",
       "      <td>-0.686035</td>\n",
       "      <td>-0.626465</td>\n",
       "      <td>-0.957520</td>\n",
       "      <td>-0.826172</td>\n",
       "      <td>-0.642090</td>\n",
       "      <td>-0.791016</td>\n",
       "      <td>-0.720215</td>\n",
       "      <td>-0.596191</td>\n",
       "      <td>-0.711426</td>\n",
       "      <td>-0.622559</td>\n",
       "      <td>-0.568848</td>\n",
       "      <td>-1.217773</td>\n",
       "      <td>-0.930176</td>\n",
       "      <td>-0.874512</td>\n",
       "      <td>-0.971191</td>\n",
       "      <td>-0.853027</td>\n",
       "      <td>-0.947754</td>\n",
       "      <td>-0.755615</td>\n",
       "      <td>-0.891846</td>\n",
       "      <td>-0.794678</td>\n",
       "      <td>-1.073975</td>\n",
       "      <td>-0.919922</td>\n",
       "      <td>-0.806885</td>\n",
       "      <td>-0.912109</td>\n",
       "      <td>-0.666992</td>\n",
       "      <td>-0.852753</td>\n",
       "      <td>-0.849365</td>\n",
       "      <td>0.477028</td>\n",
       "      <td>66.20</td>\n",
       "      <td>12.2</td>\n",
       "      <td>11.5</td>\n",
       "      <td>8.19</td>\n",
       "      <td>14.1</td>\n",
       "      <td>6.44</td>\n",
       "      <td>15</td>\n",
       "      <td>19.666667</td>\n",
       "      <td>13.63</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.413462</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.813559</td>\n",
       "      <td>1.508475</td>\n",
       "      <td>30.166667</td>\n",
       "      <td>1.833333</td>\n",
       "      <td>162.666667</td>\n",
       "      <td>5.392265</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>1.83</td>\n",
       "      <td>3.67</td>\n",
       "      <td>2.50</td>\n",
       "      <td>2.33</td>\n",
       "      <td>0.67</td>\n",
       "      <td>4.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.83</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.67</td>\n",
       "      <td>2.83</td>\n",
       "      <td>1.17</td>\n",
       "      <td>2.14</td>\n",
       "      <td>1.17</td>\n",
       "      <td>4.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15</td>\n",
       "      <td>24</td>\n",
       "      <td>35.199064</td>\n",
       "      <td>44.764492</td>\n",
       "      <td>8.156792</td>\n",
       "      <td>9.236243</td>\n",
       "      <td>40.608556</td>\n",
       "      <td>106.334225</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>10.807255</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>19</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5e7c0b55b</td>\n",
       "      <td>-1.009999</td>\n",
       "      <td>5</td>\n",
       "      <td>-1.081055</td>\n",
       "      <td>-1.118164</td>\n",
       "      <td>-0.940918</td>\n",
       "      <td>-1.053711</td>\n",
       "      <td>-1.291992</td>\n",
       "      <td>-1.281250</td>\n",
       "      <td>-1.329102</td>\n",
       "      <td>-1.380859</td>\n",
       "      <td>-1.110352</td>\n",
       "      <td>-1.357422</td>\n",
       "      <td>-1.338867</td>\n",
       "      <td>-1.095703</td>\n",
       "      <td>-1.258789</td>\n",
       "      <td>-1.320312</td>\n",
       "      <td>-1.091797</td>\n",
       "      <td>-0.928223</td>\n",
       "      <td>-1.145508</td>\n",
       "      <td>-0.876465</td>\n",
       "      <td>-1.044922</td>\n",
       "      <td>-1.076172</td>\n",
       "      <td>-0.935547</td>\n",
       "      <td>-0.937988</td>\n",
       "      <td>-0.908203</td>\n",
       "      <td>-0.829590</td>\n",
       "      <td>-1.289551</td>\n",
       "      <td>-1.348145</td>\n",
       "      <td>-1.354980</td>\n",
       "      <td>-1.060547</td>\n",
       "      <td>-1.099609</td>\n",
       "      <td>-1.172852</td>\n",
       "      <td>-0.923096</td>\n",
       "      <td>-1.036865</td>\n",
       "      <td>-1.160706</td>\n",
       "      <td>-1.136230</td>\n",
       "      <td>0.496148</td>\n",
       "      <td>74.02</td>\n",
       "      <td>8.1</td>\n",
       "      <td>8.5</td>\n",
       "      <td>7.38</td>\n",
       "      <td>9.9</td>\n",
       "      <td>6.51</td>\n",
       "      <td>20</td>\n",
       "      <td>10.800000</td>\n",
       "      <td>9.89</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.029126</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>9.016667</td>\n",
       "      <td>1.550000</td>\n",
       "      <td>22.125000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>119.625000</td>\n",
       "      <td>5.406780</td>\n",
       "      <td>2.125000</td>\n",
       "      <td>1.25</td>\n",
       "      <td>2.62</td>\n",
       "      <td>1.38</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1.25</td>\n",
       "      <td>3.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.50</td>\n",
       "      <td>1.38</td>\n",
       "      <td>1.62</td>\n",
       "      <td>0.75</td>\n",
       "      <td>2.38</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.88</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11</td>\n",
       "      <td>19</td>\n",
       "      <td>34.796639</td>\n",
       "      <td>43.829180</td>\n",
       "      <td>8.230630</td>\n",
       "      <td>8.559221</td>\n",
       "      <td>39.004372</td>\n",
       "      <td>101.882514</td>\n",
       "      <td>15.845233</td>\n",
       "      <td>9.500000</td>\n",
       "      <td>11.798834</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>17</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>66f0a9ff1</td>\n",
       "      <td>-2.386485</td>\n",
       "      <td>2</td>\n",
       "      <td>-1.282227</td>\n",
       "      <td>-1.325195</td>\n",
       "      <td>-1.458984</td>\n",
       "      <td>-1.562500</td>\n",
       "      <td>-1.504883</td>\n",
       "      <td>-1.717773</td>\n",
       "      <td>-1.636719</td>\n",
       "      <td>-1.504883</td>\n",
       "      <td>-1.704102</td>\n",
       "      <td>-1.652344</td>\n",
       "      <td>-1.524414</td>\n",
       "      <td>-1.731445</td>\n",
       "      <td>-1.528320</td>\n",
       "      <td>-1.444336</td>\n",
       "      <td>-1.569336</td>\n",
       "      <td>-1.567383</td>\n",
       "      <td>-1.583984</td>\n",
       "      <td>-1.522461</td>\n",
       "      <td>-1.288086</td>\n",
       "      <td>-1.395508</td>\n",
       "      <td>-1.555664</td>\n",
       "      <td>-1.360352</td>\n",
       "      <td>-1.143555</td>\n",
       "      <td>-1.252930</td>\n",
       "      <td>-1.486328</td>\n",
       "      <td>-1.588379</td>\n",
       "      <td>-1.570801</td>\n",
       "      <td>-1.341797</td>\n",
       "      <td>-1.303711</td>\n",
       "      <td>-1.533691</td>\n",
       "      <td>-1.251953</td>\n",
       "      <td>-1.575684</td>\n",
       "      <td>-1.456543</td>\n",
       "      <td>-1.510010</td>\n",
       "      <td>0.526079</td>\n",
       "      <td>60.79</td>\n",
       "      <td>12.7</td>\n",
       "      <td>11.5</td>\n",
       "      <td>10.62</td>\n",
       "      <td>14.8</td>\n",
       "      <td>8.09</td>\n",
       "      <td>32</td>\n",
       "      <td>15.750000</td>\n",
       "      <td>13.82</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.127072</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10.823529</td>\n",
       "      <td>1.568627</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>159.333333</td>\n",
       "      <td>5.901235</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.00</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1.17</td>\n",
       "      <td>1.50</td>\n",
       "      <td>1.33</td>\n",
       "      <td>4.83</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.17</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.33</td>\n",
       "      <td>2.33</td>\n",
       "      <td>0.17</td>\n",
       "      <td>2.17</td>\n",
       "      <td>1.50</td>\n",
       "      <td>3.17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.83</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27</td>\n",
       "      <td>41</td>\n",
       "      <td>33.554321</td>\n",
       "      <td>41.660556</td>\n",
       "      <td>12.035429</td>\n",
       "      <td>-1.235556</td>\n",
       "      <td>39.066667</td>\n",
       "      <td>106.308642</td>\n",
       "      <td>23.124612</td>\n",
       "      <td>20.500000</td>\n",
       "      <td>11.942742</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>27</td>\n",
       "      <td>23</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bdd8488dd</td>\n",
       "      <td>-0.473702</td>\n",
       "      <td>7</td>\n",
       "      <td>-0.628906</td>\n",
       "      <td>-0.485596</td>\n",
       "      <td>-0.523438</td>\n",
       "      <td>-0.439697</td>\n",
       "      <td>-0.250977</td>\n",
       "      <td>-0.307617</td>\n",
       "      <td>-0.416260</td>\n",
       "      <td>-0.548828</td>\n",
       "      <td>-0.482178</td>\n",
       "      <td>-0.411621</td>\n",
       "      <td>-0.559082</td>\n",
       "      <td>-0.450684</td>\n",
       "      <td>-0.627441</td>\n",
       "      <td>-0.629395</td>\n",
       "      <td>-0.654785</td>\n",
       "      <td>-0.095337</td>\n",
       "      <td>-0.231567</td>\n",
       "      <td>-0.051514</td>\n",
       "      <td>-0.344727</td>\n",
       "      <td>-0.394531</td>\n",
       "      <td>-0.545410</td>\n",
       "      <td>-0.569824</td>\n",
       "      <td>-0.476807</td>\n",
       "      <td>-0.583984</td>\n",
       "      <td>-0.628418</td>\n",
       "      <td>-0.485352</td>\n",
       "      <td>-0.482544</td>\n",
       "      <td>-0.369629</td>\n",
       "      <td>-0.557251</td>\n",
       "      <td>-0.345337</td>\n",
       "      <td>-0.523315</td>\n",
       "      <td>-0.163452</td>\n",
       "      <td>-0.444412</td>\n",
       "      <td>-0.483948</td>\n",
       "      <td>0.481323</td>\n",
       "      <td>80.65</td>\n",
       "      <td>7.2</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.38</td>\n",
       "      <td>10.9</td>\n",
       "      <td>5.71</td>\n",
       "      <td>8</td>\n",
       "      <td>10.200000</td>\n",
       "      <td>9.99</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.193939</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>9.088889</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>18.125000</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>97.250000</td>\n",
       "      <td>5.365517</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>1.14</td>\n",
       "      <td>2.86</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.75</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.38</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.43</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.86</td>\n",
       "      <td>1.86</td>\n",
       "      <td>0.43</td>\n",
       "      <td>2.57</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.86</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>18</td>\n",
       "      <td>16.850345</td>\n",
       "      <td>22.681080</td>\n",
       "      <td>8.485173</td>\n",
       "      <td>60.340805</td>\n",
       "      <td>21.264368</td>\n",
       "      <td>60.747126</td>\n",
       "      <td>11.366600</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>8.102868</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>20</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 106 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id    target  target_cat  ../input/readability-v36/pred_rep0  \\\n",
       "0  85aa80a4c -0.315372           7                           -0.211182   \n",
       "1  057f69731 -1.126248           5                           -0.932617   \n",
       "2  5e7c0b55b -1.009999           5                           -1.081055   \n",
       "3  66f0a9ff1 -2.386485           2                           -1.282227   \n",
       "4  bdd8488dd -0.473702           7                           -0.628906   \n",
       "\n",
       "   ../input/readability-v36/pred_rep1  ../input/readability-v36/pred_rep2  \\\n",
       "0                           -0.156738                           -0.255371   \n",
       "1                           -0.907227                           -0.729004   \n",
       "2                           -1.118164                           -0.940918   \n",
       "3                           -1.325195                           -1.458984   \n",
       "4                           -0.485596                           -0.523438   \n",
       "\n",
       "   ../input/readability-v47/pred_rep0  ../input/readability-v47/pred_rep1  \\\n",
       "0                           -0.092651                           -0.126099   \n",
       "1                           -0.751465                           -0.862305   \n",
       "2                           -1.053711                           -1.291992   \n",
       "3                           -1.562500                           -1.504883   \n",
       "4                           -0.439697                           -0.250977   \n",
       "\n",
       "   ../input/readability-v47/pred_rep2  \\\n",
       "0                           -0.195068   \n",
       "1                           -0.764160   \n",
       "2                           -1.281250   \n",
       "3                           -1.717773   \n",
       "4                           -0.307617   \n",
       "\n",
       "   ../input/readability-training-v52/pred_rep0  \\\n",
       "0                                    -0.075256   \n",
       "1                                    -0.903320   \n",
       "2                                    -1.329102   \n",
       "3                                    -1.636719   \n",
       "4                                    -0.416260   \n",
       "\n",
       "   ../input/readability-training-v52/pred_rep1  \\\n",
       "0                                    -0.080505   \n",
       "1                                    -0.686035   \n",
       "2                                    -1.380859   \n",
       "3                                    -1.504883   \n",
       "4                                    -0.548828   \n",
       "\n",
       "   ../input/readability-training-v52/pred_rep2  \\\n",
       "0                                    -0.219849   \n",
       "1                                    -0.626465   \n",
       "2                                    -1.110352   \n",
       "3                                    -1.704102   \n",
       "4                                    -0.482178   \n",
       "\n",
       "   ../input/readability-training-v55/pred_rep0  \\\n",
       "0                                    -0.005001   \n",
       "1                                    -0.957520   \n",
       "2                                    -1.357422   \n",
       "3                                    -1.652344   \n",
       "4                                    -0.411621   \n",
       "\n",
       "   ../input/readability-training-v55/pred_rep1  \\\n",
       "0                                    -0.157104   \n",
       "1                                    -0.826172   \n",
       "2                                    -1.338867   \n",
       "3                                    -1.524414   \n",
       "4                                    -0.559082   \n",
       "\n",
       "   ../input/readability-training-v55/pred_rep2  \\\n",
       "0                                    -0.129272   \n",
       "1                                    -0.642090   \n",
       "2                                    -1.095703   \n",
       "3                                    -1.731445   \n",
       "4                                    -0.450684   \n",
       "\n",
       "   ../input/readability-training-v56/pred_rep0  \\\n",
       "0                                    -0.017303   \n",
       "1                                    -0.791016   \n",
       "2                                    -1.258789   \n",
       "3                                    -1.528320   \n",
       "4                                    -0.627441   \n",
       "\n",
       "   ../input/readability-training-v56/pred_rep1  \\\n",
       "0                                    -0.143555   \n",
       "1                                    -0.720215   \n",
       "2                                    -1.320312   \n",
       "3                                    -1.444336   \n",
       "4                                    -0.629395   \n",
       "\n",
       "   ../input/readability-training-v56/pred_rep2  \\\n",
       "0                                    -0.205200   \n",
       "1                                    -0.596191   \n",
       "2                                    -1.091797   \n",
       "3                                    -1.569336   \n",
       "4                                    -0.654785   \n",
       "\n",
       "   ../input/readability-training-v59/pred_rep0  \\\n",
       "0                                    -0.152588   \n",
       "1                                    -0.711426   \n",
       "2                                    -0.928223   \n",
       "3                                    -1.567383   \n",
       "4                                    -0.095337   \n",
       "\n",
       "   ../input/readability-training-v59/pred_rep1  \\\n",
       "0                                    -0.250244   \n",
       "1                                    -0.622559   \n",
       "2                                    -1.145508   \n",
       "3                                    -1.583984   \n",
       "4                                    -0.231567   \n",
       "\n",
       "   ../input/readability-training-v59/pred_rep2  \\\n",
       "0                                    -0.130127   \n",
       "1                                    -0.568848   \n",
       "2                                    -0.876465   \n",
       "3                                    -1.522461   \n",
       "4                                    -0.051514   \n",
       "\n",
       "   ../input/readability-v62/pred_rep0  ../input/readability-v62/pred_rep1  \\\n",
       "0                           -0.245239                           -0.096924   \n",
       "1                           -1.217773                           -0.930176   \n",
       "2                           -1.044922                           -1.076172   \n",
       "3                           -1.288086                           -1.395508   \n",
       "4                           -0.344727                           -0.394531   \n",
       "\n",
       "   ../input/readability-v62/pred_rep2  ../input/readability-v69/pred_rep0  \\\n",
       "0                           -0.161621                           -0.359863   \n",
       "1                           -0.874512                           -0.971191   \n",
       "2                           -0.935547                           -0.937988   \n",
       "3                           -1.555664                           -1.360352   \n",
       "4                           -0.545410                           -0.569824   \n",
       "\n",
       "   ../input/readability-v69/pred_rep1  ../input/readability-v69/pred_rep2  \\\n",
       "0                           -0.115051                           -0.346680   \n",
       "1                           -0.853027                           -0.947754   \n",
       "2                           -0.908203                           -0.829590   \n",
       "3                           -1.143555                           -1.252930   \n",
       "4                           -0.476807                           -0.583984   \n",
       "\n",
       "   ../input/readability-training-v56/  ../input/readability-training-v55/  \\\n",
       "0                           -0.080429                           -0.081053   \n",
       "1                           -0.755615                           -0.891846   \n",
       "2                           -1.289551                           -1.348145   \n",
       "3                           -1.486328                           -1.588379   \n",
       "4                           -0.628418                           -0.485352   \n",
       "\n",
       "   ../input/readability-training-v52/  ../input/readability-v62/  \\\n",
       "0                           -0.077881                  -0.171082   \n",
       "1                           -0.794678                  -1.073975   \n",
       "2                           -1.354980                  -1.060547   \n",
       "3                           -1.570801                  -1.341797   \n",
       "4                           -0.482544                  -0.369629   \n",
       "\n",
       "   ../input/readability-v36/  ../input/readability-v47/  \\\n",
       "0                  -0.183960                  -0.109375   \n",
       "1                  -0.919922                  -0.806885   \n",
       "2                  -1.099609                  -1.172852   \n",
       "3                  -1.303711                  -1.533691   \n",
       "4                  -0.557251                  -0.345337   \n",
       "\n",
       "   ../input/readability-v69/  ../input/readability-training-v59/     amean  \\\n",
       "0                  -0.237457                           -0.201416 -0.142832   \n",
       "1                  -0.912109                           -0.666992 -0.852753   \n",
       "2                  -0.923096                           -1.036865 -1.160706   \n",
       "3                  -1.251953                           -1.575684 -1.456543   \n",
       "4                  -0.523315                           -0.163452 -0.444412   \n",
       "\n",
       "     median  standard_error  flesch_reading_ease  smog_index  \\\n",
       "0 -0.140228        0.480805                71.24         8.8   \n",
       "1 -0.849365        0.477028                66.20        12.2   \n",
       "2 -1.136230        0.496148                74.02         8.1   \n",
       "3 -1.510010        0.526079                60.79        12.7   \n",
       "4 -0.483948        0.481323                80.65         7.2   \n",
       "\n",
       "   flesch_kincaid_grade  coleman_liau_index  automated_readability_index  \\\n",
       "0                   7.5                6.90                          7.8   \n",
       "1                  11.5                8.19                         14.1   \n",
       "2                   8.5                7.38                          9.9   \n",
       "3                  11.5               10.62                         14.8   \n",
       "4                   8.0                7.38                         10.9   \n",
       "\n",
       "   dale_chall_readability_score  difficult_words  linsear_write_formula  \\\n",
       "0                          6.06               17               8.500000   \n",
       "1                          6.44               15              19.666667   \n",
       "2                          6.51               20              10.800000   \n",
       "3                          8.09               32              15.750000   \n",
       "4                          5.71                8              10.200000   \n",
       "\n",
       "   gunning_fog2  text_standard  mean_parse_tree_depth  total_sentences  ...  \\\n",
       "0          8.65            9.0               0.805310               17  ...   \n",
       "1         13.63           12.0               1.413462                6  ...   \n",
       "2          9.89            7.0               1.029126                8  ...   \n",
       "3         13.82           12.0               1.127072                6  ...   \n",
       "4          9.99            8.0               1.193939                8  ...   \n",
       "\n",
       "   semicolons  quotes  nonstop_char_count  nonstop_word_count  \\\n",
       "0           0      12            8.820896            1.746269   \n",
       "1           0       0            8.813559            1.508475   \n",
       "2           2       0            9.016667            1.550000   \n",
       "3           0       0           10.823529            1.568627   \n",
       "4           0       4            9.088889            1.600000   \n",
       "\n",
       "   words_per_sentence  ents_per_sentence  chars_per_sentence  chars_per_word  \\\n",
       "0            9.941176           0.176471           55.117647        5.544379   \n",
       "1           30.166667           1.833333          162.666667        5.392265   \n",
       "2           22.125000           1.000000          119.625000        5.406780   \n",
       "3           27.000000           0.666667          159.333333        5.901235   \n",
       "4           18.125000           0.625000           97.250000        5.365517   \n",
       "\n",
       "   punctutation_per_word  mean_adj  mean_adp  mean_adv  mean_aux  mean_cconj  \\\n",
       "0               3.117647      1.08      1.08      1.67      0.92        0.58   \n",
       "1               2.500000      1.83      3.67      2.50      2.33        0.67   \n",
       "2               2.125000      1.25      2.62      1.38      2.00        1.25   \n",
       "3               3.000000      2.00      3.17      1.17      1.50        1.33   \n",
       "4               2.500000      1.14      2.86      0.86      0.71        0.86   \n",
       "\n",
       "   mean_det  mean_intj  mean_noun  mean_num  mean_part  mean_pron  mean_propn  \\\n",
       "0      1.25       0.25       1.83      0.00       0.58       2.00        0.42   \n",
       "1      4.50       0.00       3.83      0.50       1.67       2.83        1.17   \n",
       "2      3.25       0.00       4.25      0.25       1.00       1.50        1.38   \n",
       "3      4.83       0.00       5.17      0.50       0.33       2.33        0.17   \n",
       "4      3.75       0.00       3.38      0.00       0.43       2.00        0.86   \n",
       "\n",
       "   mean_punct  mean_sconj  mean_verb  mean_x  mean_space  mean_sym  \\\n",
       "0        3.58        0.08       2.58     0.0        0.92       NaN   \n",
       "1        2.14        1.17       4.50     0.0        1.00       NaN   \n",
       "2        1.62        0.75       2.38     0.0        0.88       NaN   \n",
       "3        2.17        1.50       3.17     0.0        0.83       NaN   \n",
       "4        1.86        0.43       2.57     0.0        0.86       NaN   \n",
       "\n",
       "   complex_words  long_words    kincaid        ari  coleman_liau     flesch  \\\n",
       "0             12          26   9.722558  12.427926      7.541115  76.415078   \n",
       "1             15          24  35.199064  44.764492      8.156792   9.236243   \n",
       "2             11          19  34.796639  43.829180      8.230630   8.559221   \n",
       "3             27          41  33.554321  41.660556     12.035429  -1.235556   \n",
       "4              7          18  16.850345  22.681080      8.485173  60.340805   \n",
       "\n",
       "   gunning_fog         lix       smog        rix  dale_chall  tobeverb  \\\n",
       "0    14.257364   43.782946  10.745967   4.333333    7.628832         5   \n",
       "1    40.608556  106.334225  18.000000  12.000000   10.807255         9   \n",
       "2    39.004372  101.882514  15.845233   9.500000   11.798834         9   \n",
       "3    39.066667  106.308642  23.124612  20.500000   11.942742         6   \n",
       "4    21.264368   60.747126  11.366600   6.000000    8.102868         4   \n",
       "\n",
       "   auxverb  conjunction  pronoun  preposition  nominalization  pronoun_b  \\\n",
       "0        5            7       30           22               0          0   \n",
       "1        7            5       19           25               0          1   \n",
       "2        2           10       17           20               1          0   \n",
       "3        1            8       27           23               4          0   \n",
       "4        2            6       20           22               0          1   \n",
       "\n",
       "   interrogative  article  subordination  conjunction_b  preposition_b  \n",
       "0              0        0              0              0              1  \n",
       "1              0        0              0              0              0  \n",
       "2              0        0              0              0              0  \n",
       "3              0        0              1              1              1  \n",
       "4              0        0              0              0              0  \n",
       "\n",
       "[5 rows x 106 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "####### ADD TRAIN FEATURES\n",
    "\n",
    "train_feats = pd.read_csv('/kaggle/input/readability-features/features_train.csv')\n",
    "train_feats.drop(['url_legal', 'license', 'excerpt', 'target'], axis = 1, inplace = True)\n",
    "df_train = df_train.merge(train_feats, how = 'left', on = 'id')\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "00e3a375",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-02T20:56:40.195377Z",
     "iopub.status.busy": "2021-08-02T20:56:40.179626Z",
     "iopub.status.idle": "2021-08-02T20:57:40.353943Z",
     "shell.execute_reply": "2021-08-02T20:57:40.354412Z",
     "shell.execute_reply.started": "2021-08-02T20:00:53.917255Z"
    },
    "papermill": {
     "duration": 60.244317,
     "end_time": "2021-08-02T20:57:40.354590",
     "exception": false,
     "start_time": "2021-08-02T20:56:40.110273",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /kaggle/input/textstat/Pyphen-0.10.0-py3-none-any.whl\r\n",
      "Installing collected packages: Pyphen\r\n",
      "Successfully installed Pyphen-0.10.0\r\n",
      "\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\r\n",
      "Processing /kaggle/input/textstat/textstat-0.7.0-py3-none-any.whl\r\n",
      "Requirement already satisfied: pyphen in /opt/conda/lib/python3.7/site-packages (from textstat==0.7.0) (0.10.0)\r\n",
      "Installing collected packages: textstat\r\n",
      "Successfully installed textstat-0.7.0\r\n",
      "\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\r\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "200863b3eb3f493398aa44ee86ed4820",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 80)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>../input/readability-training-v56/</th>\n",
       "      <th>../input/readability-training-v55/</th>\n",
       "      <th>../input/readability-training-v52/</th>\n",
       "      <th>../input/readability-v62/</th>\n",
       "      <th>../input/readability-v36/</th>\n",
       "      <th>../input/readability-v47/</th>\n",
       "      <th>../input/readability-v69/</th>\n",
       "      <th>../input/readability-training-v59/</th>\n",
       "      <th>pred</th>\n",
       "      <th>url_legal</th>\n",
       "      <th>license</th>\n",
       "      <th>excerpt</th>\n",
       "      <th>flesch_reading_ease</th>\n",
       "      <th>smog_index</th>\n",
       "      <th>flesch_kincaid_grade</th>\n",
       "      <th>coleman_liau_index</th>\n",
       "      <th>automated_readability_index</th>\n",
       "      <th>dale_chall_readability_score</th>\n",
       "      <th>difficult_words</th>\n",
       "      <th>linsear_write_formula</th>\n",
       "      <th>gunning_fog2</th>\n",
       "      <th>text_standard</th>\n",
       "      <th>mean_parse_tree_depth</th>\n",
       "      <th>total_sentences</th>\n",
       "      <th>total_words</th>\n",
       "      <th>total_ents</th>\n",
       "      <th>total_chars</th>\n",
       "      <th>total_punctutation</th>\n",
       "      <th>unique_words</th>\n",
       "      <th>nonstop_token_proportion</th>\n",
       "      <th>semicolons</th>\n",
       "      <th>quotes</th>\n",
       "      <th>nonstop_char_count</th>\n",
       "      <th>nonstop_word_count</th>\n",
       "      <th>words_per_sentence</th>\n",
       "      <th>ents_per_sentence</th>\n",
       "      <th>chars_per_sentence</th>\n",
       "      <th>chars_per_word</th>\n",
       "      <th>punctutation_per_word</th>\n",
       "      <th>mean_adj</th>\n",
       "      <th>mean_adp</th>\n",
       "      <th>mean_adv</th>\n",
       "      <th>mean_aux</th>\n",
       "      <th>mean_cconj</th>\n",
       "      <th>mean_det</th>\n",
       "      <th>mean_intj</th>\n",
       "      <th>mean_noun</th>\n",
       "      <th>mean_num</th>\n",
       "      <th>mean_part</th>\n",
       "      <th>mean_pron</th>\n",
       "      <th>mean_propn</th>\n",
       "      <th>mean_punct</th>\n",
       "      <th>mean_sconj</th>\n",
       "      <th>mean_verb</th>\n",
       "      <th>mean_x</th>\n",
       "      <th>mean_space</th>\n",
       "      <th>complex_words</th>\n",
       "      <th>long_words</th>\n",
       "      <th>kincaid</th>\n",
       "      <th>ari</th>\n",
       "      <th>coleman_liau</th>\n",
       "      <th>flesch</th>\n",
       "      <th>gunning_fog</th>\n",
       "      <th>lix</th>\n",
       "      <th>smog</th>\n",
       "      <th>rix</th>\n",
       "      <th>dale_chall</th>\n",
       "      <th>tobeverb</th>\n",
       "      <th>auxverb</th>\n",
       "      <th>conjunction</th>\n",
       "      <th>pronoun</th>\n",
       "      <th>preposition</th>\n",
       "      <th>nominalization</th>\n",
       "      <th>pronoun_b</th>\n",
       "      <th>interrogative</th>\n",
       "      <th>article</th>\n",
       "      <th>subordination</th>\n",
       "      <th>conjunction_b</th>\n",
       "      <th>preposition_b</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c0f722661</td>\n",
       "      <td>-0.407019</td>\n",
       "      <td>-0.418115</td>\n",
       "      <td>-0.428809</td>\n",
       "      <td>-0.417407</td>\n",
       "      <td>-0.363428</td>\n",
       "      <td>-0.569788</td>\n",
       "      <td>-0.336011</td>\n",
       "      <td>-0.313513</td>\n",
       "      <td>-0.406761</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>My hope lay in Jack's promise that he would ke...</td>\n",
       "      <td>71.68</td>\n",
       "      <td>8.8</td>\n",
       "      <td>9.4</td>\n",
       "      <td>6.56</td>\n",
       "      <td>10.5</td>\n",
       "      <td>6.24</td>\n",
       "      <td>13</td>\n",
       "      <td>11.00</td>\n",
       "      <td>10.99</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.784431</td>\n",
       "      <td>8</td>\n",
       "      <td>149</td>\n",
       "      <td>5</td>\n",
       "      <td>772</td>\n",
       "      <td>18</td>\n",
       "      <td>149</td>\n",
       "      <td>0.517857</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>8.867925</td>\n",
       "      <td>1.622642</td>\n",
       "      <td>18.625000</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>96.500000</td>\n",
       "      <td>5.181208</td>\n",
       "      <td>2.250000</td>\n",
       "      <td>2.33</td>\n",
       "      <td>2.62</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.67</td>\n",
       "      <td>3.57</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>0.17</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.86</td>\n",
       "      <td>0.17</td>\n",
       "      <td>1.67</td>\n",
       "      <td>0.83</td>\n",
       "      <td>2.75</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>8</td>\n",
       "      <td>25</td>\n",
       "      <td>17.912667</td>\n",
       "      <td>22.567000</td>\n",
       "      <td>7.322849</td>\n",
       "      <td>55.693000</td>\n",
       "      <td>22.133333</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>11.944272</td>\n",
       "      <td>8.333333</td>\n",
       "      <td>8.221833</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>f0953f0a5</td>\n",
       "      <td>-0.775049</td>\n",
       "      <td>-0.650342</td>\n",
       "      <td>-0.656812</td>\n",
       "      <td>-0.406238</td>\n",
       "      <td>-0.452954</td>\n",
       "      <td>-0.715674</td>\n",
       "      <td>-0.301917</td>\n",
       "      <td>-0.492480</td>\n",
       "      <td>-0.556433</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Dotty continued to go to Mrs. Gray's every nig...</td>\n",
       "      <td>84.81</td>\n",
       "      <td>5.8</td>\n",
       "      <td>6.4</td>\n",
       "      <td>6.67</td>\n",
       "      <td>8.7</td>\n",
       "      <td>5.59</td>\n",
       "      <td>11</td>\n",
       "      <td>10.40</td>\n",
       "      <td>8.30</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.916279</td>\n",
       "      <td>12</td>\n",
       "      <td>181</td>\n",
       "      <td>9</td>\n",
       "      <td>967</td>\n",
       "      <td>32</td>\n",
       "      <td>181</td>\n",
       "      <td>0.525822</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>9.796610</td>\n",
       "      <td>1.898305</td>\n",
       "      <td>15.083333</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>80.583333</td>\n",
       "      <td>5.342541</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>0.73</td>\n",
       "      <td>1.55</td>\n",
       "      <td>1.09</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.82</td>\n",
       "      <td>2.09</td>\n",
       "      <td>0.09</td>\n",
       "      <td>2.27</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.73</td>\n",
       "      <td>1.64</td>\n",
       "      <td>1.64</td>\n",
       "      <td>1.91</td>\n",
       "      <td>0.36</td>\n",
       "      <td>3.36</td>\n",
       "      <td>0</td>\n",
       "      <td>0.82</td>\n",
       "      <td>9</td>\n",
       "      <td>15</td>\n",
       "      <td>21.925652</td>\n",
       "      <td>28.486232</td>\n",
       "      <td>7.747490</td>\n",
       "      <td>47.107754</td>\n",
       "      <td>26.489855</td>\n",
       "      <td>69.485507</td>\n",
       "      <td>12.486833</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>9.424720</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>18</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0df072751</td>\n",
       "      <td>-0.399255</td>\n",
       "      <td>-0.423889</td>\n",
       "      <td>-0.453345</td>\n",
       "      <td>-0.415808</td>\n",
       "      <td>-0.413208</td>\n",
       "      <td>-0.376318</td>\n",
       "      <td>-0.374390</td>\n",
       "      <td>-0.365051</td>\n",
       "      <td>-0.402658</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>It was a bright and cheerful scene that greete...</td>\n",
       "      <td>67.42</td>\n",
       "      <td>9.7</td>\n",
       "      <td>11.1</td>\n",
       "      <td>7.67</td>\n",
       "      <td>13.6</td>\n",
       "      <td>6.98</td>\n",
       "      <td>21</td>\n",
       "      <td>14.00</td>\n",
       "      <td>12.52</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>13</td>\n",
       "      <td>174</td>\n",
       "      <td>15</td>\n",
       "      <td>948</td>\n",
       "      <td>40</td>\n",
       "      <td>174</td>\n",
       "      <td>0.493088</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>7.900000</td>\n",
       "      <td>1.528571</td>\n",
       "      <td>13.384615</td>\n",
       "      <td>1.153846</td>\n",
       "      <td>72.923077</td>\n",
       "      <td>5.448276</td>\n",
       "      <td>3.076923</td>\n",
       "      <td>1.43</td>\n",
       "      <td>2.14</td>\n",
       "      <td>1.57</td>\n",
       "      <td>1.30</td>\n",
       "      <td>1.57</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.57</td>\n",
       "      <td>3.50</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.57</td>\n",
       "      <td>2.10</td>\n",
       "      <td>2.71</td>\n",
       "      <td>2.70</td>\n",
       "      <td>0.29</td>\n",
       "      <td>1.88</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>8</td>\n",
       "      <td>26</td>\n",
       "      <td>8.049615</td>\n",
       "      <td>10.627039</td>\n",
       "      <td>7.182680</td>\n",
       "      <td>82.641854</td>\n",
       "      <td>11.969181</td>\n",
       "      <td>40.035313</td>\n",
       "      <td>8.855400</td>\n",
       "      <td>3.714286</td>\n",
       "      <td>8.357364</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>27</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>04caf4e0c</td>\n",
       "      <td>-2.496289</td>\n",
       "      <td>-2.488867</td>\n",
       "      <td>-2.459375</td>\n",
       "      <td>-2.241211</td>\n",
       "      <td>-2.279492</td>\n",
       "      <td>-2.507227</td>\n",
       "      <td>-2.159277</td>\n",
       "      <td>-2.533789</td>\n",
       "      <td>-2.395691</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Cell_division</td>\n",
       "      <td>CC BY-SA 3.0</td>\n",
       "      <td>Cell division is the process by which a parent...</td>\n",
       "      <td>36.93</td>\n",
       "      <td>16.8</td>\n",
       "      <td>14.5</td>\n",
       "      <td>13.29</td>\n",
       "      <td>16.2</td>\n",
       "      <td>9.03</td>\n",
       "      <td>47</td>\n",
       "      <td>17.25</td>\n",
       "      <td>16.28</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1.386139</td>\n",
       "      <td>7</td>\n",
       "      <td>180</td>\n",
       "      <td>9</td>\n",
       "      <td>1144</td>\n",
       "      <td>19</td>\n",
       "      <td>180</td>\n",
       "      <td>0.566502</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14.258621</td>\n",
       "      <td>1.982759</td>\n",
       "      <td>25.714286</td>\n",
       "      <td>1.285714</td>\n",
       "      <td>163.428571</td>\n",
       "      <td>6.355556</td>\n",
       "      <td>2.714286</td>\n",
       "      <td>2.43</td>\n",
       "      <td>3.43</td>\n",
       "      <td>1.80</td>\n",
       "      <td>1.83</td>\n",
       "      <td>0.80</td>\n",
       "      <td>3.14</td>\n",
       "      <td>0.00</td>\n",
       "      <td>9.00</td>\n",
       "      <td>1.20</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.60</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.40</td>\n",
       "      <td>2.29</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>50</td>\n",
       "      <td>64</td>\n",
       "      <td>23.003333</td>\n",
       "      <td>25.666667</td>\n",
       "      <td>14.247589</td>\n",
       "      <td>10.290000</td>\n",
       "      <td>29.111111</td>\n",
       "      <td>80.555556</td>\n",
       "      <td>22.364917</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>12.184500</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>28</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0e63f8bea</td>\n",
       "      <td>-1.726758</td>\n",
       "      <td>-1.779590</td>\n",
       "      <td>-1.770117</td>\n",
       "      <td>-1.858301</td>\n",
       "      <td>-1.881738</td>\n",
       "      <td>-1.788184</td>\n",
       "      <td>-1.840430</td>\n",
       "      <td>-1.871289</td>\n",
       "      <td>-1.814551</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Debugging</td>\n",
       "      <td>CC BY-SA 3.0</td>\n",
       "      <td>Debugging is the process of finding and resolv...</td>\n",
       "      <td>34.60</td>\n",
       "      <td>17.7</td>\n",
       "      <td>15.4</td>\n",
       "      <td>13.87</td>\n",
       "      <td>18.1</td>\n",
       "      <td>10.01</td>\n",
       "      <td>53</td>\n",
       "      <td>15.20</td>\n",
       "      <td>17.87</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1.375000</td>\n",
       "      <td>6</td>\n",
       "      <td>168</td>\n",
       "      <td>5</td>\n",
       "      <td>1094</td>\n",
       "      <td>31</td>\n",
       "      <td>168</td>\n",
       "      <td>0.577114</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>12.515625</td>\n",
       "      <td>1.812500</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>182.333333</td>\n",
       "      <td>6.511905</td>\n",
       "      <td>5.166667</td>\n",
       "      <td>1.33</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1.33</td>\n",
       "      <td>1.67</td>\n",
       "      <td>1.17</td>\n",
       "      <td>2.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7.50</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.67</td>\n",
       "      <td>2.17</td>\n",
       "      <td>4.50</td>\n",
       "      <td>1.00</td>\n",
       "      <td>4.67</td>\n",
       "      <td>0</td>\n",
       "      <td>0.83</td>\n",
       "      <td>35</td>\n",
       "      <td>64</td>\n",
       "      <td>37.679524</td>\n",
       "      <td>45.633929</td>\n",
       "      <td>15.136174</td>\n",
       "      <td>-25.467857</td>\n",
       "      <td>41.933333</td>\n",
       "      <td>122.095238</td>\n",
       "      <td>25.912878</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>15.697900</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>22</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  ../input/readability-training-v56/  \\\n",
       "0  c0f722661                           -0.407019   \n",
       "1  f0953f0a5                           -0.775049   \n",
       "2  0df072751                           -0.399255   \n",
       "3  04caf4e0c                           -2.496289   \n",
       "4  0e63f8bea                           -1.726758   \n",
       "\n",
       "   ../input/readability-training-v55/  ../input/readability-training-v52/  \\\n",
       "0                           -0.418115                           -0.428809   \n",
       "1                           -0.650342                           -0.656812   \n",
       "2                           -0.423889                           -0.453345   \n",
       "3                           -2.488867                           -2.459375   \n",
       "4                           -1.779590                           -1.770117   \n",
       "\n",
       "   ../input/readability-v62/  ../input/readability-v36/  \\\n",
       "0                  -0.417407                  -0.363428   \n",
       "1                  -0.406238                  -0.452954   \n",
       "2                  -0.415808                  -0.413208   \n",
       "3                  -2.241211                  -2.279492   \n",
       "4                  -1.858301                  -1.881738   \n",
       "\n",
       "   ../input/readability-v47/  ../input/readability-v69/  \\\n",
       "0                  -0.569788                  -0.336011   \n",
       "1                  -0.715674                  -0.301917   \n",
       "2                  -0.376318                  -0.374390   \n",
       "3                  -2.507227                  -2.159277   \n",
       "4                  -1.788184                  -1.840430   \n",
       "\n",
       "   ../input/readability-training-v59/      pred  \\\n",
       "0                           -0.313513 -0.406761   \n",
       "1                           -0.492480 -0.556433   \n",
       "2                           -0.365051 -0.402658   \n",
       "3                           -2.533789 -2.395691   \n",
       "4                           -1.871289 -1.814551   \n",
       "\n",
       "                                     url_legal       license  \\\n",
       "0                                          NaN           NaN   \n",
       "1                                          NaN           NaN   \n",
       "2                                          NaN           NaN   \n",
       "3  https://en.wikipedia.org/wiki/Cell_division  CC BY-SA 3.0   \n",
       "4      https://en.wikipedia.org/wiki/Debugging  CC BY-SA 3.0   \n",
       "\n",
       "                                             excerpt  flesch_reading_ease  \\\n",
       "0  My hope lay in Jack's promise that he would ke...                71.68   \n",
       "1  Dotty continued to go to Mrs. Gray's every nig...                84.81   \n",
       "2  It was a bright and cheerful scene that greete...                67.42   \n",
       "3  Cell division is the process by which a parent...                36.93   \n",
       "4  Debugging is the process of finding and resolv...                34.60   \n",
       "\n",
       "   smog_index  flesch_kincaid_grade  coleman_liau_index  \\\n",
       "0         8.8                   9.4                6.56   \n",
       "1         5.8                   6.4                6.67   \n",
       "2         9.7                  11.1                7.67   \n",
       "3        16.8                  14.5               13.29   \n",
       "4        17.7                  15.4               13.87   \n",
       "\n",
       "   automated_readability_index  dale_chall_readability_score  difficult_words  \\\n",
       "0                         10.5                          6.24               13   \n",
       "1                          8.7                          5.59               11   \n",
       "2                         13.6                          6.98               21   \n",
       "3                         16.2                          9.03               47   \n",
       "4                         18.1                         10.01               53   \n",
       "\n",
       "   linsear_write_formula  gunning_fog2  text_standard  mean_parse_tree_depth  \\\n",
       "0                  11.00         10.99           11.0               1.784431   \n",
       "1                  10.40          8.30            6.0               0.916279   \n",
       "2                  14.00         12.52           14.0               1.000000   \n",
       "3                  17.25         16.28           17.0               1.386139   \n",
       "4                  15.20         17.87           18.0               1.375000   \n",
       "\n",
       "   total_sentences  total_words  total_ents  total_chars  total_punctutation  \\\n",
       "0                8          149           5          772                  18   \n",
       "1               12          181           9          967                  32   \n",
       "2               13          174          15          948                  40   \n",
       "3                7          180           9         1144                  19   \n",
       "4                6          168           5         1094                  31   \n",
       "\n",
       "   unique_words  nonstop_token_proportion  semicolons  quotes  \\\n",
       "0           149                  0.517857           0       4   \n",
       "1           181                  0.525822           2       8   \n",
       "2           174                  0.493088           1      10   \n",
       "3           180                  0.566502           0       0   \n",
       "4           168                  0.577114           0      10   \n",
       "\n",
       "   nonstop_char_count  nonstop_word_count  words_per_sentence  \\\n",
       "0            8.867925            1.622642           18.625000   \n",
       "1            9.796610            1.898305           15.083333   \n",
       "2            7.900000            1.528571           13.384615   \n",
       "3           14.258621            1.982759           25.714286   \n",
       "4           12.515625            1.812500           28.000000   \n",
       "\n",
       "   ents_per_sentence  chars_per_sentence  chars_per_word  \\\n",
       "0           0.625000           96.500000        5.181208   \n",
       "1           0.750000           80.583333        5.342541   \n",
       "2           1.153846           72.923077        5.448276   \n",
       "3           1.285714          163.428571        6.355556   \n",
       "4           0.833333          182.333333        6.511905   \n",
       "\n",
       "   punctutation_per_word  mean_adj  mean_adp  mean_adv  mean_aux  mean_cconj  \\\n",
       "0               2.250000      2.33      2.62      0.83      0.83        0.67   \n",
       "1               2.666667      0.73      1.55      1.09      0.45        0.82   \n",
       "2               3.076923      1.43      2.14      1.57      1.30        1.57   \n",
       "3               2.714286      2.43      3.43      1.80      1.83        0.80   \n",
       "4               5.166667      1.33      3.00      1.33      1.67        1.17   \n",
       "\n",
       "   mean_det  mean_intj  mean_noun  mean_num  mean_part  mean_pron  mean_propn  \\\n",
       "0      3.57       0.00       4.00      0.17       1.00       1.86        0.17   \n",
       "1      2.09       0.09       2.27      0.00       0.73       1.64        1.64   \n",
       "2      3.00       0.57       3.50      0.14       0.57       2.10        2.71   \n",
       "3      3.14       0.00       9.00      1.20       0.40       0.20        0.60   \n",
       "4      2.50       0.00       7.50      0.33       0.67       0.67        2.17   \n",
       "\n",
       "   mean_punct  mean_sconj  mean_verb  mean_x  mean_space  complex_words  \\\n",
       "0        1.67        0.83       2.75       0        1.00              8   \n",
       "1        1.91        0.36       3.36       0        0.82              9   \n",
       "2        2.70        0.29       1.88       0        1.00              8   \n",
       "3        3.20        0.40       2.29       0        1.00             50   \n",
       "4        4.50        1.00       4.67       0        0.83             35   \n",
       "\n",
       "   long_words    kincaid        ari  coleman_liau     flesch  gunning_fog  \\\n",
       "0          25  17.912667  22.567000      7.322849  55.693000    22.133333   \n",
       "1          15  21.925652  28.486232      7.747490  47.107754    26.489855   \n",
       "2          26   8.049615  10.627039      7.182680  82.641854    11.969181   \n",
       "3          64  23.003333  25.666667     14.247589  10.290000    29.111111   \n",
       "4          64  37.679524  45.633929     15.136174 -25.467857    41.933333   \n",
       "\n",
       "          lix       smog        rix  dale_chall  tobeverb  auxverb  \\\n",
       "0   66.666667  11.944272   8.333333    8.221833         4        3   \n",
       "1   69.485507  12.486833   5.000000    9.424720         5        6   \n",
       "2   40.035313   8.855400   3.714286    8.357364         8        0   \n",
       "3   80.555556  22.364917  16.000000   12.184500        11        0   \n",
       "4  122.095238  25.912878  32.000000   15.697900         8        1   \n",
       "\n",
       "   conjunction  pronoun  preposition  nominalization  pronoun_b  \\\n",
       "0            4       20           27               1          1   \n",
       "1            9       18           21               0          0   \n",
       "2           11       27           15               0          2   \n",
       "3            4        3           28               2          0   \n",
       "4            7        7           22               5          0   \n",
       "\n",
       "   interrogative  article  subordination  conjunction_b  preposition_b  \n",
       "0              0        0              0              0              0  \n",
       "1              0        0              0              0              0  \n",
       "2              1        0              0              0              0  \n",
       "3              0        0              0              0              0  \n",
       "4              0        0              0              0              0  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "####### COMPUTE TEST FEATURES\n",
    "\n",
    "!pip install '../input/textstat/Pyphen-0.10.0-py3-none-any.whl'\n",
    "!pip install '../input/textstat/textstat-0.7.0-py3-none-any.whl'\n",
    "sys.path = ['../input/readability-package'] + sys.path\n",
    "\n",
    "import readability\n",
    "import spacy\n",
    "from textstat import textstat\n",
    "\n",
    "import re\n",
    "import en_core_web_sm\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "nlp         = en_core_web_sm.load()\n",
    "STOPWORDS   = stopwords.words(\"english\")\n",
    "PUNCTUATION = list(string.punctuation)\n",
    "POS_TAGS    = [\"ADJ\",\"ADP\",\"ADV\",\"AUX\",\"CCONJ\",\"DET\",\"INTJ\",\"NOUN\",\"NUM\",\"PART\",\"PRON\",\"PROPN\",\"PUNCT\",\"SCONJ\",\"VERB\",\"X\",\"SPACE\"]\n",
    "\n",
    "\n",
    "def readability_measurements(passage: str):\n",
    "    \"\"\"\n",
    "    This function uses the readability library for feature engineering.\n",
    "    It includes textual statistics, readability scales and metric, and some pos stats\n",
    "    \"\"\"\n",
    "    results = readability.getmeasures(passage, lang='en')\n",
    "    \n",
    "    complex_words  = results['sentence info']['complex_words']\n",
    "    long_words     = results['sentence info']['long_words']\n",
    "    \n",
    "    kincaid      = results['readability grades']['Kincaid']\n",
    "    ari          = results['readability grades']['ARI']\n",
    "    coleman_liau = results['readability grades']['Coleman-Liau']\n",
    "    flesch       = results['readability grades']['FleschReadingEase']\n",
    "    gunning_fog  = results['readability grades']['GunningFogIndex']\n",
    "    lix          = results['readability grades']['LIX']\n",
    "    smog         = results['readability grades']['SMOGIndex']\n",
    "    rix          = results['readability grades']['RIX']\n",
    "    dale_chall   = results['readability grades']['DaleChallIndex']\n",
    "    \n",
    "    tobeverb       = results['word usage']['tobeverb']\n",
    "    auxverb        = results['word usage']['auxverb']\n",
    "    conjunction    = results['word usage']['conjunction']\n",
    "    pronoun        = results['word usage']['pronoun']\n",
    "    preposition    = results['word usage']['preposition']\n",
    "    nominalization = results['word usage']['nominalization']\n",
    "    \n",
    "    pronoun_b     = results['sentence beginnings']['pronoun']\n",
    "    interrogative = results['sentence beginnings']['interrogative']\n",
    "    article       = results['sentence beginnings']['article']\n",
    "    subordination = results['sentence beginnings']['subordination']\n",
    "    conjunction_b = results['sentence beginnings']['conjunction']\n",
    "    preposition_b = results['sentence beginnings']['preposition']\n",
    "\n",
    "    \n",
    "    return [complex_words, long_words,\n",
    "            kincaid, ari, coleman_liau, flesch, gunning_fog, lix, smog, rix, dale_chall,\n",
    "            tobeverb, auxverb, conjunction, pronoun, preposition, nominalization,\n",
    "            pronoun_b, interrogative, article, subordination, conjunction_b, preposition_b]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def simplify_punctuation(text):\n",
    "    # from https://github.com/shivam5992/textstat/issues/77\n",
    "    text = re.sub(r\"[,:;()\\-]\", \" \", text)  # Override commas, colons, etc to spaces/\n",
    "    text = re.sub(r\"[\\.!?]\", \".\", text)  # Change all terminators like ! and ? to \".\"\n",
    "    text = re.sub(r\"^\\s+\", \"\", text)  # Remove white space\n",
    "    text = re.sub(r\"[ ]*(\\n|\\r\\n|\\r)[ ]*\", \" \", text)  # Remove new lines\n",
    "    text = re.sub(r\"([\\.])[\\. ]+\", \".\", text)  # Change all \"..\" to \".\"\n",
    "    text = re.sub(r\"[ ]*([\\.])\", \". \", text)  # Normalize all \".\"`\n",
    "    text = re.sub(r\"\\s+\", \" \", text)  # Remove multiple spaces\n",
    "    text = re.sub(r\"\\s+$\", \"\", text)  # Remove trailing spaces\n",
    "    return text\n",
    "\n",
    "\n",
    "def get_mean_parse_tree_depth(text):\n",
    "    sentences = text.split(\".\")\n",
    "    depths = []\n",
    "    for doc in list(nlp.pipe(sentences)):\n",
    "        depths += get_parse_tree_depths(doc)\n",
    "    return np.mean(depths)\n",
    "\n",
    "\n",
    "def get_parse_tree_depths(doc):\n",
    "    return [get_depth(token) for token in doc]\n",
    "\n",
    "\n",
    "def get_depth(token, depth=0):\n",
    "    depths = [get_depth(child, depth + 1) for child in token.children]\n",
    "    return max(depths) if len(depths) > 0 else depth\n",
    "\n",
    "\n",
    "def get_mean_pos_tags(text):\n",
    "    sentences       = text.split(\".\")\n",
    "    sentence_counts = make_pos_tag_count_lists(sentences)\n",
    "    num_sentences   = textstat.sentence_count(text)\n",
    "    mean_pos_tags   = calculate_mean_per_tag(sentence_counts, num_sentences)\n",
    "    return mean_pos_tags\n",
    "\n",
    "\n",
    "def make_pos_tag_count_lists(sentences):\n",
    "    sentence_counts = {}\n",
    "    for doc in list(nlp.pipe(sentences)):\n",
    "        pos_counts = get_pos_tag_counts(doc)\n",
    "        for key in pos_counts:\n",
    "            if key in sentence_counts:\n",
    "                sentence_counts[key].append(pos_counts[key])\n",
    "            else:\n",
    "                sentence_counts[key] = [pos_counts[key]]\n",
    "    return sentence_counts\n",
    "\n",
    "\n",
    "def get_pos_tag_counts(doc):\n",
    "    pos_counts = {}\n",
    "    pos_tags = [token.pos_ for token in doc]\n",
    "    for tag in pos_tags:\n",
    "        if tag in pos_counts:\n",
    "            pos_counts[tag] += 1\n",
    "        else:\n",
    "            pos_counts[tag] = 1\n",
    "    return pos_counts\n",
    "\n",
    "\n",
    "def calculate_mean_per_tag(counts, num_sentences):\n",
    "    mean_pos_tags = {f\"mean_{tag.lower()}\": 0 for tag in POS_TAGS}\n",
    "    for key in counts:\n",
    "        if len(counts[key]) < num_sentences:\n",
    "            counts[key] += [0] * (num_sentences - len(counts[key]))\n",
    "        mean_value = round(np.mean(counts[key]), 2)\n",
    "        mean_pos_tags[\"mean_\" + key.lower()] = mean_value\n",
    "    return mean_pos_tags\n",
    "\n",
    "\n",
    "def get_total_ents(text):\n",
    "    return len(nlp(text).doc.ents)\n",
    "\n",
    "\n",
    "def get_mean_nonstop_char_length_word_count(text):\n",
    "    spans = tokenize_on_stopwords(text)\n",
    "    return sum([get_num_chars(span) for span in spans]) / len(spans),  sum([get_num_words(span) for span in spans]) / len(spans)\n",
    "\n",
    "\n",
    "def get_nonstop_proportion(text):\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    nonstop_tokens = [token for token in tokens if token not in STOPWORDS + PUNCTUATION]\n",
    "    return len(nonstop_tokens) / len(tokens)\n",
    "\n",
    "\n",
    "def tokenize_on_stopwords(text):\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    spans = []\n",
    "    current_span = []\n",
    "    for token in tokens:\n",
    "        if token not in STOPWORDS + PUNCTUATION:\n",
    "            current_span.append(token)\n",
    "        else:\n",
    "            if len(current_span) > 0:\n",
    "                spans.append(\" \".join(current_span))\n",
    "            current_span = []\n",
    "    return spans\n",
    "\n",
    "\n",
    "def get_num_chars(text):\n",
    "    return len(text)\n",
    "\n",
    "\n",
    "def get_num_words(text):\n",
    "    return len(text.split())\n",
    "\n",
    "\n",
    "def get_num_unique_words(text):\n",
    "     return len(set(w for w in text.split()))\n",
    "\n",
    "\n",
    "def get_num_sentences(text):\n",
    "    total = text.count(\".\") + text.count(\"?\") + text.count(\"!\")\n",
    "    if total == 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return total\n",
    "    \n",
    "    \n",
    "def get_num_semicolons(text):\n",
    "    total = text.count(\";\")\n",
    "    return total\n",
    "\n",
    "\n",
    "def get_num_quotes(text):\n",
    "    total = text.count('\"')\n",
    "    return total\n",
    "\n",
    "\n",
    "def get_num_punctuation(text):\n",
    "    total = sum(text.count(w) for w in '.,;:!?\"')\n",
    "    return total\n",
    "\n",
    "\n",
    "def gen_features(text):\n",
    "    \n",
    "    '''Compute text features'''\n",
    "        \n",
    "    simplified_text = simplify_punctuation(text)\n",
    "\n",
    "    features = {\n",
    "        \"flesch_reading_ease\":          textstat.flesch_reading_ease(simplified_text),\n",
    "        \"smog_index\":                   textstat.smog_index(simplified_text),\n",
    "        \"flesch_kincaid_grade\":         textstat.flesch_kincaid_grade(simplified_text),\n",
    "        \"coleman_liau_index\":           textstat.coleman_liau_index(simplified_text),\n",
    "        \"automated_readability_index\":  textstat.automated_readability_index(simplified_text),\n",
    "        \"dale_chall_readability_score\": textstat.dale_chall_readability_score(simplified_text),\n",
    "        \"difficult_words\":              textstat.difficult_words(simplified_text),\n",
    "        \"linsear_write_formula\":        textstat.linsear_write_formula(simplified_text),\n",
    "        \"gunning_fog2\":                 textstat.gunning_fog(simplified_text),\n",
    "        \"text_standard\":                textstat.text_standard(simplified_text, float_output = True),\n",
    "        \"mean_parse_tree_depth\":        get_mean_parse_tree_depth(text),\n",
    "        \"total_sentences\":              get_num_sentences(text),\n",
    "        \"total_words\":                  get_num_words(text),\n",
    "        \"total_ents\":                   get_total_ents(text),\n",
    "        \"total_chars\":                  get_num_chars(text),\n",
    "        \"total_punctutation\":           get_num_punctuation(text),\n",
    "        \"unique_words\":                 get_num_words(text),\n",
    "        \"nonstop_token_proportion\":     get_nonstop_proportion(text),\n",
    "        \"semicolons\":                   get_num_semicolons(text),\n",
    "        \"quotes\":                       get_num_quotes(text),\n",
    "    }\n",
    "    \n",
    "    nonstops = get_mean_nonstop_char_length_word_count(text)\n",
    "    features['nonstop_char_count'] = nonstops[0]\n",
    "    features['nonstop_word_count'] = nonstops[1]\n",
    "\n",
    "    features['words_per_sentence']    = features['total_words']        / features['total_sentences']\n",
    "    features['ents_per_sentence']     = features['total_ents']         / features['total_sentences']\n",
    "    features['chars_per_sentence']    = features['total_chars']        / features['total_sentences']\n",
    "    features['chars_per_word']        = features['total_chars']        / features['total_words']\n",
    "    features['punctutation_per_word'] = features['total_punctutation'] / features['total_sentences']\n",
    "\n",
    "    features.update(get_mean_pos_tags(text))\n",
    "        \n",
    "    return features\n",
    "\n",
    "\n",
    "def add_features(data):\n",
    "    \n",
    "    feature_data = []\n",
    "\n",
    "    for text in tqdm(data):\n",
    "        features = gen_features(text)\n",
    "        feature_data.append(features)\n",
    "\n",
    "    return pd.DataFrame(feature_data)\n",
    "\n",
    "\n",
    "def TF_IDF_W2V(text):\n",
    "    '''Calculate TF-IDF with word2vec\n",
    "    '''\n",
    "    #Load TF-IDF from sklearn\n",
    "    TFIDF_model = TfidfVectorizer()\n",
    "    #fit on text\n",
    "    TFIDF_model.fit(text)\n",
    "    #create dictionary with word as key\n",
    "    #and idf as value\n",
    "    dictionary = dict(zip(TFIDF_model.get_feature_names(), list(TFIDF_model.idf_)))\n",
    "    #apply set as we need unique features\n",
    "    TFIDF_words = set(TFIDF_model.get_feature_names())\n",
    "    #create list which stores TFIDF_W2V\n",
    "    TFIDF_W2V_vectors = []\n",
    "    for sentence in text:\n",
    "        #create empty vector to store result\n",
    "        vector = np.zeros(300)\n",
    "        #number of words with valid vector in sentence\n",
    "        TFIDF_weight =0\n",
    "        for word in sentence.split(): \n",
    "            #if word exist in glove_words and TFIDF_words\n",
    "            if (word in glove_words) and (word in TFIDF_words):\n",
    "                #get its vector from glove_words\n",
    "                vec = word2vec_model[word]\n",
    "                #calculate TF-IDF for each word\n",
    "                TFIDF = dictionary[word]*(sentence.count(word)/len(sentence.split()))\n",
    "                #calculate TF-IDF weighted W2V\n",
    "                vector += (vec * TFIDF)\n",
    "                TFIDF_weight += TFIDF\n",
    "                \n",
    "        if TFIDF_weight != 0:\n",
    "            vector /= TFIDF_weight\n",
    "        TFIDF_W2V_vectors.append(vector)\n",
    "    return TFIDF_W2V_vectors \n",
    "\n",
    "\n",
    "def clean_text(text):\n",
    "    text = str(text).lower()\n",
    "    text = re.sub('\\n', '', text)\n",
    "    text = \"\".join([i for i in text if i not in string.punctuation])\n",
    "    return text\n",
    "\n",
    "\n",
    "def tf_idf_features(df: pd.DataFrame):\n",
    "\n",
    "    text    = df['excerpt'].apply(lambda x: clean_text(x))\n",
    "    tfidf   = TF_IDF_W2V(text)\n",
    "    vectors = np.array(tfidf)\n",
    "        \n",
    "    return vectors\n",
    "\n",
    "\n",
    "def get_tf_idf_col_names():\n",
    "    names = list()\n",
    "    for i in range(300):\n",
    "        names.append(f\"tf_idf_{i}\")\n",
    "        \n",
    "    return names\n",
    "\n",
    "\n",
    "test           = pd.read_csv('../input/commonlitreadabilityprize/test.csv')\n",
    "test_features  = add_features(test.excerpt.to_list())\n",
    "test_features  = pd.DataFrame(test_features)\n",
    "test_features2 = pd.DataFrame(test.excerpt.apply(lambda p : readability_measurements(p)).tolist(), \n",
    "                               columns = [\"complex_words\",\"long_words\",\n",
    "                                          \"kincaid\", \"ari\", \"coleman_liau\", \"flesch\", \"gunning_fog\", \"lix\", \"smog\", \"rix\", \"dale_chall\",\n",
    "                                          \"tobeverb\", \"auxverb\", \"conjunction\", \"pronoun\", \"preposition\", \"nominalization\",\n",
    "                                          \"pronoun_b\", \"interrogative\", \"article\", \"subordination\", \"conjunction_b\", \"preposition_b\",])\n",
    "test_feats = pd.concat([test, test_features, test_features2], axis = 1)\n",
    "df_test    = df_test.merge(test_feats, how = 'left', on = 'id')\n",
    "print(df_test.shape)\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "84b63891",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-02T20:57:40.509458Z",
     "iopub.status.busy": "2021-08-02T20:57:40.508616Z",
     "iopub.status.idle": "2021-08-02T20:57:40.513431Z",
     "shell.execute_reply": "2021-08-02T20:57:40.512990Z",
     "shell.execute_reply.started": "2021-08-02T20:01:55.125033Z"
    },
    "papermill": {
     "duration": 0.084252,
     "end_time": "2021-08-02T20:57:40.513563",
     "exception": false,
     "start_time": "2021-08-02T20:57:40.429311",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2834, 106) (2834,)\n",
      "(7, 80)\n"
     ]
    }
   ],
   "source": [
    "####### TRANSFORM DATA\n",
    "\n",
    "y      = df_train['target']\n",
    "y_cat  = df_train['target_cat']\n",
    "X      = df_train.copy()\n",
    "X_test = df_test.copy()\n",
    "print(X.shape, y.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d647dc42",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-02T20:57:40.667907Z",
     "iopub.status.busy": "2021-08-02T20:57:40.667244Z",
     "iopub.status.idle": "2021-08-02T20:57:40.670446Z",
     "shell.execute_reply": "2021-08-02T20:57:40.670926Z",
     "shell.execute_reply.started": "2021-08-02T20:01:55.135625Z"
    },
    "papermill": {
     "duration": 0.08179,
     "end_time": "2021-08-02T20:57:40.671067",
     "exception": false,
     "start_time": "2021-08-02T20:57:40.589277",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75 features\n",
      "['flesch_reading_ease', 'smog_index', 'flesch_kincaid_grade', 'coleman_liau_index', 'automated_readability_index', 'dale_chall_readability_score', 'difficult_words', 'linsear_write_formula', 'gunning_fog2', 'text_standard', 'mean_parse_tree_depth', 'total_sentences', 'total_words', 'total_ents', 'total_chars', 'total_punctutation', 'unique_words', 'nonstop_token_proportion', 'semicolons', 'quotes', 'nonstop_char_count', 'nonstop_word_count', 'words_per_sentence', 'ents_per_sentence', 'chars_per_sentence', 'chars_per_word', 'punctutation_per_word', 'mean_adj', 'mean_adp', 'mean_adv', 'mean_aux', 'mean_cconj', 'mean_det', 'mean_intj', 'mean_noun', 'mean_num', 'mean_part', 'mean_pron', 'mean_propn', 'mean_punct', 'mean_sconj', 'mean_verb', 'mean_x', 'mean_space', 'complex_words', 'long_words', 'kincaid', 'ari', 'coleman_liau', 'flesch', 'gunning_fog', 'lix', 'smog', 'rix', 'dale_chall', 'tobeverb', 'auxverb', 'conjunction', 'pronoun', 'preposition', 'nominalization', 'pronoun_b', 'interrogative', 'article', 'subordination', 'conjunction_b', 'preposition_b', '../input/readability-training-v56/', '../input/readability-training-v55/', '../input/readability-training-v52/', '../input/readability-v62/', '../input/readability-v36/', '../input/readability-v47/', '../input/readability-v69/', '../input/readability-training-v59/']\n"
     ]
    }
   ],
   "source": [
    "####### SELECT RELEVANT FEATURES\n",
    "\n",
    "features      = list(test_feats.columns) + CFG['models']\n",
    "drop_features = ['id', 'url_legal', 'license', 'excerpt', 'standard_error']\n",
    "features      = [f for f in features if f not in drop_features]\n",
    "print(len(features), 'features')\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c769899b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-02T20:57:40.827933Z",
     "iopub.status.busy": "2021-08-02T20:57:40.827083Z",
     "iopub.status.idle": "2021-08-02T20:57:40.829995Z",
     "shell.execute_reply": "2021-08-02T20:57:40.829556Z",
     "shell.execute_reply.started": "2021-08-02T20:09:48.209621Z"
    },
    "papermill": {
     "duration": 0.083213,
     "end_time": "2021-08-02T20:57:40.830107",
     "exception": false,
     "start_time": "2021-08-02T20:57:40.746894",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "CFG['lgb_params']   = {'objective':         'regression',\n",
    "                       'metrics':           'rmse',\n",
    "                       'n_estimators':      10000,\n",
    "                       'learning_rate':     0.01,\n",
    "                       'num_leaves':        12,\n",
    "                       'max_depth':         3,\n",
    "                       'min_child_samples': 20,\n",
    "                       'subsample':         0.8,\n",
    "                       'colsample_bytree':  0.8,\n",
    "                       'reg_alpha':         0.01,\n",
    "                       'reg_lambda':        0.01,\n",
    "                       'silent':            True,\n",
    "                       'verbosity':         -1,\n",
    "                       'n_jobs' :           -1,\n",
    "                       'random_state':      13353}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ed268094",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-02T20:57:40.988601Z",
     "iopub.status.busy": "2021-08-02T20:57:40.987828Z",
     "iopub.status.idle": "2021-08-02T20:57:53.547077Z",
     "shell.execute_reply": "2021-08-02T20:57:53.546627Z",
     "shell.execute_reply.started": "2021-08-02T20:09:48.735183Z"
    },
    "papermill": {
     "duration": 12.643786,
     "end_time": "2021-08-02T20:57:53.547230",
     "exception": false,
     "start_time": "2021-08-02T20:57:40.903444",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "- FOLD 1: RMSE = 0.4610\n",
      "- FOLD 2: RMSE = 0.4682\n",
      "- FOLD 3: RMSE = 0.4469\n",
      "- FOLD 4: RMSE = 0.4649\n",
      "- FOLD 5: RMSE = 0.4619\n",
      "------------------------------\n",
      "REP 0: RMSE = 0.4606\n",
      "------------------------------\n",
      "- FOLD 1: RMSE = 0.4711\n",
      "- FOLD 2: RMSE = 0.4663\n",
      "- FOLD 3: RMSE = 0.4446\n",
      "- FOLD 4: RMSE = 0.4762\n",
      "- FOLD 5: RMSE = 0.4495\n",
      "------------------------------\n",
      "REP 1: RMSE = 0.4617\n",
      "------------------------------\n",
      "- FOLD 1: RMSE = 0.4576\n",
      "- FOLD 2: RMSE = 0.4564\n",
      "- FOLD 3: RMSE = 0.4777\n",
      "- FOLD 4: RMSE = 0.4485\n",
      "- FOLD 5: RMSE = 0.4697\n",
      "------------------------------\n",
      "REP 2: RMSE = 0.4621\n",
      "------------------------------\n",
      "\n",
      "OOF RMSE = 0.4599\n"
     ]
    }
   ],
   "source": [
    "####### STACKING LOOP\n",
    "\n",
    "# placeholders\n",
    "oof_preds     = np.zeros((len(X), CFG['lgb_reps']))\n",
    "all_lgb_preds = None\n",
    "importances   = pd.DataFrame()\n",
    "\n",
    "# cross-validation\n",
    "print('-' * 30)\n",
    "for rep in range(CFG['lgb_reps']):\n",
    "    \n",
    "    # partitinonig\n",
    "    skf = StratifiedKFold(n_splits = CFG['lgb_folds'], random_state = CFG['seed'] + rep, shuffle = True)\n",
    "    for fold, (trn_idx, val_idx) in enumerate(skf.split(X, y_cat)):\n",
    "\n",
    "        # placeholders\n",
    "        lgb_preds = np.zeros(len(X_test))\n",
    "\n",
    "        # extract samples\n",
    "        X_train, y_train = X.iloc[trn_idx][features], y.iloc[trn_idx]\n",
    "        X_valid, y_valid = X.iloc[val_idx][features], y.iloc[val_idx]\n",
    "        X_test           = X_test[features]\n",
    "\n",
    "        # modeling\n",
    "        clf = lgb.LGBMRegressor(**CFG['lgb_params']) \n",
    "        clf = clf.fit(X_train, y_train, \n",
    "                      eval_set              = [(X_train, y_train), (X_valid, y_valid)],\n",
    "                      early_stopping_rounds = CFG['lgb_stop_rounds'],\n",
    "                      verbose               = False)\n",
    "\n",
    "        # prediction\n",
    "        oof_preds[val_idx, rep] = clf.predict(X_valid)\n",
    "        lgb_preds               = clf.predict(X_test)\n",
    "\n",
    "        # save preditions\n",
    "        lgb_preds     = pd.DataFrame(lgb_preds, columns = ['lgb_rep{}_fold{}'.format(rep, fold)])\n",
    "        all_lgb_preds = pd.concat([all_lgb_preds, lgb_preds], axis = 1)\n",
    "\n",
    "        # feature importance\n",
    "        fold_importance_df               = pd.DataFrame()\n",
    "        fold_importance_df['Feature']    = features\n",
    "        fold_importance_df['Importance'] = clf.feature_importances_\n",
    "        importances = pd.concat([importances, fold_importance_df], axis = 0)\n",
    "\n",
    "        # information\n",
    "        print('- FOLD {}: RMSE = {:.4f}'.format(fold + 1, get_score(y_valid, oof_preds[val_idx, rep])))\n",
    "\n",
    "    # print performance\n",
    "    print('-' * 30)\n",
    "    print('REP {}: RMSE = {:.4f}'.format(rep, get_score(y, oof_preds[:, rep])))\n",
    "    print('-' * 30)\n",
    "    \n",
    "# print performance\n",
    "print('')\n",
    "print('OOF RMSE = {:.4f}'.format(get_score(y, oof_preds.mean(axis = 1)))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "48232b60",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-02T20:57:53.715116Z",
     "iopub.status.busy": "2021-08-02T20:57:53.714566Z",
     "iopub.status.idle": "2021-08-02T20:57:55.465525Z",
     "shell.execute_reply": "2021-08-02T20:57:55.465934Z",
     "shell.execute_reply.started": "2021-08-02T20:10:07.074045Z"
    },
    "papermill": {
     "duration": 1.842173,
     "end_time": "2021-08-02T20:57:55.466079",
     "exception": false,
     "start_time": "2021-08-02T20:57:53.623906",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "###### FEATURE IMPORTANCE\n",
    "\n",
    "fig  = plt.figure(figsize = (10, 10))\n",
    "cols = importances[['Feature', 'Importance']].groupby('Feature').mean().sort_values(by = 'Importance', ascending = False).index\n",
    "importance = importances.loc[importances.Feature.isin(cols)].groupby('Feature').mean().reset_index(drop = False)\n",
    "sns.barplot(x = 'Importance', y = 'Feature', data = importance.sort_values(by = 'Importance', ascending = False), ci = 0)\n",
    "plt.title('Feature Importance')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4dd45894",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-02T20:57:55.627942Z",
     "iopub.status.busy": "2021-08-02T20:57:55.627074Z",
     "iopub.status.idle": "2021-08-02T20:57:55.643039Z",
     "shell.execute_reply": "2021-08-02T20:57:55.643604Z",
     "shell.execute_reply.started": "2021-08-02T20:10:17.682202Z"
    },
    "papermill": {
     "duration": 0.101432,
     "end_time": "2021-08-02T20:57:55.643755",
     "exception": false,
     "start_time": "2021-08-02T20:57:55.542323",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blending fold predictions with: amean\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>lgb_rep0</th>\n",
       "      <th>lgb_rep1</th>\n",
       "      <th>lgb_rep2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c0f722661</td>\n",
       "      <td>-0.347026</td>\n",
       "      <td>-0.355782</td>\n",
       "      <td>-0.353793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>f0953f0a5</td>\n",
       "      <td>-0.560983</td>\n",
       "      <td>-0.566695</td>\n",
       "      <td>-0.547930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0df072751</td>\n",
       "      <td>-0.383909</td>\n",
       "      <td>-0.381284</td>\n",
       "      <td>-0.399454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>04caf4e0c</td>\n",
       "      <td>-2.494757</td>\n",
       "      <td>-2.477678</td>\n",
       "      <td>-2.445026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0e63f8bea</td>\n",
       "      <td>-1.840127</td>\n",
       "      <td>-1.818459</td>\n",
       "      <td>-1.857208</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  lgb_rep0  lgb_rep1  lgb_rep2\n",
       "0  c0f722661 -0.347026 -0.355782 -0.353793\n",
       "1  f0953f0a5 -0.560983 -0.566695 -0.547930\n",
       "2  0df072751 -0.383909 -0.381284 -0.399454\n",
       "3  04caf4e0c -2.494757 -2.477678 -2.445026\n",
       "4  0e63f8bea -1.840127 -1.818459 -1.857208"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "######## BLEND FOLD PREDICTIONS\n",
    "\n",
    "# copy predictions\n",
    "test_preds_lgb       = all_lgb_preds.copy()\n",
    "test_preds_lgb['id'] = sub['id']\n",
    "\n",
    "# blend folds\n",
    "print('Blending fold predictions with: ' + CFG['fold_blend'])\n",
    "for rep in range(CFG['lgb_reps']):\n",
    "    preds = ['lgb_rep' + str(rep) + '_fold' + str(fold) for fold in range(CFG['lgb_folds'])]\n",
    "    test_preds_lgb['lgb_rep' + str(rep)] = compute_blend(test_preds_lgb, preds, CFG['fold_blend'], CFG)\n",
    "    test_preds_lgb.drop(preds, axis = 1, inplace = True)\n",
    "test_preds_lgb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9ff343dc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-02T20:57:55.813137Z",
     "iopub.status.busy": "2021-08-02T20:57:55.812231Z",
     "iopub.status.idle": "2021-08-02T20:57:55.816561Z",
     "shell.execute_reply": "2021-08-02T20:57:55.817051Z",
     "shell.execute_reply.started": "2021-08-02T20:10:21.510683Z"
    },
    "papermill": {
     "duration": 0.093813,
     "end_time": "2021-08-02T20:57:55.817199",
     "exception": false,
     "start_time": "2021-08-02T20:57:55.723386",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blending bag predictions with: amean\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c0f722661</td>\n",
       "      <td>-0.352200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>f0953f0a5</td>\n",
       "      <td>-0.558536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0df072751</td>\n",
       "      <td>-0.388216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>04caf4e0c</td>\n",
       "      <td>-2.472487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0e63f8bea</td>\n",
       "      <td>-1.838598</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id      pred\n",
       "0  c0f722661 -0.352200\n",
       "1  f0953f0a5 -0.558536\n",
       "2  0df072751 -0.388216\n",
       "3  04caf4e0c -2.472487\n",
       "4  0e63f8bea -1.838598"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "######## BLEND BAG PREDICTIONS\n",
    "\n",
    "print('Blending bag predictions with: ' + CFG['rep_blend'])\n",
    "preds                  = test_preds_lgb.filter(like = 'lgb').columns\n",
    "test_preds_lgb['pred'] = compute_blend(test_preds_lgb, preds, CFG['rep_blend'], CFG)\n",
    "test_preds_lgb.drop(preds, axis = 1, inplace = True)\n",
    "test_preds_lgb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8519f6ad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-02T20:57:55.981984Z",
     "iopub.status.busy": "2021-08-02T20:57:55.980724Z",
     "iopub.status.idle": "2021-08-02T20:57:56.281833Z",
     "shell.execute_reply": "2021-08-02T20:57:56.282753Z",
     "shell.execute_reply.started": "2021-08-02T20:10:26.138009Z"
    },
    "papermill": {
     "duration": 0.387862,
     "end_time": "2021-08-02T20:57:56.282965",
     "exception": false,
     "start_time": "2021-08-02T20:57:55.895103",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "- optimal weight of stacking:   0.4200\n",
      "- RMSE of blend-stack ensemble: 0.4572\n"
     ]
    }
   ],
   "source": [
    "####### OPTIMAL STACKING WEIGHT\n",
    "\n",
    "# placeholders\n",
    "score_steps = 100\n",
    "scores      = []\n",
    "\n",
    "# optimize stacking weight\n",
    "for a in range(score_steps):\n",
    "    w    = a / score_steps\n",
    "    pred = oof_preds.mean(axis = 1) * w + oof_blend['pred'] * (1 - w)\n",
    "    scores.append(get_score(y, pred))\n",
    "plt.plot(scores)\n",
    "plt.show()\n",
    "\n",
    "# feedback\n",
    "w_stack = scores.index(min(scores)) / score_steps\n",
    "print('')\n",
    "print('- optimal weight of stacking:   {:.4f}'.format(w_stack))\n",
    "print('- RMSE of blend-stack ensemble: {:.4f}'.format(min(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c9db3bb",
   "metadata": {
    "papermill": {
     "duration": 0.133245,
     "end_time": "2021-08-02T20:57:56.558487",
     "exception": false,
     "start_time": "2021-08-02T20:57:56.425242",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# SUBMISSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1c18f488",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-02T20:57:56.734034Z",
     "iopub.status.busy": "2021-08-02T20:57:56.733100Z",
     "iopub.status.idle": "2021-08-02T20:57:56.737440Z",
     "shell.execute_reply": "2021-08-02T20:57:56.737906Z",
     "shell.execute_reply.started": "2021-07-28T08:52:07.05132Z"
    },
    "papermill": {
     "duration": 0.098991,
     "end_time": "2021-08-02T20:57:56.738042",
     "exception": false,
     "start_time": "2021-08-02T20:57:56.639051",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensembling: 1.00 * blend + 0.00 * stacking\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>../input/readability-training-v56/</th>\n",
       "      <th>../input/readability-training-v55/</th>\n",
       "      <th>../input/readability-training-v52/</th>\n",
       "      <th>../input/readability-v62/</th>\n",
       "      <th>../input/readability-v36/</th>\n",
       "      <th>../input/readability-v47/</th>\n",
       "      <th>../input/readability-v69/</th>\n",
       "      <th>../input/readability-training-v59/</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c0f722661</td>\n",
       "      <td>-0.407019</td>\n",
       "      <td>-0.418115</td>\n",
       "      <td>-0.428809</td>\n",
       "      <td>-0.417407</td>\n",
       "      <td>-0.363428</td>\n",
       "      <td>-0.569788</td>\n",
       "      <td>-0.336011</td>\n",
       "      <td>-0.313513</td>\n",
       "      <td>-0.406761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>f0953f0a5</td>\n",
       "      <td>-0.775049</td>\n",
       "      <td>-0.650342</td>\n",
       "      <td>-0.656812</td>\n",
       "      <td>-0.406238</td>\n",
       "      <td>-0.452954</td>\n",
       "      <td>-0.715674</td>\n",
       "      <td>-0.301917</td>\n",
       "      <td>-0.492480</td>\n",
       "      <td>-0.556433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0df072751</td>\n",
       "      <td>-0.399255</td>\n",
       "      <td>-0.423889</td>\n",
       "      <td>-0.453345</td>\n",
       "      <td>-0.415808</td>\n",
       "      <td>-0.413208</td>\n",
       "      <td>-0.376318</td>\n",
       "      <td>-0.374390</td>\n",
       "      <td>-0.365051</td>\n",
       "      <td>-0.402658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>04caf4e0c</td>\n",
       "      <td>-2.496289</td>\n",
       "      <td>-2.488867</td>\n",
       "      <td>-2.459375</td>\n",
       "      <td>-2.241211</td>\n",
       "      <td>-2.279492</td>\n",
       "      <td>-2.507227</td>\n",
       "      <td>-2.159277</td>\n",
       "      <td>-2.533789</td>\n",
       "      <td>-2.395691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0e63f8bea</td>\n",
       "      <td>-1.726758</td>\n",
       "      <td>-1.779590</td>\n",
       "      <td>-1.770117</td>\n",
       "      <td>-1.858301</td>\n",
       "      <td>-1.881738</td>\n",
       "      <td>-1.788184</td>\n",
       "      <td>-1.840430</td>\n",
       "      <td>-1.871289</td>\n",
       "      <td>-1.814551</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  ../input/readability-training-v56/  \\\n",
       "0  c0f722661                           -0.407019   \n",
       "1  f0953f0a5                           -0.775049   \n",
       "2  0df072751                           -0.399255   \n",
       "3  04caf4e0c                           -2.496289   \n",
       "4  0e63f8bea                           -1.726758   \n",
       "\n",
       "   ../input/readability-training-v55/  ../input/readability-training-v52/  \\\n",
       "0                           -0.418115                           -0.428809   \n",
       "1                           -0.650342                           -0.656812   \n",
       "2                           -0.423889                           -0.453345   \n",
       "3                           -2.488867                           -2.459375   \n",
       "4                           -1.779590                           -1.770117   \n",
       "\n",
       "   ../input/readability-v62/  ../input/readability-v36/  \\\n",
       "0                  -0.417407                  -0.363428   \n",
       "1                  -0.406238                  -0.452954   \n",
       "2                  -0.415808                  -0.413208   \n",
       "3                  -2.241211                  -2.279492   \n",
       "4                  -1.858301                  -1.881738   \n",
       "\n",
       "   ../input/readability-v47/  ../input/readability-v69/  \\\n",
       "0                  -0.569788                  -0.336011   \n",
       "1                  -0.715674                  -0.301917   \n",
       "2                  -0.376318                  -0.374390   \n",
       "3                  -2.507227                  -2.159277   \n",
       "4                  -1.788184                  -1.840430   \n",
       "\n",
       "   ../input/readability-training-v59/      pred  \n",
       "0                           -0.313513 -0.406761  \n",
       "1                           -0.492480 -0.556433  \n",
       "2                           -0.365051 -0.402658  \n",
       "3                           -2.533789 -2.395691  \n",
       "4                           -1.871289 -1.814551  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "####### ENSEMBLING BLEND AND STACKING\n",
    "\n",
    "print('Ensembling: {:.2f} * blend + {:.2f} * stacking'.format(1 - CFG['w_stack'], CFG['w_stack']))\n",
    "test_preds = test_preds_nn.copy()\n",
    "test_preds['pred'] = test_preds_nn['pred'] * (1 - CFG['w_stack']) + test_preds_lgb['pred'] * CFG['w_stack']\n",
    "test_preds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "49a15bee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-02T20:57:56.910204Z",
     "iopub.status.busy": "2021-08-02T20:57:56.905668Z",
     "iopub.status.idle": "2021-08-02T20:57:56.915869Z",
     "shell.execute_reply": "2021-08-02T20:57:56.915394Z",
     "shell.execute_reply.started": "2021-07-28T08:52:07.073637Z"
    },
    "papermill": {
     "duration": 0.097996,
     "end_time": "2021-08-02T20:57:56.915994",
     "exception": false,
     "start_time": "2021-08-02T20:57:56.817998",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c0f722661</td>\n",
       "      <td>-0.406761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>f0953f0a5</td>\n",
       "      <td>-0.556433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0df072751</td>\n",
       "      <td>-0.402658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>04caf4e0c</td>\n",
       "      <td>-2.395691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0e63f8bea</td>\n",
       "      <td>-1.814551</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id    target\n",
       "0  c0f722661 -0.406761\n",
       "1  f0953f0a5 -0.556433\n",
       "2  0df072751 -0.402658\n",
       "3  04caf4e0c -2.395691\n",
       "4  0e63f8bea -1.814551"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "####### SUBMISSION FILE\n",
    "\n",
    "if all_counter == len(CFG['models'] * CFG['use_folds'] * CFG['use_reps']):\n",
    "    sub = test_preds[['id', 'pred']].copy()   \n",
    "    sub.columns = ['id', 'target']\n",
    "    sub['target'] = np.clip(sub['target'].values, CFG['clip'][0], CFG['clip'][1])\n",
    "    sub.to_csv(CFG['out_path'] + 'submission.csv', index = False)\n",
    "    display(sub.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd97acd",
   "metadata": {
    "papermill": {
     "duration": 0.079292,
     "end_time": "2021-08-02T20:57:57.084928",
     "exception": false,
     "start_time": "2021-08-02T20:57:57.005636",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# PUBLIC KERNELS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4e419ea",
   "metadata": {
    "papermill": {
     "duration": 0.079285,
     "end_time": "2021-08-02T20:57:57.243606",
     "exception": false,
     "start_time": "2021-08-02T20:57:57.164321",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## MODEL 1 [5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f2bcf18e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-02T20:57:57.424869Z",
     "iopub.status.busy": "2021-08-02T20:57:57.424187Z",
     "iopub.status.idle": "2021-08-02T20:58:37.476411Z",
     "shell.execute_reply": "2021-08-02T20:58:37.476830Z",
     "shell.execute_reply.started": "2021-07-28T08:58:08.025768Z"
    },
    "papermill": {
     "duration": 40.154343,
     "end_time": "2021-08-02T20:58:37.476995",
     "exception": false,
     "start_time": "2021-08-02T20:57:57.322652",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Using ../input/commonlit-roberta-0467/model_1.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at /kaggle/input/transformers/roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Using ../input/commonlit-roberta-0467/model_2.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at /kaggle/input/transformers/roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Using ../input/commonlit-roberta-0467/model_3.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at /kaggle/input/transformers/roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Using ../input/commonlit-roberta-0467/model_4.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at /kaggle/input/transformers/roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Using ../input/commonlit-roberta-0467/model_5.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at /kaggle/input/transformers/roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "if CFG['w_public'] > 0:\n",
    "\n",
    "    import os\n",
    "    import math\n",
    "    import random\n",
    "    import time\n",
    "\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "\n",
    "    import torch\n",
    "    import torch.nn as nn\n",
    "    from torch.utils.data import Dataset\n",
    "    from torch.utils.data import DataLoader\n",
    "\n",
    "    from transformers import AutoTokenizer\n",
    "    from transformers import AutoModel\n",
    "    from transformers import AutoConfig\n",
    "\n",
    "    from sklearn.model_selection import KFold\n",
    "    from sklearn.svm import SVR\n",
    "\n",
    "    import gc\n",
    "    gc.enable()\n",
    "\n",
    "\n",
    "    BATCH_SIZE     = 32\n",
    "    MAX_LEN        = 248\n",
    "    EVAL_SCHEDULE  = [(0.50, 16), (0.49, 8), (0.48, 4), (0.47, 2), (-1., 1)]\n",
    "    ROBERTA_PATH   = \"/kaggle/input/transformers/roberta-base\"\n",
    "    TOKENIZER_PATH = \"/kaggle/input/transformers/roberta-base\"\n",
    "    DEVICE         = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "    test_df       = pd.read_csv(\"/kaggle/input/commonlitreadabilityprize/test.csv\")\n",
    "    submission_df = pd.read_csv(\"/kaggle/input/commonlitreadabilityprize/sample_submission.csv\")\n",
    "    tokenizer     = AutoTokenizer.from_pretrained(TOKENIZER_PATH)\n",
    "\n",
    "\n",
    "    class LitDataset(Dataset):\n",
    "        def __init__(self, df, inference_only=False):\n",
    "            super().__init__()\n",
    "\n",
    "            self.df = df        \n",
    "            self.inference_only = inference_only\n",
    "            self.text = df.excerpt.tolist()\n",
    "            #self.text = [text.replace(\"\\n\", \" \") for text in self.text]\n",
    "\n",
    "            if not self.inference_only:\n",
    "                self.target = torch.tensor(df.target.values, dtype=torch.float32)        \n",
    "\n",
    "            self.encoded = tokenizer.batch_encode_plus(\n",
    "                self.text,\n",
    "                padding = 'max_length',            \n",
    "                max_length = MAX_LEN,\n",
    "                truncation = True,\n",
    "                return_attention_mask=True\n",
    "            )        \n",
    "\n",
    "\n",
    "        def __len__(self):\n",
    "            return len(self.df)\n",
    "\n",
    "\n",
    "        def __getitem__(self, index):        \n",
    "            input_ids = torch.tensor(self.encoded['input_ids'][index])\n",
    "            attention_mask = torch.tensor(self.encoded['attention_mask'][index])\n",
    "\n",
    "            if self.inference_only:\n",
    "                return (input_ids, attention_mask)            \n",
    "            else:\n",
    "                target = self.target[index]\n",
    "                return (input_ids, attention_mask, target)\n",
    "\n",
    "\n",
    "    class LitModel(nn.Module):\n",
    "        def __init__(self):\n",
    "            super().__init__()\n",
    "\n",
    "            config = AutoConfig.from_pretrained(ROBERTA_PATH)\n",
    "            config.update({\"output_hidden_states\":True, \n",
    "                           \"hidden_dropout_prob\": 0.0,\n",
    "                           \"layer_norm_eps\": 1e-7})                       \n",
    "\n",
    "            self.roberta = AutoModel.from_pretrained(ROBERTA_PATH, config=config)  \n",
    "\n",
    "            self.attention = nn.Sequential(            \n",
    "                nn.Linear(768, 512),            \n",
    "                nn.Tanh(),                       \n",
    "                nn.Linear(512, 1),\n",
    "                nn.Softmax(dim=1)\n",
    "            )        \n",
    "\n",
    "            self.regressor = nn.Sequential(                        \n",
    "                nn.Linear(768, 1)                        \n",
    "            )\n",
    "\n",
    "\n",
    "        def forward(self, input_ids, attention_mask):\n",
    "            roberta_output = self.roberta(input_ids=input_ids,\n",
    "                                          attention_mask=attention_mask)        \n",
    "\n",
    "            # There are a total of 13 layers of hidden states.\n",
    "            # 1 for the embedding layer, and 12 for the 12 Roberta layers.\n",
    "            # We take the hidden states from the last Roberta layer.\n",
    "            last_layer_hidden_states = roberta_output.hidden_states[-1]\n",
    "\n",
    "            # The number of cells is MAX_LEN.\n",
    "            # The size of the hidden state of each cell is 768 (for roberta-base).\n",
    "            # In order to condense hidden states of all cells to a context vector,\n",
    "            # we compute a weighted average of the hidden states of all cells.\n",
    "            # We compute the weight of each cell, using the attention neural network.\n",
    "            weights = self.attention(last_layer_hidden_states)\n",
    "\n",
    "            # weights.shape is BATCH_SIZE x MAX_LEN x 1\n",
    "            # last_layer_hidden_states.shape is BATCH_SIZE x MAX_LEN x 768        \n",
    "            # Now we compute context_vector as the weighted average.\n",
    "            # context_vector.shape is BATCH_SIZE x 768\n",
    "            context_vector = torch.sum(weights * last_layer_hidden_states, dim=1)        \n",
    "\n",
    "            # Now we reduce the context vector to the prediction score.\n",
    "            return self.regressor(context_vector)\n",
    "\n",
    "\n",
    "    def predict(model, data_loader):\n",
    "        \"\"\"Returns an np.array with predictions of the |model| on |data_loader|\"\"\"\n",
    "        model.eval()\n",
    "\n",
    "        result = np.zeros(len(data_loader.dataset))    \n",
    "        index = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch_num, (input_ids, attention_mask) in enumerate(data_loader):\n",
    "                input_ids = input_ids.to(DEVICE)\n",
    "                attention_mask = attention_mask.to(DEVICE)\n",
    "\n",
    "                pred = model(input_ids, attention_mask)                        \n",
    "\n",
    "                result[index : index + pred.shape[0]] = pred.flatten().to(\"cpu\")\n",
    "                index += pred.shape[0]\n",
    "\n",
    "        return result\n",
    "\n",
    "\n",
    "    NUM_MODELS = 5\n",
    "\n",
    "    all_predictions = np.zeros((NUM_MODELS, len(test_df)))\n",
    "    test_dataset    = LitDataset(test_df, inference_only=True)\n",
    "    test_loader     = DataLoader(test_dataset, batch_size=BATCH_SIZE,\n",
    "                             drop_last=False, shuffle=False, num_workers=2)\n",
    "\n",
    "    for model_index in range(NUM_MODELS):            \n",
    "        model_path = f\"../input/commonlit-roberta-0467/model_{model_index + 1}.pth\"\n",
    "        print(f\"\\nUsing {model_path}\")\n",
    "\n",
    "        model = LitModel()\n",
    "        model.load_state_dict(torch.load(model_path, map_location=DEVICE))    \n",
    "        model.to(DEVICE)\n",
    "\n",
    "        all_predictions[model_index] = predict(model, test_loader)\n",
    "\n",
    "        del model\n",
    "        gc.collect()\n",
    "\n",
    "\n",
    "    model1_predictions = all_predictions.mean(axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89e4fab4",
   "metadata": {
    "papermill": {
     "duration": 0.08315,
     "end_time": "2021-08-02T20:58:37.693630",
     "exception": false,
     "start_time": "2021-08-02T20:58:37.610480",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## MODEL 2 [15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a90bc00d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-02T20:58:37.903102Z",
     "iopub.status.busy": "2021-08-02T20:58:37.880406Z",
     "iopub.status.idle": "2021-08-02T21:02:48.209709Z",
     "shell.execute_reply": "2021-08-02T21:02:48.209277Z",
     "shell.execute_reply.started": "2021-07-28T08:58:59.957976Z"
    },
    "papermill": {
     "duration": 250.433482,
     "end_time": "2021-08-02T21:02:48.209841",
     "exception": false,
     "start_time": "2021-08-02T20:58:37.776359",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[ASome weights of the model checkpoint at ../input/roberta-base/ were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model pushed to 1 GPU(s), type Tesla P100-PCIE-16GB.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ../input/robertalarge/ were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model pushed to 1 GPU(s), type Tesla P100-PCIE-16GB.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ../input/robertalarge/ were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model pushed to 1 GPU(s), type Tesla P100-PCIE-16GB.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 20%|██        | 1/5 [01:13<04:52, 73.02s/it]\u001b[ASome weights of the model checkpoint at ../input/roberta-base/ were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model pushed to 1 GPU(s), type Tesla P100-PCIE-16GB.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ../input/robertalarge/ were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model pushed to 1 GPU(s), type Tesla P100-PCIE-16GB.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ../input/robertalarge/ were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model pushed to 1 GPU(s), type Tesla P100-PCIE-16GB.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 40%|████      | 2/5 [01:59<02:51, 57.23s/it]\u001b[ASome weights of the model checkpoint at ../input/roberta-base/ were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model pushed to 1 GPU(s), type Tesla P100-PCIE-16GB.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ../input/robertalarge/ were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model pushed to 1 GPU(s), type Tesla P100-PCIE-16GB.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ../input/robertalarge/ were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model pushed to 1 GPU(s), type Tesla P100-PCIE-16GB.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 60%|██████    | 3/5 [02:47<01:46, 53.07s/it]\u001b[ASome weights of the model checkpoint at ../input/roberta-base/ were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model pushed to 1 GPU(s), type Tesla P100-PCIE-16GB.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ../input/robertalarge/ were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model pushed to 1 GPU(s), type Tesla P100-PCIE-16GB.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ../input/robertalarge/ were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model pushed to 1 GPU(s), type Tesla P100-PCIE-16GB.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 80%|████████  | 4/5 [03:29<00:48, 48.74s/it]\u001b[ASome weights of the model checkpoint at ../input/roberta-base/ were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model pushed to 1 GPU(s), type Tesla P100-PCIE-16GB.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ../input/robertalarge/ were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model pushed to 1 GPU(s), type Tesla P100-PCIE-16GB.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ../input/robertalarge/ were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model pushed to 1 GPU(s), type Tesla P100-PCIE-16GB.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 5/5 [04:10<00:00, 50.06s/it]\n"
     ]
    }
   ],
   "source": [
    "if CFG['w_public'] > 0:\n",
    "\n",
    "    test = test_df\n",
    "\n",
    "    from glob import glob\n",
    "    import os\n",
    "    import matplotlib.pyplot as plt\n",
    "    import json\n",
    "    from collections import defaultdict\n",
    "\n",
    "    import torch\n",
    "    import torch.nn as nn\n",
    "    import torch.nn.functional as F\n",
    "    import torch.optim as optim\n",
    "    from torch.optim.optimizer import Optimizer\n",
    "    import torch.optim.lr_scheduler as lr_scheduler\n",
    "    from torch.utils.data import (\n",
    "        Dataset, DataLoader, \n",
    "        SequentialSampler, RandomSampler\n",
    "    )\n",
    "    from transformers import RobertaConfig\n",
    "    from transformers import (\n",
    "        get_cosine_schedule_with_warmup, \n",
    "        get_cosine_with_hard_restarts_schedule_with_warmup\n",
    "    )\n",
    "    from transformers import RobertaTokenizer\n",
    "    from transformers import RobertaModel\n",
    "    from IPython.display import clear_output\n",
    "    from tqdm import tqdm, trange\n",
    "\n",
    "\n",
    "    def convert_examples_to_features(data, tokenizer, max_len, is_test=False):\n",
    "        data = data.replace('\\n', '')\n",
    "        tok = tokenizer.encode_plus(\n",
    "            data, \n",
    "            max_length=max_len, \n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_token_type_ids=True\n",
    "        )\n",
    "        curr_sent = {}\n",
    "        padding_length = max_len - len(tok['input_ids'])\n",
    "        curr_sent['input_ids'] = tok['input_ids'] + ([0] * padding_length)\n",
    "        curr_sent['token_type_ids'] = tok['token_type_ids'] + \\\n",
    "            ([0] * padding_length)\n",
    "        curr_sent['attention_mask'] = tok['attention_mask'] + \\\n",
    "            ([0] * padding_length)\n",
    "        return curr_sent\n",
    "\n",
    "\n",
    "    class DatasetRetriever(Dataset):\n",
    "        def __init__(self, data, tokenizer, max_len, is_test=False):\n",
    "            self.data = data\n",
    "            self.excerpts = self.data.excerpt.values.tolist()\n",
    "            self.tokenizer = tokenizer\n",
    "            self.is_test = is_test\n",
    "            self.max_len = max_len\n",
    "\n",
    "        def __len__(self):\n",
    "            return len(self.data)\n",
    "\n",
    "        def __getitem__(self, item):\n",
    "            if not self.is_test:\n",
    "                excerpt, label = self.excerpts[item], self.targets[item]\n",
    "                features = convert_examples_to_features(\n",
    "                    excerpt, self.tokenizer, \n",
    "                    self.max_len, self.is_test\n",
    "                )\n",
    "                return {\n",
    "                    'input_ids':torch.tensor(features['input_ids'], dtype=torch.long),\n",
    "                    'token_type_ids':torch.tensor(features['token_type_ids'], dtype=torch.long),\n",
    "                    'attention_mask':torch.tensor(features['attention_mask'], dtype=torch.long),\n",
    "                    'label':torch.tensor(label, dtype=torch.double),\n",
    "                }\n",
    "            else:\n",
    "                excerpt = self.excerpts[item]\n",
    "                features = convert_examples_to_features(\n",
    "                    excerpt, self.tokenizer, \n",
    "                    self.max_len, self.is_test\n",
    "                )\n",
    "                return {\n",
    "                    'input_ids':torch.tensor(features['input_ids'], dtype=torch.long),\n",
    "                    'token_type_ids':torch.tensor(features['token_type_ids'], dtype=torch.long),\n",
    "                    'attention_mask':torch.tensor(features['attention_mask'], dtype=torch.long),\n",
    "                }\n",
    "\n",
    "\n",
    "    class CommonLitModel(nn.Module):\n",
    "        def __init__(\n",
    "            self, \n",
    "            model_name, \n",
    "            config,  \n",
    "            multisample_dropout=False,\n",
    "            output_hidden_states=False\n",
    "        ):\n",
    "            super(CommonLitModel, self).__init__()\n",
    "            self.config = config\n",
    "            self.roberta = RobertaModel.from_pretrained(\n",
    "                model_name, \n",
    "                output_hidden_states=output_hidden_states\n",
    "            )\n",
    "            self.layer_norm = nn.LayerNorm(config.hidden_size)\n",
    "            if multisample_dropout:\n",
    "                self.dropouts = nn.ModuleList([\n",
    "                    nn.Dropout(0.5) for _ in range(5)\n",
    "                ])\n",
    "            else:\n",
    "                self.dropouts = nn.ModuleList([nn.Dropout(0.3)])\n",
    "            self.regressor = nn.Linear(config.hidden_size, 1)\n",
    "            self._init_weights(self.layer_norm)\n",
    "            self._init_weights(self.regressor)\n",
    "\n",
    "        def _init_weights(self, module):\n",
    "            if isinstance(module, nn.Linear):\n",
    "                module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n",
    "                if module.bias is not None:\n",
    "                    module.bias.data.zero_()\n",
    "            elif isinstance(module, nn.Embedding):\n",
    "                module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n",
    "                if module.padding_idx is not None:\n",
    "                    module.weight.data[module.padding_idx].zero_()\n",
    "            elif isinstance(module, nn.LayerNorm):\n",
    "                module.bias.data.zero_()\n",
    "                module.weight.data.fill_(1.0)\n",
    "\n",
    "        def forward(\n",
    "            self, \n",
    "            input_ids=None,\n",
    "            attention_mask=None,\n",
    "            token_type_ids=None,\n",
    "            labels=None\n",
    "        ):\n",
    "            outputs = self.roberta(\n",
    "                input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                token_type_ids=token_type_ids,\n",
    "            )\n",
    "            sequence_output = outputs[1]\n",
    "            sequence_output = self.layer_norm(sequence_output)\n",
    "\n",
    "            # multi-sample dropout\n",
    "            for i, dropout in enumerate(self.dropouts):\n",
    "                if i == 0:\n",
    "                    logits = self.regressor(dropout(sequence_output))\n",
    "                else:\n",
    "                    logits += self.regressor(dropout(sequence_output))\n",
    "\n",
    "            logits /= len(self.dropouts)\n",
    "\n",
    "            # calculate loss\n",
    "            loss = None\n",
    "            if labels is not None:\n",
    "                loss_fn = torch.nn.MSELoss()\n",
    "                logits = logits.view(-1).to(labels.dtype)\n",
    "                loss = torch.sqrt(loss_fn(logits, labels.view(-1)))\n",
    "\n",
    "            output = (logits,) + outputs[1:]\n",
    "            return ((loss,) + output) if loss is not None else output\n",
    "\n",
    "\n",
    "    def make_model(model_name, num_labels=1):\n",
    "        tokenizer = RobertaTokenizer.from_pretrained(model_name)\n",
    "        config    = RobertaConfig.from_pretrained(model_name)\n",
    "        config.update({'num_labels':num_labels})\n",
    "        model = CommonLitModel(model_name, config=config)\n",
    "        return model, tokenizer\n",
    "\n",
    "    def make_loader(\n",
    "        data, \n",
    "        tokenizer, \n",
    "        max_len,\n",
    "        batch_size,\n",
    "    ):\n",
    "\n",
    "        test_dataset = DatasetRetriever(data, tokenizer, max_len, is_test=True)\n",
    "        test_sampler = SequentialSampler(test_dataset)\n",
    "        test_loader = DataLoader(\n",
    "            test_dataset, \n",
    "            batch_size=batch_size // 2, \n",
    "            sampler=test_sampler, \n",
    "            pin_memory=False, \n",
    "            drop_last=False, \n",
    "            num_workers=0\n",
    "        )\n",
    "\n",
    "        return test_loader\n",
    "\n",
    "\n",
    "    class Evaluator:\n",
    "        def __init__(self, model, scalar=None):\n",
    "            self.model = model\n",
    "            self.scalar = scalar\n",
    "\n",
    "        def evaluate(self, data_loader, tokenizer):\n",
    "            preds = []\n",
    "            self.model.eval()\n",
    "            total_loss = 0\n",
    "            with torch.no_grad():\n",
    "                for batch_idx, batch_data in enumerate(data_loader):\n",
    "                    input_ids, attention_mask, token_type_ids = batch_data['input_ids'], \\\n",
    "                        batch_data['attention_mask'], batch_data['token_type_ids']\n",
    "                    input_ids, attention_mask, token_type_ids = input_ids.cuda(), \\\n",
    "                        attention_mask.cuda(), token_type_ids.cuda()\n",
    "\n",
    "                    if self.scalar is not None:\n",
    "                        with torch.cuda.amp.autocast():\n",
    "                            outputs = self.model(\n",
    "                                input_ids=input_ids,\n",
    "                                attention_mask=attention_mask,\n",
    "                                token_type_ids=token_type_ids\n",
    "                            )\n",
    "                    else:\n",
    "                        outputs = self.model(\n",
    "                            input_ids=input_ids,\n",
    "                            attention_mask=attention_mask,\n",
    "                            token_type_ids=token_type_ids\n",
    "                        )\n",
    "\n",
    "                    logits = outputs[0].detach().cpu().numpy().squeeze().tolist()\n",
    "                    preds += logits\n",
    "            return preds\n",
    "\n",
    "\n",
    "    def config(fold, model_name, load_model_path):\n",
    "        torch.manual_seed(2021)\n",
    "        torch.cuda.manual_seed(2021)\n",
    "        torch.cuda.manual_seed_all(2021)\n",
    "\n",
    "        max_len = 250\n",
    "        batch_size = 8\n",
    "\n",
    "        model, tokenizer = make_model(\n",
    "            model_name=model_name, \n",
    "            num_labels=1\n",
    "        )\n",
    "        model.load_state_dict(\n",
    "            torch.load(f'{load_model_path}/model{fold}.bin')\n",
    "        )\n",
    "        test_loader = make_loader(\n",
    "            test, tokenizer, max_len=max_len,\n",
    "            batch_size=batch_size\n",
    "        )\n",
    "\n",
    "        if torch.cuda.device_count() >= 1:\n",
    "            print('Model pushed to {} GPU(s), type {}.'.format(\n",
    "                torch.cuda.device_count(), \n",
    "                torch.cuda.get_device_name(0))\n",
    "            )\n",
    "            model = model.cuda() \n",
    "        else:\n",
    "            raise ValueError('CPU training is not supported')\n",
    "\n",
    "        # scaler = torch.cuda.amp.GradScaler()\n",
    "        scaler = None\n",
    "        return (\n",
    "            model, tokenizer, \n",
    "            test_loader, scaler\n",
    "        )\n",
    "\n",
    "\n",
    "    def run(fold=0, model_name=None, load_model_path=None):\n",
    "        model, tokenizer, \\\n",
    "            test_loader, scaler = config(fold, model_name, load_model_path)\n",
    "\n",
    "        import time\n",
    "\n",
    "        evaluator = Evaluator(model, scaler)\n",
    "\n",
    "        test_time_list = []\n",
    "\n",
    "        torch.cuda.synchronize()\n",
    "        tic1 = time.time()\n",
    "\n",
    "        preds = evaluator.evaluate(test_loader, tokenizer)\n",
    "\n",
    "        torch.cuda.synchronize()\n",
    "        tic2 = time.time() \n",
    "        test_time_list.append(tic2 - tic1)\n",
    "\n",
    "        del model, tokenizer, test_loader, scaler\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        return preds\n",
    "\n",
    "\n",
    "    pred_df1 = pd.DataFrame()\n",
    "    pred_df2 = pd.DataFrame()\n",
    "    pred_df3 = pd.DataFrame()\n",
    "\n",
    "    for fold in tqdm(range(5)):\n",
    "        pred_df1[f'fold{fold}']    = run(fold, '../input/roberta-base/', '../input/commonlit-roberta-base-i/')\n",
    "        pred_df2[f'fold{fold+5}']  = run(fold, '../input/robertalarge/', '../input/roberta-large-itptfit/')\n",
    "        pred_df3[f'fold{fold+10}'] = run(fold, '../input/robertalarge/', '../input/commonlit-roberta-large-ii/')\n",
    "\n",
    "\n",
    "    pred_df1 = np.array(pred_df1)\n",
    "    pred_df2 = np.array(pred_df2)\n",
    "    pred_df3 = np.array(pred_df3)\n",
    "\n",
    "    model2_predictions = (pred_df2.mean(axis=1) * 1/3) + \\\n",
    "                         (pred_df1.mean(axis=1) * 1/3) + \\\n",
    "                         (pred_df3.mean(axis=1) * 1/3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90c489b7",
   "metadata": {
    "papermill": {
     "duration": 0.096342,
     "end_time": "2021-08-02T21:02:48.402509",
     "exception": false,
     "start_time": "2021-08-02T21:02:48.306167",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## MODEL 3 [5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7d16ae59",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-02T21:02:48.616243Z",
     "iopub.status.busy": "2021-08-02T21:02:48.615652Z",
     "iopub.status.idle": "2021-08-02T21:04:59.529742Z",
     "shell.execute_reply": "2021-08-02T21:04:59.529297Z",
     "shell.execute_reply.started": "2021-07-28T09:06:24.115309Z"
    },
    "papermill": {
     "duration": 131.031003,
     "end_time": "2021-08-02T21:04:59.529874",
     "exception": false,
     "start_time": "2021-08-02T21:02:48.498871",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63ee51aa207b4b5d86b9d9aa556fcf85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Using model_114_1.pth\n",
      "\n",
      "Using model_114_2.pth\n",
      "\n",
      "Using model_114_3.pth\n",
      "\n",
      "Using model_114_4.pth\n",
      "\n",
      "Using model_114_5.pth\n"
     ]
    }
   ],
   "source": [
    "if CFG['w_public'] > 0:  \n",
    "\n",
    "    import os\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    import random\n",
    "\n",
    "    from transformers import AutoConfig, AutoModel, AutoTokenizer, AdamW, get_linear_schedule_with_warmup, logging\n",
    "\n",
    "    import torch\n",
    "    import torch.nn as nn\n",
    "    import torch.nn.functional as F\n",
    "    from torch.utils.data import Dataset, TensorDataset, SequentialSampler, RandomSampler, DataLoader\n",
    "\n",
    "    from tqdm.notebook import tqdm\n",
    "\n",
    "    import gc; gc.enable()\n",
    "    from IPython.display import clear_output\n",
    "\n",
    "    from sklearn.model_selection import StratifiedKFold\n",
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn as sns\n",
    "\n",
    "    sns.set_style('whitegrid')\n",
    "    logging.set_verbosity_error()\n",
    "\n",
    "\n",
    "    INPUT_DIR      = '../input/commonlitreadabilityprize'\n",
    "    MODEL_DIR      = '../input/transformers/roberta-large'\n",
    "    CHECKPOINT_DIR = '../input/clrp-mean-pooling/'\n",
    "\n",
    "    DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    MAX_LENGTH = 248\n",
    "    TEST_BATCH_SIZE = 1\n",
    "    HIDDEN_SIZE = 1024\n",
    "\n",
    "    NUM_FOLDS = 5\n",
    "    SEEDS = [113]\n",
    "\n",
    "    test = pd.read_csv(os.path.join(INPUT_DIR, 'test.csv'))\n",
    "\n",
    "\n",
    "    class MeanPoolingModel(nn.Module):\n",
    "\n",
    "        def __init__(self, model_name):\n",
    "            super().__init__()\n",
    "\n",
    "            config = AutoConfig.from_pretrained(model_name)\n",
    "            self.model = AutoModel.from_pretrained(model_name, config=config)\n",
    "            self.linear = nn.Linear(HIDDEN_SIZE, 1)\n",
    "            self.loss = nn.MSELoss()\n",
    "\n",
    "        def forward(self, input_ids, attention_mask, labels=None):\n",
    "\n",
    "            outputs = self.model(input_ids, attention_mask)\n",
    "            last_hidden_state = outputs[0]\n",
    "            input_mask_expanded = attention_mask.unsqueeze(-1).expand(last_hidden_state.size()).float()\n",
    "            sum_embeddings = torch.sum(last_hidden_state * input_mask_expanded, 1)\n",
    "            sum_mask = input_mask_expanded.sum(1)\n",
    "            sum_mask = torch.clamp(sum_mask, min=1e-9)\n",
    "            mean_embeddings = sum_embeddings / sum_mask\n",
    "            logits = self.linear(mean_embeddings)\n",
    "\n",
    "            preds = logits.squeeze(-1).squeeze(-1)\n",
    "\n",
    "            if labels is not None:\n",
    "                loss = self.loss(preds.view(-1).float(), labels.view(-1).float())\n",
    "                return loss\n",
    "            else:\n",
    "                return preds\n",
    "\n",
    "\n",
    "    def get_test_loader(data):\n",
    "\n",
    "        x_test = data.excerpt.tolist()\n",
    "\n",
    "        tokenizer = AutoTokenizer.from_pretrained(MODEL_DIR)\n",
    "\n",
    "        encoded_test = tokenizer.batch_encode_plus(\n",
    "            x_test, \n",
    "            add_special_tokens=True, \n",
    "            return_attention_mask=True, \n",
    "            padding='max_length', \n",
    "            truncation=True,\n",
    "            max_length=MAX_LENGTH, \n",
    "            return_tensors='pt'\n",
    "        )\n",
    "\n",
    "        dataset_test = TensorDataset(\n",
    "            encoded_test['input_ids'],\n",
    "            encoded_test['attention_mask']\n",
    "        )\n",
    "\n",
    "        dataloader_test = DataLoader(\n",
    "            dataset_test,\n",
    "            sampler = SequentialSampler(dataset_test),\n",
    "            batch_size=TEST_BATCH_SIZE\n",
    "        )\n",
    "\n",
    "        return dataloader_test\n",
    "\n",
    "    test_dataloader = get_test_loader(test)\n",
    "\n",
    "\n",
    "    all_predictions = []\n",
    "    for seed in SEEDS:\n",
    "\n",
    "        fold_predictions = []\n",
    "\n",
    "        for fold in tqdm(range(NUM_FOLDS)):\n",
    "            model_path = f\"model_{seed + 1}_{fold + 1}.pth\"\n",
    "\n",
    "            print(f\"\\nUsing {model_path}\")\n",
    "\n",
    "            model_path = CHECKPOINT_DIR + f\"model_{seed + 1}_{fold + 1}.pth\"\n",
    "            model = MeanPoolingModel(MODEL_DIR)\n",
    "            model.load_state_dict(torch.load(model_path)) \n",
    "            model.to(DEVICE)\n",
    "            model.eval()\n",
    "\n",
    "            predictions = []\n",
    "            for batch in test_dataloader:\n",
    "\n",
    "                batch = tuple(b.to(DEVICE) for b in batch)\n",
    "\n",
    "                inputs = {'input_ids':      batch[0],\n",
    "                          'attention_mask': batch[1],\n",
    "                          'labels':         None,\n",
    "                         }\n",
    "\n",
    "                preds = model(**inputs).item()\n",
    "                predictions.append(preds)\n",
    "\n",
    "            del model \n",
    "            gc.collect()\n",
    "\n",
    "            fold_predictions.append(predictions)\n",
    "        all_predictions.append(np.mean(fold_predictions, axis=0).tolist())\n",
    "\n",
    "    model3_predictions = np.mean(all_predictions,axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d6967acc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-02T21:04:59.730492Z",
     "iopub.status.busy": "2021-08-02T21:04:59.729944Z",
     "iopub.status.idle": "2021-08-02T21:04:59.734224Z",
     "shell.execute_reply": "2021-08-02T21:04:59.733815Z",
     "shell.execute_reply.started": "2021-07-28T09:08:29.032652Z"
    },
    "papermill": {
     "duration": 0.107234,
     "end_time": "2021-08-02T21:04:59.734341",
     "exception": false,
     "start_time": "2021-08-02T21:04:59.627107",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.42785269 -0.53396597 -0.42449434 -2.38692547 -1.78933372 -1.22127291\n",
      "  0.10485552]\n"
     ]
    }
   ],
   "source": [
    "if CFG['w_public'] > 0:  \n",
    "\n",
    "    predictions = model1_predictions * (1/3) + model2_predictions * (1/3) + model3_predictions * (1/3)\n",
    "    print(predictions[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4e2b79d",
   "metadata": {
    "papermill": {
     "duration": 0.098398,
     "end_time": "2021-08-02T21:04:59.931044",
     "exception": false,
     "start_time": "2021-08-02T21:04:59.832646",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# FINAL BLEND"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "23747db7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-02T21:05:00.134115Z",
     "iopub.status.busy": "2021-08-02T21:05:00.132388Z",
     "iopub.status.idle": "2021-08-02T21:05:00.150886Z",
     "shell.execute_reply": "2021-08-02T21:05:00.151286Z",
     "shell.execute_reply.started": "2021-07-28T08:52:07.228079Z"
    },
    "papermill": {
     "duration": 0.122367,
     "end_time": "2021-08-02T21:05:00.151425",
     "exception": false,
     "start_time": "2021-08-02T21:05:00.029058",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensembling: 0.80 * my + 0.20 * public\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c0f722661</td>\n",
       "      <td>-0.410979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>f0953f0a5</td>\n",
       "      <td>-0.551940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0df072751</td>\n",
       "      <td>-0.407025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>04caf4e0c</td>\n",
       "      <td>-2.393938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0e63f8bea</td>\n",
       "      <td>-1.809507</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id    target\n",
       "0  c0f722661 -0.410979\n",
       "1  f0953f0a5 -0.551940\n",
       "2  0df072751 -0.407025\n",
       "3  04caf4e0c -2.393938\n",
       "4  0e63f8bea -1.809507"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "####### SUBMISSION FILE\n",
    "\n",
    "if CFG['w_public'] > 0:\n",
    "\n",
    "    print('Ensembling: {:.2f} * my + {:.2f} * public'.format(1 - CFG['w_public'], CFG['w_public']))\n",
    "    sub           = pd.read_csv(CFG['out_path'] + 'submission.csv')\n",
    "    sub['target'] = (1 - CFG['w_public']) * sub['target'] + CFG['w_public'] * predictions\n",
    "    sub.to_csv(CFG['out_path'] + 'submission.csv', index = False)\n",
    "    display(sub.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1284.073661,
   "end_time": "2021-08-02T21:05:03.725423",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-08-02T20:43:39.651762",
   "version": "2.3.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "0b9759ed9a5c46e198310c7702bc7fb5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_aaf476aacecf4bfb8e013f77426945d6",
       "placeholder": "​",
       "style": "IPY_MODEL_112daaeed1904f0094a5cf5a1f5369bf",
       "value": "100%"
      }
     },
     "0f990297cb0845d798cec864bbfacfde": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_ce065d54503e4f00bda349a20103d2da",
       "placeholder": "​",
       "style": "IPY_MODEL_45e9d52a951c4ca4bc563cafb248ecba",
       "value": " 80/80 [12:37&lt;00:00,  3.70s/it]"
      }
     },
     "112daaeed1904f0094a5cf5a1f5369bf": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "182d011a4be24c4a8c53e50f88a239bd": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "200863b3eb3f493398aa44ee86ed4820": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_d70a8df7d1414e46a9589eba3f2f9725",
        "IPY_MODEL_6f05e37d8f7e49dab511c19e490a2887",
        "IPY_MODEL_d7ffc07b516c49f08cd3bcc01d57906f"
       ],
       "layout": "IPY_MODEL_fccb5c1699384fc6b52c6f40295c6b21"
      }
     },
     "2acc6c46b4834168b060776653ff3a02": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "35b8a4f7355740548eacc2df273e26f5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_cfe02f4f258540cb839c7e667edc19d3",
       "placeholder": "​",
       "style": "IPY_MODEL_ba7b209a6f35478f99bf2c4414d45d1a",
       "value": "100%"
      }
     },
     "45e9d52a951c4ca4bc563cafb248ecba": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "492496e0ff8e4a71904d66c30bfac2ff": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "4a9f25266b6d4db28a16b6b730709cae": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_35b8a4f7355740548eacc2df273e26f5",
        "IPY_MODEL_773704bdd4fa4ce38141ad25177e34c0",
        "IPY_MODEL_0f990297cb0845d798cec864bbfacfde"
       ],
       "layout": "IPY_MODEL_dda8b381574a4b9386791ad894088d4a"
      }
     },
     "588adcf854df4f139cbadfea0cbacc2c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "5e23cebf1aaa432fa4aae82679f44489": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "63ee51aa207b4b5d86b9d9aa556fcf85": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_0b9759ed9a5c46e198310c7702bc7fb5",
        "IPY_MODEL_b5bd45d61c984c27a3bc8547fd42ee89",
        "IPY_MODEL_b1ac87f8a6704824a3e0b38ad788a3f5"
       ],
       "layout": "IPY_MODEL_5e23cebf1aaa432fa4aae82679f44489"
      }
     },
     "6f05e37d8f7e49dab511c19e490a2887": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_d50760d27a184a31abd561fcbf162427",
       "max": 7.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_7b55de5185ef4a18aa67f29ec0fff29a",
       "value": 7.0
      }
     },
     "71f0ce3d417442a69c37dbeff54c5a1d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "773704bdd4fa4ce38141ad25177e34c0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_182d011a4be24c4a8c53e50f88a239bd",
       "max": 80.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_afe282542f7948f3adefb4b44fc2573a",
       "value": 80.0
      }
     },
     "7b55de5185ef4a18aa67f29ec0fff29a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "a2f7c3531b454656af242d28105fce29": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "a4dd880db0ce43819cf43f799c782767": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "aaf476aacecf4bfb8e013f77426945d6": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "afe282542f7948f3adefb4b44fc2573a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "b1ac87f8a6704824a3e0b38ad788a3f5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_492496e0ff8e4a71904d66c30bfac2ff",
       "placeholder": "​",
       "style": "IPY_MODEL_e9b26307476e4a69ad7ce4b3e09ee8ef",
       "value": " 5/5 [02:10&lt;00:00, 23.25s/it]"
      }
     },
     "b5bd45d61c984c27a3bc8547fd42ee89": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_71f0ce3d417442a69c37dbeff54c5a1d",
       "max": 5.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_2acc6c46b4834168b060776653ff3a02",
       "value": 5.0
      }
     },
     "ba7b209a6f35478f99bf2c4414d45d1a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "c037459ba56143f4ac0dd462e98176d6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "ce065d54503e4f00bda349a20103d2da": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "cfe02f4f258540cb839c7e667edc19d3": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d50760d27a184a31abd561fcbf162427": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d70a8df7d1414e46a9589eba3f2f9725": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_a2f7c3531b454656af242d28105fce29",
       "placeholder": "​",
       "style": "IPY_MODEL_c037459ba56143f4ac0dd462e98176d6",
       "value": "100%"
      }
     },
     "d7ffc07b516c49f08cd3bcc01d57906f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_588adcf854df4f139cbadfea0cbacc2c",
       "placeholder": "​",
       "style": "IPY_MODEL_a4dd880db0ce43819cf43f799c782767",
       "value": " 7/7 [00:02&lt;00:00,  2.93it/s]"
      }
     },
     "dda8b381574a4b9386791ad894088d4a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e9b26307476e4a69ad7ce4b3e09ee8ef": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "fccb5c1699384fc6b52c6f40295c6b21": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
